{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cil-TiwB2UV1"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/TransformerLensOrg/TransformerLens/blob/main/demos/Grokking_Demo.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2A9Wv1do2UV2"
      },
      "source": [
        "# Dev Interp - Grokking Modular Addition and Multiplication"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A13-7Mc62UV3"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Q998xCML2UV3"
      },
      "outputs": [],
      "source": [
        "TRAIN_MODEL = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "zUBTNnz62UV3",
        "outputId": "3658e07b-1cba-42b8-f23b-a319f209561a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running as a Jupyter notebook - intended for development only!\n",
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/85/m4tlmmlj4w58khykxvwgvt980000gn/T/ipykernel_97413/2858945602.py:22: DeprecationWarning:\n",
            "\n",
            "`magic(...)` is deprecated since IPython 0.13 (warning added in 8.1), use run_line_magic(magic_name, parameter_s).\n",
            "\n",
            "/var/folders/85/m4tlmmlj4w58khykxvwgvt980000gn/T/ipykernel_97413/2858945602.py:23: DeprecationWarning:\n",
            "\n",
            "`magic(...)` is deprecated since IPython 0.13 (warning added in 8.1), use run_line_magic(magic_name, parameter_s).\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Janky code to do different setup when run in a Colab notebook vs VSCode\n",
        "import os\n",
        "\n",
        "DEVELOPMENT_MODE = True\n",
        "IN_GITHUB = os.getenv(\"GITHUB_ACTIONS\") == \"true\"\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"Running as a Colab notebook\")\n",
        "\n",
        "    # PySvelte is an unmaintained visualization library, use it as a backup if circuitsvis isn't working\n",
        "    # # Install another version of node that makes PySvelte work way faster\n",
        "    # !curl -fsSL https://deb.nodesource.com/setup_16.x | sudo -E bash -; sudo apt-get install -y nodejs\n",
        "    # %pip install git+https://github.com/neelnanda-io/PySvelte.git\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    print(\"Running as a Jupyter notebook - intended for development only!\")\n",
        "    from IPython import get_ipython\n",
        "\n",
        "    ipython = get_ipython()\n",
        "    # Code to automatically update the HookedTransformer code as its edited without restarting the kernel\n",
        "    ipython.magic(\"load_ext autoreload\")\n",
        "    ipython.magic(\"autoreload 2\")\n",
        "\n",
        "if IN_COLAB or IN_GITHUB:\n",
        "    %pip install transformer_lens\n",
        "    %pip install circuitsvis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "I8nEQDlP2UV4",
        "outputId": "a46ab340-d447-407c-9e3d-36be3ef04ad3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using renderer: notebook_connected\n"
          ]
        }
      ],
      "source": [
        "# Plotly needs a different renderer for VSCode/Notebooks vs Colab argh\n",
        "import plotly.io as pio\n",
        "if IN_COLAB or not DEVELOPMENT_MODE:\n",
        "    pio.renderers.default = \"colab\"\n",
        "else:\n",
        "    pio.renderers.default = \"notebook_connected\"\n",
        "print(f\"Using renderer: {pio.renderers.default}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "rp4RGtCp2UV4"
      },
      "outputs": [],
      "source": [
        "pio.templates['plotly'].layout.xaxis.title.font.size = 20\n",
        "pio.templates['plotly'].layout.yaxis.title.font.size = 20\n",
        "pio.templates['plotly'].layout.title.font.size = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "RpPUz36r2UV4"
      },
      "outputs": [],
      "source": [
        "# Import stuff\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import einops\n",
        "from fancy_einsum import einsum\n",
        "import os\n",
        "import tqdm.auto as tqdm\n",
        "import random\n",
        "from pathlib import Path\n",
        "import plotly.express as px\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from typing import List, Union, Optional\n",
        "from functools import partial\n",
        "import copy\n",
        "\n",
        "import itertools\n",
        "from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n",
        "import dataclasses\n",
        "import datasets\n",
        "from IPython.display import HTML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "NmIM5yWr2UV4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "device: cpu\n"
          ]
        }
      ],
      "source": [
        "import transformer_lens.utils as utils\n",
        "from transformer_lens import HookedTransformer, HookedTransformerConfig\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "print(f\"device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5bjmWrq2UV5"
      },
      "source": [
        "Plotting helper functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "aZe03f--2UV5"
      },
      "outputs": [],
      "source": [
        "from collections import deque\n",
        "\n",
        "def rolling_average(values, window_size):\n",
        "    window = deque(maxlen=window_size)\n",
        "    averages = []\n",
        "    \n",
        "    for value in values:\n",
        "        window.append(value)\n",
        "        averages.append(sum(window) / len(window))\n",
        "    \n",
        "    return averages\n",
        "\n",
        "def imshow(tensor, renderer=None, xaxis=\"\", yaxis=\"\", **kwargs):\n",
        "    px.imshow(utils.to_numpy(tensor), color_continuous_midpoint=0.0, color_continuous_scale=\"RdBu\", labels={\"x\":xaxis, \"y\":yaxis}, **kwargs).show(renderer)\n",
        "\n",
        "def line(tensor, renderer=None, xaxis=\"\", yaxis=\"\", **kwargs):\n",
        "    px.line(utils.to_numpy(tensor), labels={\"x\":xaxis, \"y\":yaxis}, **kwargs).show(renderer)\n",
        "\n",
        "def scatter(x, y, xaxis=\"\", yaxis=\"\", caxis=\"\", renderer=None, **kwargs):\n",
        "    x = utils.to_numpy(x)\n",
        "    y = utils.to_numpy(y)\n",
        "    px.scatter(y=y, x=x, labels={\"x\":xaxis, \"y\":yaxis, \"color\":caxis}, **kwargs).show(renderer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EE1YCCg2UV5"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "2-6AgR5N2UV5"
      },
      "outputs": [],
      "source": [
        "DATA_SEED = 598"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqhvJcjT2UV5"
      },
      "source": [
        "## Create the dataset\n",
        "* Define modular addition and modular multiplication datasets\n",
        "* Combine the two data sets\n",
        "* We can vary the proportion of addition to multiplication in the training dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Addition dataset size = 16900\n",
            "Multiplication dataset size = 16900\n",
            "Total train size = 16900\n",
            "Addition train size = 11830\n",
            "Addition test size = 5070\n",
            "Multiplication train size = 5070\n",
            "Multiplication test size = 5070\n",
            "Addition: 70.0% Multiplication: 30.0%\n",
            "Combined dataset = 27040\n",
            "Train size = 16900\n",
            "Test size = 10140\n",
            "train_data.shape = torch.Size([16900, 3])\n",
            "train_labels.shape = torch.Size([16900])\n",
            "test_data.shape = torch.Size([10140, 3])\n",
            "test_labels.shape = torch.Size([10140])\n",
            "train_data[:10] = tensor([[ 51,   0,  92],\n",
            "        [ 33,   0, 104],\n",
            "        [121,   1,  24],\n",
            "        [114,   0, 120],\n",
            "        [ 42,   1,  35],\n",
            "        [129,   1, 115],\n",
            "        [ 85,   1,   5],\n",
            "        [108,   1,   3],\n",
            "        [111,   1, 127],\n",
            "        [ 14,   1,  32]])\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "max_nums = 130\n",
        "mod_value = 113\n",
        "\n",
        "# The fraction of the data that should be used for training (not all of the rest will be used for testing)\n",
        "train_frac = 0.5\n",
        "\n",
        "# The fraction of the training data that should be addition (the rest will be multiplication)\n",
        "addition_frac = 0.7\n",
        "\n",
        "def create_dataset(max_nums: int, addition: bool, mod_value: int):\n",
        "    data = list()\n",
        "    for a in range(max_nums):\n",
        "        for b in range(max_nums):\n",
        "            if addition:\n",
        "                label = (a + b) % mod_value\n",
        "            else:\n",
        "                label = (a * b) % mod_value\n",
        "            data.append([[a, int(addition), b], label])\n",
        "\n",
        "    return pd.DataFrame(data, columns=[\"input\", \"label\"])\n",
        "\n",
        "addition_df = create_dataset(max_nums, True, mod_value)\n",
        "multiplication_df = create_dataset(max_nums, False, mod_value)\n",
        "\n",
        "print(f\"Addition dataset size = {len(addition_df)}\")\n",
        "print(f\"Multiplication dataset size = {len(multiplication_df)}\")\n",
        "\n",
        "total_train_size = int((len(addition_df) + len(multiplication_df)) * train_frac)\n",
        "\n",
        "print(f\"Total train size = {total_train_size}\")\n",
        "# Calculate the sizes for train datasets based on the desired proportion\n",
        "add_train_size = int(total_train_size * addition_frac)\n",
        "multi_train_size = total_train_size - add_train_size\n",
        "\n",
        "# Determine the size for test datasets (use the remaining data, but ensure equal sizes)\n",
        "test_size = min(len(addition_df) - add_train_size, len(multiplication_df) - multi_train_size)\n",
        "\n",
        "# Create train datasets\n",
        "add_train_df = addition_df.sample(n=add_train_size, random_state=DATA_SEED)\n",
        "multi_train_df = multiplication_df.sample(n=multi_train_size, random_state=DATA_SEED)\n",
        "\n",
        "# Create test datasets with equal size\n",
        "add_test_df = addition_df.drop(add_train_df.index).sample(n=test_size, random_state=DATA_SEED)\n",
        "multi_test_df = multiplication_df.drop(multi_train_df.index).sample(n=test_size, random_state=DATA_SEED)\n",
        "\n",
        "# Print sizes for verification\n",
        "print(f\"Addition train size = {len(add_train_df)}\")\n",
        "print(f\"Addition test size = {len(add_test_df)}\")\n",
        "print(f\"Multiplication train size = {len(multi_train_df)}\")\n",
        "print(f\"Multiplication test size = {len(multi_test_df)}\")\n",
        "\n",
        "print(f\"Addition: {len(add_train_df)/(len(add_train_df) + len(multi_train_df))*100:0.1f}% \\\n",
        "Multiplication: {len(multi_train_df)/(len(add_train_df) + len(multi_train_df))*100:0.1f}%\")\n",
        "\n",
        "# Combine and shuffle the datasets\n",
        "train_df = pd.concat([add_train_df, multi_train_df], ignore_index=True).sample(frac=1, random_state=DATA_SEED).reset_index(drop=True)\n",
        "test_df = pd.concat([add_test_df, multi_test_df], ignore_index=True).sample(frac=1, random_state=DATA_SEED).reset_index(drop=True)\n",
        "\n",
        "print(f\"Combined dataset = {len(train_df) + len(test_df)}\")\n",
        "\n",
        "print(f\"Train size = {len(train_df)}\")\n",
        "print(f\"Test size = {len(test_df)}\")\n",
        "\n",
        "# Create the dataloaders\n",
        "def get_dataloader(df, batch_size, shuffle):\n",
        "    inputs = torch.tensor(df['input'].tolist())\n",
        "    labels = torch.tensor(df['label'].tolist())\n",
        "    dataset = TensorDataset(inputs, labels)\n",
        "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
        "\n",
        "train_loader = get_dataloader(train_df, 1024, shuffle=True)\n",
        "test_loader = get_dataloader(test_df, len(test_df), shuffle=False)\n",
        "\n",
        "train_data = torch.tensor(train_df['input'].tolist())\n",
        "train_labels = torch.tensor(train_df['label'].tolist())\n",
        "\n",
        "test_data = torch.tensor(test_df['input'].tolist())\n",
        "test_labels = torch.tensor(test_df['label'].tolist())\n",
        "\n",
        "add_test_data = torch.tensor(add_test_df['input'].tolist())\n",
        "add_test_labels = torch.tensor(add_test_df['label'].tolist())\n",
        "\n",
        "multi_test_data = torch.tensor(multi_test_df['input'].tolist())\n",
        "multi_test_labels = torch.tensor(multi_test_df['label'].tolist())\n",
        "\n",
        "print(f\"train_data.shape = {train_data.shape}\")\n",
        "print(f\"train_labels.shape = {train_labels.shape}\")\n",
        "print(f\"test_data.shape = {test_data.shape}\")\n",
        "print(f\"test_labels.shape = {test_labels.shape}\")\n",
        "print(f\"train_data[:10] = {train_data[:10]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mcd2dy9x2UV6"
      },
      "source": [
        "## Define Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "GO7-UYjQ2UV6"
      },
      "outputs": [],
      "source": [
        "\n",
        "cfg = HookedTransformerConfig(\n",
        "    n_layers = 1,\n",
        "    n_heads = 4,\n",
        "    d_model = 128,\n",
        "    d_head = 32,\n",
        "    d_mlp = 512,\n",
        "    act_fn = \"relu\",\n",
        "    normalization_type=\"LN\",\n",
        "    d_vocab=max_nums+1,\n",
        "    d_vocab_out=mod_value,\n",
        "    n_ctx= train_data.shape[1],\n",
        "    init_weights=True,\n",
        "    device=device,\n",
        "    seed = 999,\n",
        ")\n",
        "\n",
        "model = HookedTransformer(cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qNAf_pY2UV6"
      },
      "source": [
        "Disable the biases, as we don't need them for this task and it makes things easier to interpret."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "9Y6S95XF2UV6"
      },
      "outputs": [],
      "source": [
        "for name, param in model.named_parameters():\n",
        "    if \"b_\" in name:\n",
        "        param.requires_grad = False\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQtU2xX02UV6"
      },
      "source": [
        "## Define Optimizer + Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "kt9M_v7a2UV6"
      },
      "outputs": [],
      "source": [
        "# Optimizer config\n",
        "lr = 1e-3\n",
        "wd = 1.\n",
        "betas = (0.90, 0.98)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd, betas=betas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_loss = 5.046054775218921\n",
            "test_loss = 5.063647319925165\n"
          ]
        }
      ],
      "source": [
        "def loss_fn(logits, labels):\n",
        "    if len(logits.shape)==3:\n",
        "        logits = logits[:, -1]\n",
        "    logits = logits.to(torch.float64)\n",
        "    log_probs = logits.log_softmax(dim=-1)\n",
        "    correct_log_probs = log_probs.gather(dim=-1, index=labels[:, None])[:, 0]\n",
        "    return -correct_log_probs.mean()\n",
        "\n",
        "train_logits = model(train_data)\n",
        "train_loss = loss_fn(train_logits, train_labels)\n",
        "print(f\"train_loss = {train_loss}\")\n",
        "test_logits = model(test_data)\n",
        "test_loss = loss_fn(test_logits, test_labels)\n",
        "print(f\"test_loss = {test_loss}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOuSwO1U2UV7"
      },
      "source": [
        "## Actually Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "c477d3a6463646deb7cf1de99bb0199a"
          ]
        },
        "id": "B78ji8Si2UV7",
        "outputId": "db8171c9-35a3-497a-aa61-a9b8efeee374"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "67e3c5e683d04114b0a354c6a92b3cb6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/5000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 99 Train Loss 2.3294648834150715 Test Loss 4.679007530181849 Add Test Loss 4.069230493292609 Multi Test Loss 5.288784567071089\n",
            "Epoch 199 Train Loss 0.3136851436641664 Test Loss 4.551669366701374 Add Test Loss 2.848536382936925 Multi Test Loss 6.2548023504658214\n",
            "Epoch 299 Train Loss 0.061398116457624774 Test Loss 4.6520407518985465 Add Test Loss 2.4287113748556486 Multi Test Loss 6.875370128941447\n",
            "Epoch 399 Train Loss 0.021673669077540456 Test Loss 4.63081129888064 Add Test Loss 2.076342635387659 Multi Test Loss 7.18527996237362\n",
            "Epoch 499 Train Loss 0.01951381511198585 Test Loss 4.6177622625262105 Add Test Loss 1.7909188069739796 Multi Test Loss 7.444605718078441\n",
            "Epoch 599 Train Loss 0.010175613193089149 Test Loss 4.596109025772736 Add Test Loss 1.682979258270012 Multi Test Loss 7.50923879327546\n",
            "Epoch 699 Train Loss 0.005060668832677027 Test Loss 4.712357317486467 Add Test Loss 1.5351547716374576 Multi Test Loss 7.889559863335477\n",
            "Epoch 799 Train Loss 0.002202568011900958 Test Loss 4.77435825599499 Add Test Loss 1.2888520676802346 Multi Test Loss 8.259864444309745\n",
            "Epoch 899 Train Loss 0.01137453861111188 Test Loss 4.269316779957655 Add Test Loss 0.956046050673977 Multi Test Loss 7.582587509241333\n",
            "Epoch 999 Train Loss 0.011460007386450803 Test Loss 4.041817915568508 Add Test Loss 0.8804770094552105 Multi Test Loss 7.203158821681807\n",
            "Epoch 1099 Train Loss 0.00650897782149914 Test Loss 3.966094322236062 Add Test Loss 0.6655689845165699 Multi Test Loss 7.266619659955555\n",
            "Epoch 1199 Train Loss 0.013863906088528158 Test Loss 3.7008459701169545 Add Test Loss 0.4218736061935138 Multi Test Loss 6.979818334040393\n",
            "Epoch 1299 Train Loss 0.01151259217942994 Test Loss 3.516440667533995 Add Test Loss 0.33160328000152234 Multi Test Loss 6.701278055066468\n",
            "Epoch 1399 Train Loss 0.19472490330366093 Test Loss 3.5484369808108385 Add Test Loss 0.4117068589329299 Multi Test Loss 6.685167102688748\n",
            "Epoch 1499 Train Loss 0.018095227490689886 Test Loss 3.2287213497929517 Add Test Loss 0.15090426901699203 Multi Test Loss 6.306538430568911\n",
            "Epoch 1599 Train Loss 0.011487846313990111 Test Loss 3.142323950334153 Add Test Loss 0.08804870957082084 Multi Test Loss 6.196599191097485\n",
            "Epoch 1699 Train Loss 0.021689836580187267 Test Loss 3.084627493609083 Add Test Loss 0.07026714615967167 Multi Test Loss 6.098987841058495\n",
            "Epoch 1799 Train Loss 0.015278402139207135 Test Loss 2.9412397268484627 Add Test Loss 0.04304530783021395 Multi Test Loss 5.839434145866711\n",
            "Epoch 1899 Train Loss 0.237168955692582 Test Loss 3.134476629208618 Add Test Loss 0.20374496150986274 Multi Test Loss 6.0652082969073735\n",
            "Epoch 1999 Train Loss 0.018926311891019242 Test Loss 2.8440684982609437 Add Test Loss 0.034849923673857426 Multi Test Loss 5.6532870728480304\n",
            "Epoch 2099 Train Loss 0.01139810506525754 Test Loss 2.790496529818521 Add Test Loss 0.01914012143959549 Multi Test Loss 5.561852938197447\n",
            "Epoch 2199 Train Loss 0.040737054352613516 Test Loss 2.896378226083673 Add Test Loss 0.05076948120511553 Multi Test Loss 5.741986970962231\n",
            "Epoch 2299 Train Loss 0.01699003902134733 Test Loss 2.6945272686723754 Add Test Loss 0.02412496794485993 Multi Test Loss 5.364929569399889\n",
            "Epoch 2399 Train Loss 0.009409330719846332 Test Loss 2.6601576275719534 Add Test Loss 0.01321672266217309 Multi Test Loss 5.307098532481735\n",
            "Epoch 2499 Train Loss 0.025422034492026357 Test Loss 2.648323908947515 Add Test Loss 0.03664223038064145 Multi Test Loss 5.260005587514389\n",
            "Epoch 2599 Train Loss 0.01627852678400649 Test Loss 2.4603928518910254 Add Test Loss 0.021117975757828686 Multi Test Loss 4.899667728024221\n",
            "Epoch 2699 Train Loss 0.008532215215912764 Test Loss 2.406647448056413 Add Test Loss 0.010671729209437915 Multi Test Loss 4.802623166903388\n",
            "Epoch 2799 Train Loss 0.0036291231519131146 Test Loss 2.406851175614199 Add Test Loss 0.004940060145729543 Multi Test Loss 4.808762291082668\n",
            "Epoch 2899 Train Loss 0.022401829436081384 Test Loss 2.264650635417536 Add Test Loss 0.030171401400639376 Multi Test Loss 4.499129869434433\n",
            "Epoch 2999 Train Loss 0.01245004907657316 Test Loss 2.069647259953012 Add Test Loss 0.015642803515517285 Multi Test Loss 4.123651716390506\n",
            "Epoch 3099 Train Loss 0.0074848249559814175 Test Loss 1.9609682216807547 Add Test Loss 0.008434980938619874 Multi Test Loss 3.913501462422889\n",
            "Epoch 3199 Train Loss 0.003438799409594276 Test Loss 1.8888882751728235 Add Test Loss 0.0040102966368198685 Multi Test Loss 3.773766253708828\n",
            "Epoch 3299 Train Loss 0.9842592065147469 Test Loss 2.7012962469848145 Add Test Loss 0.3862854951447887 Multi Test Loss 5.016306998824841\n",
            "Epoch 3399 Train Loss 0.014064287157920165 Test Loss 1.5014769617958514 Add Test Loss 0.014680344694420427 Multi Test Loss 2.9882735788972825\n",
            "Epoch 3499 Train Loss 0.010794531161462537 Test Loss 1.3872966226535326 Add Test Loss 0.010476032183902438 Multi Test Loss 2.764117213123163\n",
            "Epoch 3599 Train Loss 0.005533231577728907 Test Loss 1.26660601560828 Add Test Loss 0.005584823189498859 Multi Test Loss 2.527627208027061\n",
            "Epoch 3699 Train Loss 0.002431948018199024 Test Loss 1.1837190100796644 Add Test Loss 0.0026466730245196224 Multi Test Loss 2.3647913471348088\n",
            "Epoch 3799 Train Loss 0.0010620798282528026 Test Loss 1.1328971715874387 Add Test Loss 0.0012183043065615697 Multi Test Loss 2.2645760388683156\n",
            "Epoch 3899 Train Loss 0.02873343230764509 Test Loss 0.9241407558731577 Add Test Loss 0.031173130820040126 Multi Test Loss 1.8171083809262756\n",
            "Epoch 3999 Train Loss 0.012790116910216977 Test Loss 0.8078854037015689 Add Test Loss 0.01579207322057893 Multi Test Loss 1.5999787341825589\n",
            "Epoch 4099 Train Loss 0.008514643470982268 Test Loss 0.7600083675321332 Add Test Loss 0.00950900335548474 Multi Test Loss 1.5105077317087816\n",
            "Epoch 4199 Train Loss 0.004139589453792056 Test Loss 0.6829804164249507 Add Test Loss 0.004395078659220375 Multi Test Loss 1.361565754190681\n",
            "Epoch 4299 Train Loss 0.001855107889735828 Test Loss 0.6304446543772072 Add Test Loss 0.0019830701695176616 Multi Test Loss 1.2589062385848968\n",
            "Epoch 4399 Train Loss 0.0008278803852085826 Test Loss 0.6120321702764208 Add Test Loss 0.0009226166045597213 Multi Test Loss 1.2231417239482816\n",
            "Epoch 4499 Train Loss 0.0003548103473153383 Test Loss 0.6276874989874458 Add Test Loss 0.000417181990445456 Multi Test Loss 1.2549578159844463\n",
            "Epoch 4599 Train Loss 0.006571085315512406 Test Loss 0.47029413192680014 Add Test Loss 0.0066405259887980786 Multi Test Loss 0.9339477378648023\n",
            "Epoch 4699 Train Loss 0.005998245062903775 Test Loss 0.4420176759249475 Add Test Loss 0.00579708137215893 Multi Test Loss 0.8782382704777362\n",
            "Epoch 4799 Train Loss 0.003921289023940109 Test Loss 0.39415206528284086 Add Test Loss 0.0037602670789550967 Multi Test Loss 0.7845438634867264\n",
            "Epoch 4899 Train Loss 0.0019177616618704092 Test Loss 0.33962873926045845 Add Test Loss 0.001884844653068439 Multi Test Loss 0.6773726338678484\n",
            "Epoch 4999 Train Loss 0.0008504701795256429 Test Loss 0.3034197198021579 Add Test Loss 0.0008708735360578688 Multi Test Loss 0.6059685660682579\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 5000\n",
        "checkpoint_every = 100\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "add_test_losses = []\n",
        "multi_test_losses = []\n",
        "model_checkpoints = []\n",
        "checkpoint_epochs = []\n",
        "if TRAIN_MODEL:\n",
        "    for epoch in tqdm.tqdm(range(num_epochs)):\n",
        "        model.train()\n",
        "        train_logits = model(train_data)\n",
        "        train_loss = loss_fn(train_logits, train_labels)\n",
        "        train_loss.backward()\n",
        "        train_losses.append(train_loss.item())\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        model.eval()\n",
        "        with torch.inference_mode():\n",
        "            # General test loss\n",
        "            test_logits = model(test_data)\n",
        "            test_loss = loss_fn(test_logits, test_labels)\n",
        "            test_losses.append(test_loss.item())\n",
        "\n",
        "            if (epoch+1) % 10 == 0:\n",
        "                # Addition test loss\n",
        "                add_test_logits = model(add_test_data)\n",
        "                add_test_loss = loss_fn(add_test_logits, add_test_labels)\n",
        "                add_test_losses.append(add_test_loss.item())\n",
        "\n",
        "                # Multiplication test loss\n",
        "                multi_test_logits = model(multi_test_data)\n",
        "                multi_test_loss = loss_fn(multi_test_logits, multi_test_labels)\n",
        "                multi_test_losses.append(multi_test_loss.item())\n",
        "\n",
        "        if ((epoch+1)%checkpoint_every)==0:\n",
        "            checkpoint_epochs.append(epoch)\n",
        "            model_checkpoints.append(copy.deepcopy(model.state_dict()))\n",
        "            print(f\"Epoch {epoch} Train Loss {train_loss.item()} Test Loss {test_loss.item()} Add Test Loss {add_test_loss.item()} Multi Test Loss {multi_test_loss.item()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "UrvOo2Qs2UV7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "len(train_losses) = 5000 len(test_losses) = 5000 len(model_checkpoints) = 50\n"
          ]
        }
      ],
      "source": [
        "PTH_LOCATION = \"../saves/grokking_add_multi_0.7.pth\"\n",
        "if TRAIN_MODEL:\n",
        "    # Create the directory if it does not exist\n",
        "    os.makedirs(Path(PTH_LOCATION).parent, exist_ok=True)\n",
        "    \n",
        "    print(f\"len(train_losses) = {len(train_losses)} len(test_losses) = {len(test_losses)} len(model_checkpoints) = {len(model_checkpoints)}\")\n",
        "    torch.save(\n",
        "        {\n",
        "            \"model\":model.state_dict(),\n",
        "            \"config\": model.cfg,\n",
        "            \"checkpoints\": model_checkpoints,\n",
        "            \"checkpoint_epochs\": checkpoint_epochs,\n",
        "            \"test_losses\": test_losses,\n",
        "            \"train_losses\": train_losses,\n",
        "            \"add_test_losses\": add_test_losses,\n",
        "            \"multi_test_losses\": multi_test_losses,\n",
        "            \"max_nums\": max_nums,\n",
        "            \"mod_value\": mod_value,\n",
        "            \"train_frac\": train_frac,\n",
        "            \"addition_frac\": addition_frac,\n",
        "        },\n",
        "        PTH_LOCATION)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "tx5DVueg2UV7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "len(train_losses) = 4000 len(test_losses) = 4000 len(model_checkpoints) = 40\n"
          ]
        }
      ],
      "source": [
        "LOAD_LOCATION = \"../saves/grokking_add_multi_0.7.pth\"\n",
        "if not TRAIN_MODEL:\n",
        "    cached_data = torch.load(LOAD_LOCATION, weights_only=False)\n",
        "    model.load_state_dict(cached_data['model'])\n",
        "    model_checkpoints = cached_data[\"checkpoints\"]\n",
        "    checkpoint_epochs = cached_data[\"checkpoint_epochs\"]\n",
        "    test_losses = cached_data['test_losses']\n",
        "    train_losses = cached_data['train_losses']\n",
        "    add_test_losses = cached_data['add_test_losses']\n",
        "    multi_test_losses = cached_data['multi_test_losses']\n",
        "    max_nums = cached_data['max_nums']\n",
        "    mod_value = cached_data['mod_value']\n",
        "    train_frac = cached_data['train_frac']\n",
        "    addition_frac = cached_data['addition_frac']\n",
        "    print(f\"len(train_losses) = {len(train_losses)} len(test_losses) = {len(test_losses)} len(model_checkpoints) = {len(model_checkpoints)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test_loss = 0.000318961571838122\n"
          ]
        }
      ],
      "source": [
        "test_logits = model(test_data)\n",
        "test_loss = loss_fn(test_logits, test_labels)\n",
        "print(f\"test_loss = {test_loss}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHA9-QD52UV7"
      },
      "source": [
        "## Show Model Training Statistics, Check that it groks!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "mHu_Yz8i2UV7",
        "outputId": "ff53e647-20f1-4a7d-8dae-f680164305f0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>                            <div id=\"5a134d09-a649-4c06-9b5d-4eaa2217d273\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"5a134d09-a649-4c06-9b5d-4eaa2217d273\")) {                    Plotly.newPlot(                        \"5a134d09-a649-4c06-9b5d-4eaa2217d273\",                        [{\"hovertemplate\":\"Color=train\\u003cbr\\u003eEpoch=%{x}\\u003cbr\\u003eLoss=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"0\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"train\",\"showlegend\":true,\"x\":[0,10,20,30,40,50,60,70,80,90,100,110,120,130,140,150,160,170,180,190,200,210,220,230,240,250,260,270,280,290,300,310,320,330,340,350,360,370,380,390,400,410,420,430,440,450,460,470,480,490,500,510,520,530,540,550,560,570,580,590,600,610,620,630,640,650,660,670,680,690,700,710,720,730,740,750,760,770,780,790,800,810,820,830,840,850,860,870,880,890,900,910,920,930,940,950,960,970,980,990,1000,1010,1020,1030,1040,1050,1060,1070,1080,1090,1100,1110,1120,1130,1140,1150,1160,1170,1180,1190,1200,1210,1220,1230,1240,1250,1260,1270,1280,1290,1300,1310,1320,1330,1340,1350,1360,1370,1380,1390,1400,1410,1420,1430,1440,1450,1460,1470,1480,1490,1500,1510,1520,1530,1540,1550,1560,1570,1580,1590,1600,1610,1620,1630,1640,1650,1660,1670,1680,1690,1700,1710,1720,1730,1740,1750,1760,1770,1780,1790,1800,1810,1820,1830,1840,1850,1860,1870,1880,1890,1900,1910,1920,1930,1940,1950,1960,1970,1980,1990,2000,2010,2020,2030,2040,2050,2060,2070,2080,2090,2100,2110,2120,2130,2140,2150,2160,2170,2180,2190,2200,2210,2220,2230,2240,2250,2260,2270,2280,2290,2300,2310,2320,2330,2340,2350,2360,2370,2380,2390,2400,2410,2420,2430,2440,2450,2460,2470,2480,2490,2500,2510,2520,2530,2540,2550,2560,2570,2580,2590,2600,2610,2620,2630,2640,2650,2660,2670,2680,2690,2700,2710,2720,2730,2740,2750,2760,2770,2780,2790,2800,2810,2820,2830,2840,2850,2860,2870,2880,2890,2900,2910,2920,2930,2940,2950,2960,2970,2980,2990,3000,3010,3020,3030,3040,3050,3060,3070,3080,3090,3100,3110,3120,3130,3140,3150,3160,3170,3180,3190,3200,3210,3220,3230,3240,3250,3260,3270,3280,3290,3300,3310,3320,3330,3340,3350,3360,3370,3380,3390,3400,3410,3420,3430,3440,3450,3460,3470,3480,3490,3500,3510,3520,3530,3540,3550,3560,3570,3580,3590,3600,3610,3620,3630,3640,3650,3660,3670,3680,3690,3700,3710,3720,3730,3740,3750,3760,3770,3780,3790,3800,3810,3820,3830,3840,3850,3860,3870,3880,3890,3900,3910,3920,3930,3940,3950,3960,3970,3980,3990,4000,4010,4020,4030,4040,4050,4060,4070,4080,4090,4100,4110,4120,4130,4140,4150,4160,4170,4180,4190,4200,4210,4220,4230,4240,4250,4260,4270,4280,4290,4300,4310,4320,4330,4340,4350,4360,4370,4380,4390,4400,4410,4420,4430,4440,4450,4460,4470,4480,4490,4500,4510,4520,4530,4540,4550,4560,4570,4580,4590,4600,4610,4620,4630,4640,4650,4660,4670,4680,4690,4700,4710,4720,4730,4740,4750,4760,4770,4780,4790,4800,4810,4820,4830,4840,4850,4860,4870,4880,4890,4900,4910,4920,4930,4940,4950,4960,4970,4980,4990],\"xaxis\":\"x\",\"y\":[5.046054775218921,4.701941728606955,4.655276113553953,4.588210968214286,4.454214097662265,4.253911502369257,3.967448342203477,3.592933942212994,3.157284283182121,2.715970223997908,2.2849257257766125,1.9198795525872903,1.60121488070511,1.3306882380630907,1.089488047379832,0.8893881925722463,0.7242772202250342,0.5842427941182871,0.47465638465610094,0.3777326581865567,0.3089416636455519,0.2488704040139109,0.20406126525542845,0.16862431675047407,0.14204114952192098,0.12046656260787626,0.10382529388521364,0.089338741363381,0.07807475059239868,0.06832601459837871,0.06065161948250773,0.05388058683463623,0.048420962366214244,0.04281309464060682,0.03866359842568834,0.03496574889068877,0.03165329632519238,0.028527455390712542,0.02628216026841411,0.023365008329737893,0.0213722766822992,0.0195272613285816,0.017821763487953134,0.01603480729917671,0.015407246142064207,0.01351622617532725,0.012243405058825341,0.02355563115452566,0.05945581437562614,0.030379186851666948,0.01881611157588902,0.01439742969669679,0.012737786087723278,0.012137014378372406,0.011911055384020942,0.011771134037703183,0.011603517004414605,0.011357132310153093,0.01102195329376736,0.010605854582882355,0.010125166321021369,0.009600801684410621,0.00905097684908693,0.008491756546168582,0.007933810724700877,0.007392652596009782,0.006866243068937117,0.006364246160591283,0.005902612520097659,0.005436109464378639,0.005030278304284559,0.004663689779839909,0.004282794468118025,0.003911121953639037,0.0035939078936290396,0.0033343587783391045,0.003111830113186112,0.0028401236749696266,0.002676183536123356,0.0023484006073293605,0.002218567149438201,0.0020073707441720734,0.45176654826824136,0.23828888212888483,0.06409333413423672,0.027901131970142972,0.01698732737553644,0.012955196245357762,0.011604012001032058,0.011281183021368683,0.011396445330371027,0.011671355959269446,0.01196652537685159,0.012218717398516906,0.012394467282193853,0.012476746341866624,0.012454752686871972,0.012328732957420976,0.012106341265459565,0.011800140287643947,0.011418884138881152,0.010977436140181115,0.010491217781616931,0.00997171465519525,0.009437676225307558,0.008901076364695264,0.008373501440069311,0.007812964076924335,0.007312694661291316,0.006893266992618385,0.006511755754701881,0.006073345160599205,0.005570673869531891,0.006089163527181777,0.2912495658352796,0.08568888568117973,0.03687654694862339,0.022332648393015162,0.016585443390666223,0.01455726894601461,0.013823257614048916,0.013630356872976812,0.013604180330916557,0.013600648514142648,0.013543155710254289,0.013404559512557706,0.01317241218967048,0.012850845630708657,0.01244749047710621,0.011976143945515083,0.011459805078906291,0.010899940105168518,0.01033209729366301,0.009733915087124425,0.009199066106260697,0.008732524106714788,0.008304070561650037,0.0075878287750656215,0.025522160502113752,0.55849199841483,0.17744156895615562,0.06854767189935605,0.03780635199633979,0.0266133942553812,0.02213383983505235,0.020278466872489142,0.019460285063786005,0.019045079948233606,0.018746731793988804,0.018432366675120514,0.018053771926797697,0.017590127772673197,0.01704511108696444,0.016430729252325377,0.015755141345219346,0.015040397608218405,0.014311133489410143,0.01353034870423945,0.012767576588228625,0.012095573015888173,0.011525835391275977,0.010884781825380649,0.010875896851210654,0.904537670876388,0.28069263613283124,0.1025572630347315,0.050713771457111055,0.03299796470236744,0.02595290081531399,0.02294954839512803,0.02159392870256054,0.020885178102776573,0.02039885454018695,0.01994875860871033,0.019456793128810598,0.018892173320111384,0.01825449400372641,0.017546845709615407,0.016796028666453477,0.015990024318367598,0.015209377419286628,0.014288402184828752,0.013469383207437518,0.012850682719734139,0.01180987277873774,0.011325541813485291,0.010736070669477538,0.009572209032231455,0.03995552390803857,0.6841631553705395,0.21365877672958836,0.08527128981420651,0.043793546263905095,0.029805722827213423,0.024119601249711083,0.021725879779445983,0.02067600986606315,0.020122650201291416,0.0197323927314098,0.019336147810193566,0.018876809292494735,0.018333642520330234,0.017708548685865386,0.0170121686797563,0.01625779132142482,0.015456785234795052,0.014626773154299822,0.013811779911915565,0.012952164989454678,0.012092423339563568,0.011283769271420985,0.010534081846090077,0.009753620669969173,0.009068654714870098,0.00842252940240674,0.007776579388859259,2.4159409438173856,0.5518729065432418,0.1821948987125251,0.0724156176663384,0.0387819629184371,0.02727853364951932,0.02252395195547171,0.020564210656766675,0.019697305275750455,0.019236616008949492,0.018888990276588694,0.018519946453796496,0.018072485661582788,0.017538031411453638,0.01692541417268329,0.016243657508161126,0.015500227205487088,0.014725850563046046,0.0139364642945984,0.013119042015139653,0.012315306875327087,0.011524996548258514,0.010764315332018534,0.009959360773112354,0.009330823125392108,0.008595828265818003,0.008148158702523807,0.007264558085817146,0.007209454980531126,1.1023758609450658,0.3348080585829493,0.11572780628149013,0.052856277631631005,0.03258247983795022,0.024931455663648985,0.021791436612920174,0.020461523181136303,0.019838096368542328,0.019453808082786316,0.019093213093062826,0.018678383848279197,0.01818189065323018,0.01759835755918901,0.01693396022882501,0.016202907496420293,0.015430759975874208,0.01462216352349392,0.013789519839641292,0.012972428943339115,0.012135523738430612,0.011347931143337028,0.010578147124299742,0.009823168933797451,0.009069525945983928,0.008456405367962523,0.007864476687189193,0.007119921662495506,0.006671432417925641,0.006071547712751357,0.005630465512952261,0.005195368956032366,0.0047006592774185944,0.0046712574689594276,0.003973456461083148,0.0035855474286255727,0.0036746713695061483,0.0031199795605326,0.0028095113940034434,0.002582566559000348,0.0024540410678956007,0.9560118553743866,0.2425415812121404,0.08086307677839175,0.03548619452991699,0.02148179551585971,0.016382279992394697,0.014448503163318242,0.013721432341939215,0.013473807903739242,0.013386860830172735,0.013309810286350835,0.013189636277744585,0.01300199981824745,0.012740196053452071,0.012414951622017409,0.012035786800466011,0.011608650951232589,0.011139552577222824,0.010640383816142612,0.010117590269780251,0.009580754500942673,0.009035671560654,0.008490253591676319,0.007960665084887882,0.007432454862195295,0.006925349874280464,0.006441579324173025,0.005970374740423386,0.00554473158105121,0.005121042257173824,0.004707727082038006,0.004361109168235285,0.004045368870184272,0.0037019111888097647,0.0034055516544522677,0.0031351453715069036,0.0029305607707971024,0.002646176546378494,0.0024393522968244315,0.00226165049881969,0.0020575588498355844,0.0019000595820544905,0.001763623733076035,0.0018859101326020034,0.8332969277172859,0.2131642560938036,0.0797791228377622,0.03587455906778694,0.022447715496669452,0.017152821482974086,0.01521019920396723,0.014450980146883967,0.014198680906844575,0.014113045482173367,0.014057686841759924,0.013971569907858668,0.013834759853627518,0.013637493107267395,0.013379520138288439,0.013060194062300036,0.01268310419392578,0.012254959488858384,0.011782373817677442,0.011274413767364901,0.010740253762056468,0.010186609637568978,0.009620856159348594,0.00905462854007974,0.008491961708124215,0.007940955264117224,0.0074101488461079815,0.0068889725386794,0.006405289752355731,0.005926918267008987,0.005488622530343703,0.005064953071435504,0.004686433602242114,0.004311749469786666,0.003974056565303411,0.003683021132588297,0.003375610534163529,0.003102402991876895,0.002858798987049095,0.0026503960237809023,0.002414929774208667,0.0022263507261244962,0.002055958982036078,0.001883528968715558,0.0017434483607750518,0.0016104424587161617,0.0014712268968385366,0.0013985524456641887,0.001243125300488298,0.0011591235141894397,0.0010482444414389568,0.000989976778384299,0.0008904564822939956,0.0008201150538386106,0.0007560075403852289,0.0006919293502741742,0.0011795580894482854,0.5836210026626655,0.14533982808521487,0.05247541881215464,0.027131830541411606,0.018391457175750504,0.014980068886122785,0.013714985797534869,0.013286003184235352,0.013172723777552867,0.013158700212231445,0.013136004914606418,0.01307197987817468,0.012950868423256294,0.012769218061654243,0.012526917627594697,0.012226428548369724,0.011870652122206836,0.011466482943928609,0.011021411949721194,0.010543122387081147,0.010040069984116355,0.009520833472025534,0.008992520288735631,0.00846116130536142,0.007939729849267248,0.007429495806463507,0.006944539481713854,0.006470997611076677,0.006030668886044819,0.005596243609463375,0.005203492476143358,0.004817414598520356,0.004444165632747299,0.004114977400118627,0.0038116293318561653,0.003508834166688971,0.0032353334626389566,0.00297044369480596,0.002748153050986695,0.0025432421874995326,0.002325196518902824,0.0021523741525676936,0.0019874102781485426,0.0018458438993052264,0.00167417162485384,0.0015446551217468138,0.0014327375833203752,0.0013236767759156906,0.0012172188459903311,0.0011885625763809727,0.0010344778540103794,0.0009391374481689117,0.0009223207650789551,0.0008178175280557241,0.0007408578739743232,0.0007005176261422141,0.0006326181953224664,0.0006092848127762124,0.0005351483508507912,0.0005202456216346492,0.0004610922268107912,0.0004794051525714429,0.0003909948894748486,0.0003536879820392586,0.0003300696955041893,0.0003183735578114978,1.003038181729588,0.1680293799293482,0.04770250143763953,0.019350499297449406,0.011050729823772748,0.008032678659275757,0.00692150637776806,0.0065532193697904655,0.006480359784001255,0.006496699825128598,0.006520405070799349,0.006515633047841509,0.006481960985078752,0.00642181918440843,0.006338307435872298,0.006236246479114156,0.006118112165176192,0.005984119633185479,0.005833578854586082,0.005667029748050401,0.005482337586150172,0.0052805570731550636,0.005065855421327932,0.004841877728740362,0.0046101328344470074,0.004373749870593361,0.004135290257511046,0.0038976004249649606,0.0036630172541187076,0.0034329092585952525,0.003208874415262756,0.002993160372354801,0.0027869203263915622,0.0025890359762027037,0.0024031780210152652,0.002225871027581367,0.0020599271482106335,0.0019030086508406644,0.0017616893110691393,0.00162101459742957,0.0015001252860640673,0.001381271556137959,0.0012704752530112527,0.0011731163979572903,0.0010859315695170351,0.0009995319737721668,0.0009171831051653694],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"hovertemplate\":\"Color=test\\u003cbr\\u003eEpoch=%{x}\\u003cbr\\u003eLoss=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"1\",\"line\":{\"color\":\"#EF553B\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"test\",\"showlegend\":true,\"x\":[0,10,20,30,40,50,60,70,80,90,100,110,120,130,140,150,160,170,180,190,200,210,220,230,240,250,260,270,280,290,300,310,320,330,340,350,360,370,380,390,400,410,420,430,440,450,460,470,480,490,500,510,520,530,540,550,560,570,580,590,600,610,620,630,640,650,660,670,680,690,700,710,720,730,740,750,760,770,780,790,800,810,820,830,840,850,860,870,880,890,900,910,920,930,940,950,960,970,980,990,1000,1010,1020,1030,1040,1050,1060,1070,1080,1090,1100,1110,1120,1130,1140,1150,1160,1170,1180,1190,1200,1210,1220,1230,1240,1250,1260,1270,1280,1290,1300,1310,1320,1330,1340,1350,1360,1370,1380,1390,1400,1410,1420,1430,1440,1450,1460,1470,1480,1490,1500,1510,1520,1530,1540,1550,1560,1570,1580,1590,1600,1610,1620,1630,1640,1650,1660,1670,1680,1690,1700,1710,1720,1730,1740,1750,1760,1770,1780,1790,1800,1810,1820,1830,1840,1850,1860,1870,1880,1890,1900,1910,1920,1930,1940,1950,1960,1970,1980,1990,2000,2010,2020,2030,2040,2050,2060,2070,2080,2090,2100,2110,2120,2130,2140,2150,2160,2170,2180,2190,2200,2210,2220,2230,2240,2250,2260,2270,2280,2290,2300,2310,2320,2330,2340,2350,2360,2370,2380,2390,2400,2410,2420,2430,2440,2450,2460,2470,2480,2490,2500,2510,2520,2530,2540,2550,2560,2570,2580,2590,2600,2610,2620,2630,2640,2650,2660,2670,2680,2690,2700,2710,2720,2730,2740,2750,2760,2770,2780,2790,2800,2810,2820,2830,2840,2850,2860,2870,2880,2890,2900,2910,2920,2930,2940,2950,2960,2970,2980,2990,3000,3010,3020,3030,3040,3050,3060,3070,3080,3090,3100,3110,3120,3130,3140,3150,3160,3170,3180,3190,3200,3210,3220,3230,3240,3250,3260,3270,3280,3290,3300,3310,3320,3330,3340,3350,3360,3370,3380,3390,3400,3410,3420,3430,3440,3450,3460,3470,3480,3490,3500,3510,3520,3530,3540,3550,3560,3570,3580,3590,3600,3610,3620,3630,3640,3650,3660,3670,3680,3690,3700,3710,3720,3730,3740,3750,3760,3770,3780,3790,3800,3810,3820,3830,3840,3850,3860,3870,3880,3890,3900,3910,3920,3930,3940,3950,3960,3970,3980,3990,4000,4010,4020,4030,4040,4050,4060,4070,4080,4090,4100,4110,4120,4130,4140,4150,4160,4170,4180,4190,4200,4210,4220,4230,4240,4250,4260,4270,4280,4290,4300,4310,4320,4330,4340,4350,4360,4370,4380,4390,4400,4410,4420,4430,4440,4450,4460,4470,4480,4490,4500,4510,4520,4530,4540,4550,4560,4570,4580,4590,4600,4610,4620,4630,4640,4650,4660,4670,4680,4690,4700,4710,4720,4730,4740,4750,4760,4770,4780,4790,4800,4810,4820,4830,4840,4850,4860,4870,4880,4890,4900,4910,4920,4930,4940,4950,4960,4970,4980,4990],\"xaxis\":\"x\",\"y\":[4.903952655034201,4.729077263974157,4.718740880485145,4.8185480420290885,4.937145497538741,4.995294792856148,5.023538191339242,5.007484003093777,4.914497898411238,4.785087239471139,4.6685192620678935,4.591539383596442,4.530982423718286,4.498051006092669,4.4796764289174495,4.47897425106623,4.485110477693247,4.498160186830786,4.517168018631423,4.529205569291537,4.553752887353214,4.570379855699995,4.587423892346031,4.605593157451217,4.620201741241783,4.630721245791406,4.642542229555175,4.648441574145253,4.648459975364694,4.650281663097238,4.652804521571386,4.652695144526787,4.654278469694451,4.649695879400307,4.65169425344768,4.653103057639093,4.645292189775785,4.644792967884698,4.639802614037798,4.635197833935403,4.635310854641796,4.635224760678697,4.63036140932899,4.627333855207371,4.631157299806619,4.624433435954029,4.622749944050467,4.903165417425409,4.777275702150032,4.654614154435506,4.616364308191096,4.604580548283796,4.59399507268698,4.586529915641198,4.579808800865142,4.576305443915179,4.574890592706495,4.57682778019497,4.581109493124753,4.588165312707366,4.597127372527153,4.607679922702581,4.618744323568305,4.630620317310822,4.643388966856108,4.656220832539921,4.668269246799457,4.679524230145942,4.692190681712627,4.702790755391048,4.71111418301733,4.723563590962233,4.729223468678995,4.737134149316252,4.745641075880798,4.748541471111691,4.760216402236211,4.757686298741441,4.768320356566364,4.768864219025985,4.76624550715892,4.770175485883443,5.883977447997656,4.634552490575685,4.608316129523514,4.5091093773486195,4.433646374598974,4.391687625282901,4.346167927515012,4.306346817362321,4.2656230524962195,4.23120894513823,4.200060312012578,4.171753018678515,4.145371527826701,4.122160799116078,4.101611020962603,4.083189212811973,4.066498315382953,4.052557650723147,4.040698243232106,4.029953685810871,4.020343480118563,4.0115300279343655,4.004368629674631,3.998490033084611,3.9897757500461988,3.983739406931449,3.9834874294539553,3.97091678940817,3.97895527507941,3.9616849503208953,3.9629303401718547,3.988692131342793,4.074617552807279,3.907539499419315,3.842188773684304,3.807919989889793,3.7567683585831153,3.7237820363876404,3.6981613211937514,3.6723324520269536,3.6473662269472857,3.625470282762151,3.604507899536043,3.5853388575092717,3.567863360523148,3.5521459887766573,3.538539788025256,3.5262480178955844,3.515992381909412,3.5069765607821144,3.4985992253737046,3.491583461194079,3.487652152384942,3.480298623605542,3.4817171624644923,3.4746268241435034,4.725271643341401,3.685883296362286,3.535960152145358,3.4698310200432063,3.4287373714461253,3.3856683549216284,3.3582671226989738,3.3354469260813517,3.3088883635879034,3.285523467567933,3.263400961660237,3.2440844266518476,3.2270785292809014,3.211085450505552,3.1968799758447766,3.184667548244568,3.174499986329868,3.164813043263006,3.1578891270456935,3.152021034616329,3.146129351457977,3.1447002091029526,3.1386949911051456,3.1397133725880657,3.1524831699133014,3.3808548764049093,3.3107558419340326,3.218927782035678,3.180486667502497,3.1502150540407388,3.126306751858329,3.1069524307295957,3.0819414587949536,3.0588704928296204,3.039140806404206,3.019732890503145,3.002508638673107,2.987817119111045,2.974624964962949,2.9639288251605205,2.9538654932413158,2.9462573127281004,2.9388694256556143,2.93486844799433,2.93378048895413,2.9343508165377994,2.931980760339313,2.930942347268994,2.9384006810459367,2.9397325100360736,3.999834688496904,3.288130734226857,3.124236891367626,3.0366352478549516,3.0130866265642027,2.9840341468591243,2.963177039613603,2.9380042301377607,2.9172489468968457,2.895268316465955,2.8758654887033934,2.858782547721491,2.8424411058033012,2.828629115691118,2.8173328158515174,2.8079525307492683,2.800704332898182,2.7949439691515066,2.7905435791099698,2.7898977839405625,2.788804264655196,2.789077593065432,2.7919110124892073,2.7911385498995056,2.7992146858705036,2.799800394741348,2.808616260417953,2.8106332281144475,4.442186985660173,3.1362114574272155,2.986288328637168,2.928408626233867,2.8923221805318713,2.8685872035023383,2.838459329668021,2.8165020627972877,2.7951073382846636,2.773763417357551,2.753429824517767,2.735324215909719,2.718747176833739,2.7049479838905057,2.693370942211216,2.6832864613832514,2.674358434822749,2.6671120840438944,2.662486538465775,2.6589432176104753,2.6559590900546324,2.65509284180119,2.655309918766443,2.657087423957631,2.6563863269303574,2.65906193519016,2.664816558547252,2.6676606740575752,2.685318363256806,3.3212374055155727,2.942955138258468,2.8019254108727356,2.7191443390067698,2.6754583105683305,2.6460980350772845,2.6194141141569944,2.5967592139685762,2.5739548010684272,2.5528219508318974,2.533003328122179,2.515291920916658,2.499017081426271,2.4838758782265713,2.470809872060588,2.4590988233362454,2.448937362457809,2.4409187569026245,2.4326689032721434,2.425852894497338,2.420036364760948,2.417516525053611,2.4116943443381973,2.4096316786821594,2.4080677435552276,2.404606060018684,2.4021685038296385,2.4020224827047687,2.403897420793461,2.4026477426725856,2.401983098485425,2.4078432293412777,2.4045589383806005,2.4174924064054517,2.4088547716255047,2.4101801517571046,2.415427627996051,2.4139310526536963,2.4134785131319365,2.4191340414880935,2.4228210267576795,3.2858965234208575,2.6011750203990216,2.391119521534025,2.317789361046421,2.2617439677019884,2.2324260165407814,2.207892495247306,2.18655636946042,2.1669481931716463,2.148942467047398,2.1308292884925186,2.1140264325206326,2.0982806004215244,2.0830996387031866,2.0683433651534444,2.055389265308156,2.0426265338402345,2.0303131874400013,2.0186971926031343,2.007883756389353,1.9973508480283362,1.986748178228874,1.9778425001472788,1.9692918443596041,1.9603028163072151,1.9510718090717818,1.9430435781266315,1.9357843133058,1.9268413300003182,1.9195157137617667,1.9134933999859227,1.9059260446538961,1.9023322683515236,1.893743053449384,1.8893309655922614,1.8847694163351556,1.8778546605844535,1.8739679842811745,1.869929453621817,1.8657234321848006,1.8603344583372032,1.8577043371103612,1.8571098797444856,1.9051016082131902,2.5368818375726447,1.9590640940708794,1.7290974021456107,1.6335094147808622,1.5913151960589862,1.55948981334231,1.5405747303758082,1.528637645673877,1.5195900359444303,1.5097941034522455,1.5005116682720225,1.4906885197471234,1.4808013140302474,1.4701653789914249,1.459009073131499,1.4472688899083166,1.4354552068532214,1.4234578480424553,1.411257597851258,1.3986243904285431,1.3859277494259912,1.3728729229578065,1.360474489618638,1.347967257682577,1.334923916873007,1.3228791541830114,1.3120462596436582,1.3004217133345097,1.2880129418612527,1.276414370389467,1.2666330955269702,1.2566598953595634,1.244955642965258,1.2365967645571192,1.2272409063196548,1.2208537105789194,1.2105013992774452,1.20309997575095,1.198410983107199,1.188304479314316,1.1815156864130452,1.177728300076814,1.1693787161355522,1.1652041484146733,1.159868612291939,1.1504002456465952,1.1481073423862176,1.1422240073613679,1.139508980764609,1.1330520573452296,1.130064144655762,1.1328822132012368,1.1271095239513818,1.122247770090126,1.1214265405544648,1.1186577572719592,1.7455122198781527,1.8437149300925892,1.2584684636667705,1.032320922922124,0.916230092328429,0.8662872114021899,0.8377515435880472,0.8260047183238007,0.8206385088619605,0.8180399743512056,0.8157095207225624,0.8140895589876396,0.8123091342104093,0.8100185631386171,0.8076049617082536,0.8044378288068247,0.8011436880758168,0.7976800864663178,0.7936017881324517,0.7891530666041171,0.7847374573373189,0.7791601095523255,0.7733303143385362,0.7667822072718063,0.7592209534730222,0.7516162465990239,0.7442338318290523,0.7367031769152401,0.728967264224813,0.7208797991964906,0.7129386462793769,0.7053791980763355,0.6970967674612097,0.689248439481815,0.6832919332836449,0.6759406216347319,0.6700361049520391,0.6623084574179322,0.6567040474444726,0.6524474522353617,0.6460821890733269,0.6419287227549318,0.6397995553607342,0.633179601097961,0.6318748121175326,0.6264369559089272,0.6228713485200552,0.6223096981177717,0.6185236939589623,0.6179414537019112,0.6142420187039506,0.6128141135668518,0.6133282376593222,0.6249785663438173,0.6105553793179272,0.6129407057113819,0.6174474519008377,0.6159879447641281,0.6190278421809184,0.6195438505391185,0.6295846275748912,0.6230716645810637,0.6252299830311626,0.6237342379214728,0.6307372160875782,0.6334517658742301,0.6408531317636056,2.907217623928834,1.043279903979839,0.7509354282813654,0.6072174846980677,0.5351151541435224,0.496264921499422,0.4775029608619995,0.46951176296980274,0.46472851270591187,0.4623643875778911,0.45981215167746026,0.45686892196996814,0.4547180841230869,0.45219764000635054,0.44960143177566547,0.44700198641115974,0.44441583367263826,0.44172102524233775,0.43835584051372356,0.43478403996987325,0.4308375802910469,0.426638759642077,0.4220503352129887,0.4168449135535361,0.4115510620371697,0.405723627707981,0.39987272462268497,0.39350949953658654,0.38731548620238526,0.3812697946375647,0.37575421340072473,0.3696154751336152,0.3635577350433439,0.35803863908417644,0.35327783212971386,0.34877391904935384,0.34337757849744227,0.33844524512951374,0.3355260706398109,0.3307544170287626,0.32576344644831245,0.32333686996769373,0.3191480637492003,0.3146604873333861,0.3138543709913814,0.30821718508076645,0.30618565174115264],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"hovertemplate\":\"Color=add loss\\u003cbr\\u003eEpoch=%{x}\\u003cbr\\u003eLoss=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"2\",\"line\":{\"color\":\"#00cc96\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"add loss\",\"showlegend\":true,\"x\":[0,10,20,30,40,50,60,70,80,90,100,110,120,130,140,150,160,170,180,190,200,210,220,230,240,250,260,270,280,290,300,310,320,330,340,350,360,370,380,390,400,410,420,430,440,450,460,470,480,490,500,510,520,530,540,550,560,570,580,590,600,610,620,630,640,650,660,670,680,690,700,710,720,730,740,750,760,770,780,790,800,810,820,830,840,850,860,870,880,890,900,910,920,930,940,950,960,970,980,990,1000,1010,1020,1030,1040,1050,1060,1070,1080,1090,1100,1110,1120,1130,1140,1150,1160,1170,1180,1190,1200,1210,1220,1230,1240,1250,1260,1270,1280,1290,1300,1310,1320,1330,1340,1350,1360,1370,1380,1390,1400,1410,1420,1430,1440,1450,1460,1470,1480,1490,1500,1510,1520,1530,1540,1550,1560,1570,1580,1590,1600,1610,1620,1630,1640,1650,1660,1670,1680,1690,1700,1710,1720,1730,1740,1750,1760,1770,1780,1790,1800,1810,1820,1830,1840,1850,1860,1870,1880,1890,1900,1910,1920,1930,1940,1950,1960,1970,1980,1990,2000,2010,2020,2030,2040,2050,2060,2070,2080,2090,2100,2110,2120,2130,2140,2150,2160,2170,2180,2190,2200,2210,2220,2230,2240,2250,2260,2270,2280,2290,2300,2310,2320,2330,2340,2350,2360,2370,2380,2390,2400,2410,2420,2430,2440,2450,2460,2470,2480,2490,2500,2510,2520,2530,2540,2550,2560,2570,2580,2590,2600,2610,2620,2630,2640,2650,2660,2670,2680,2690,2700,2710,2720,2730,2740,2750,2760,2770,2780,2790,2800,2810,2820,2830,2840,2850,2860,2870,2880,2890,2900,2910,2920,2930,2940,2950,2960,2970,2980,2990,3000,3010,3020,3030,3040,3050,3060,3070,3080,3090,3100,3110,3120,3130,3140,3150,3160,3170,3180,3190,3200,3210,3220,3230,3240,3250,3260,3270,3280,3290,3300,3310,3320,3330,3340,3350,3360,3370,3380,3390,3400,3410,3420,3430,3440,3450,3460,3470,3480,3490,3500,3510,3520,3530,3540,3550,3560,3570,3580,3590,3600,3610,3620,3630,3640,3650,3660,3670,3680,3690,3700,3710,3720,3730,3740,3750,3760,3770,3780,3790,3800,3810,3820,3830,3840,3850,3860,3870,3880,3890,3900,3910,3920,3930,3940,3950,3960,3970,3980,3990,4000,4010,4020,4030,4040,4050,4060,4070,4080,4090,4100,4110,4120,4130,4140,4150,4160,4170,4180,4190,4200,4210,4220,4230,4240,4250,4260,4270,4280,4290,4300,4310,4320,4330,4340,4350,4360,4370,4380,4390,4400,4410,4420,4430,4440,4450,4460,4470,4480,4490,4500,4510,4520,4530,4540,4550,4560,4570,4580,4590,4600,4610,4620,4630,4640,4650,4660,4670,4680,4690,4700,4710,4720,4730,4740,4750,4760,4770,4780,4790,4800,4810,4820,4830,4840,4850,4860,4870,4880,4890,4900,4910,4920,4930,4940,4950,4960,4970,4980,4990],\"xaxis\":\"x\",\"y\":[4.753764206627752,4.770117105970807,4.818922728184628,4.891195981592336,4.969073182376873,4.999749793987521,4.957830315223992,4.7560401866297735,4.417548326619542,4.069230493292609,3.796657684086978,3.5893962672845126,3.425203542023789,3.292909409121357,3.1797622788354,3.096231891611541,3.022807030001137,2.9619782484168344,2.8958305590864524,2.848536382936925,2.7964210390479045,2.750387980192066,2.704205006121389,2.662941661112203,2.624411278097519,2.5829388606477433,2.5443310530715584,2.5063764806494575,2.4649261659398314,2.4287113748556486,2.393762548013648,2.354311491872954,2.317741997164109,2.2825095689718444,2.2472748578594284,2.212875727474509,2.1785123966651714,2.1462110638752474,2.1097253236727225,2.076342635387659,2.047255934993789,2.0150907723832128,1.9812939782879597,1.956944968253968,1.9213332366579126,1.8875711843325627,1.9343970268772934,2.155506349327478,1.8743655743657426,1.7909188069739796,1.7668217048723076,1.7429389362027767,1.7368980962564777,1.7281074444011568,1.7237613056843906,1.7173376591071219,1.7103557654896706,1.7022608022721013,1.6931853599817666,1.682979258270012,1.6721282284997467,1.6599584644231016,1.647556630303802,1.6340892454988618,1.6195917953039751,1.6053302723221599,1.5893116233614466,1.571670180436961,1.5537799252882418,1.5351547716374576,1.514426220065172,1.4938756767997372,1.469628751098227,1.4458507414609476,1.4232619505690216,1.3954756110411117,1.371126589182898,1.3418231442996078,1.3108725536368877,1.2888520676802346,1.2534133328686916,2.0926047311487324,1.534031403667631,1.2228042642944161,1.1058502462552988,1.03058107621686,0.9934702979261001,0.973366015081618,0.9647277493026997,0.956046050673977,0.9526836815833766,0.9498815588489213,0.9466801869637023,0.942367846208633,0.9370640685578896,0.9297820477176845,0.9206179609344188,0.908855151176205,0.8951853460098391,0.8804770094552105,0.8639123303522026,0.8453323046897935,0.8259116161359862,0.8051923759414178,0.7840651162977281,0.7625041988094063,0.7384249257652072,0.7137899214320466,0.6920653333935807,0.6655689845165699,0.6438964122452723,0.615675305324883,0.598394352262218,1.040322131729548,0.6765499099696104,0.5493409174654998,0.492528400785073,0.4513075507777067,0.4313602720507895,0.4218736061935138,0.41513809418466757,0.40962065393473596,0.4047788781072076,0.39787364434623684,0.38989412301577314,0.38008108042322314,0.3693859393325398,0.35749229986354203,0.34472524823391293,0.33160328000152234,0.31757691656375314,0.3032708133280898,0.28846080927884415,0.27352488201130737,0.25976577947016566,0.24545024190085954,0.23117239039418871,0.23621885651201693,0.7410501409682438,0.4117068589329299,0.303419580310351,0.24506011101035421,0.20403848279756007,0.18373806333188808,0.1756894414142285,0.16887778501367798,0.1642779622977466,0.16003919048600862,0.1556902310457962,0.15090426901699203,0.14562738126551586,0.13977111914944815,0.13358709449680645,0.12720132689138888,0.12056595392998094,0.1139206079055849,0.10728693612153019,0.10070940404872013,0.09415207290638777,0.08804870957082084,0.08221719617553656,0.0768325056742518,0.6037532057266157,0.2738423592722755,0.1721442005748199,0.1200583391414613,0.09329442101547049,0.08065913217821297,0.07399616880060245,0.07026714615967167,0.06731965714034337,0.06492206458163159,0.06249193967208767,0.06002918688543474,0.05745068281810455,0.054736868148747966,0.05187127434463954,0.04890727661424753,0.04595211992273422,0.04304530783021395,0.040177444512777515,0.037483759461760316,0.035073333481169366,0.03258811271821549,0.030578077513813483,0.02850383426076256,0.02624792322356351,0.028658931907634654,0.4002692574343398,0.20374496150986274,0.1143977084861603,0.0712038098203809,0.055327201596773,0.04660782474079441,0.04270389617760484,0.04048144995820388,0.03890857720534155,0.037564447192933594,0.036247381595050324,0.034849923673857426,0.0333637154443648,0.03178281669449438,0.030148522189779047,0.028504161831434626,0.026865561458633936,0.025241121223862163,0.023621184995009797,0.022068086082675045,0.02055173940557195,0.01914012143959549,0.017842378463813424,0.016570096888318946,0.015414788445714804,0.014313156797023751,0.013287049467903747,2.13014257958006,0.33145467184723,0.14775109833193648,0.07767271329352876,0.05076948120511553,0.039824848716353285,0.034653359435963725,0.032029001796493484,0.03029543165171122,0.02919074292095358,0.028272277807501866,0.027288812195282217,0.026268388383034223,0.025230383361062574,0.02412496794485993,0.02297686484025005,0.02176078213375113,0.020537648001385685,0.019348520471578916,0.018199041113671714,0.017111468877274726,0.016038084532852173,0.01504874948896557,0.014095621104962342,0.01321672266217309,0.012351217508601648,0.011563461124445652,0.010792529431085562,0.010064683806179772,0.7273730396194548,0.23133950473751255,0.11898825495679628,0.06451271972140639,0.04556157568176313,0.03664223038064145,0.0324261060281699,0.030449097779275406,0.029089199156409385,0.027954447252068415,0.026925715067086547,0.02588903646830662,0.024752746699738367,0.0235896051954584,0.022373254295557254,0.021117975757828686,0.019853240060636317,0.018622413349389577,0.017480857176304175,0.01636839142451192,0.015292699303875492,0.01423340715109742,0.013266484105901522,0.012342297570964311,0.011461079132769043,0.010671729209437915,0.00992887968436459,0.009183687890179917,0.008538064201865678,0.007901378055268827,0.0073332221108821935,0.006793921437769326,0.006271787150958107,0.005864816747361051,0.005427181266732219,0.004940060145729543,0.0047113835724719765,0.004280317141494594,0.003934049574767169,0.0036494460121322928,0.0033632993576679154,0.702982341459698,0.16927622849934598,0.08082331822947558,0.04336477396033806,0.030171401400639376,0.02414862303928091,0.021322020886072802,0.02014144950813297,0.01948267129557959,0.018987375607682117,0.018411063829052315,0.01781099680543045,0.01713353761854481,0.01640040645416928,0.015642803515517285,0.014869712574773574,0.014092994414176193,0.013293370069847963,0.012520576644081462,0.011776297810161977,0.011060102328735218,0.01035462065862111,0.0096841378479925,0.009043937480111602,0.008434980938619874,0.007860842184003963,0.007311610411809024,0.006791908857770169,0.006315590440068876,0.005867739575138434,0.005437570074997836,0.005041093779081566,0.004670425330155401,0.004328928959922013,0.0040102966368198685,0.003708148783270243,0.003443617520462223,0.0031765434585248466,0.0029300304297151226,0.0027207731483077074,0.002502676633886807,0.00232467332460473,0.002148656541657362,0.0020708743584985593,0.3862854951447887,0.11815840506737638,0.06305231395255421,0.03314663455734395,0.022251512873523262,0.01805700643359733,0.01623488462723591,0.015459472924773811,0.01509313879403062,0.014868917016367158,0.014680344694420427,0.014423776433889719,0.01413983921125797,0.013803476949059765,0.013429730190521476,0.01302752753378141,0.01256748973155899,0.01207058126798553,0.011553281241783137,0.011021883113839266,0.010476032183902438,0.009931472283116917,0.009388152785306659,0.008846312127880965,0.00832434190761946,0.007819855207265473,0.007335529063584332,0.006869258330157346,0.0064190825881104375,0.0059956024247112966,0.005584823189498859,0.005196347446046462,0.00482852844458573,0.00448333191835469,0.004163881103577778,0.0038620243058138607,0.0035846932884415796,0.0033219027576249184,0.0030772850677775396,0.002857626381860371,0.0026466730245196224,0.0024457743619826756,0.0022697650323733765,0.0021018767548352415,0.0019472164316603677,0.0018070423205526587,0.001664889479135135,0.0015601164463401778,0.0014289158846647468,0.001319562147126509,0.0012183043065615697,0.0011281617109911623,0.0010432388305483696,0.0009688581679099837,0.0008957904061209539,0.0008231643151264067,0.0008634601935564018,0.31745946365595396,0.10664455004630834,0.04912333963597645,0.031173130820040126,0.022562774992391565,0.018827137366038596,0.01749239344252079,0.016984732408318225,0.016786366715178108,0.01668220199322536,0.016573537068849273,0.016387147167419548,0.016125024066626165,0.01579207322057893,0.015376678001342967,0.014892282056915482,0.014336493649385242,0.013722136806502753,0.013068986280219528,0.012367123042593943,0.011653848397277506,0.01093706121173522,0.010215619601834966,0.00950900335548474,0.00883352401961473,0.008188755903484574,0.007590844298580654,0.007035462840187901,0.0065202457883713864,0.006034143036370485,0.005580321421091704,0.005162255669081518,0.004765891877089018,0.004395078659220375,0.004058312444710553,0.0037399808516470606,0.003453565441815576,0.0031833511616424456,0.0029359511036893566,0.002721125812467067,0.0025104291492504737,0.0023159317667780337,0.0021461830636770604,0.0019830701695176616,0.001836688749807831,0.001698954708027062,0.0015707125056204118,0.0014577277915584065,0.001347783171833239,0.0012629413744283725,0.0011630904584150536,0.0010635863892149411,0.0009977809878748754,0.0009226166045597213,0.0008458223053639887,0.0007828364073155513,0.0007248939512373242,0.0006812743711775955,0.0006217703214030701,0.0005767604742220544,0.0005342344691926159,0.0005492574966447853,0.00046003535750137965,0.000417181990445456,0.00038533059684839316,0.00036455822968997035,0.13038943596320135,0.08858056016435682,0.040710242331615014,0.017670135737163917,0.010539982362876869,0.007991608497303421,0.007037718814934041,0.0066405259887980786,0.006526255438184149,0.006504595840134626,0.0064928246499286555,0.006454938620231614,0.006387928142762098,0.006295858229853558,0.006191610789391741,0.006071191026942756,0.005940601174920306,0.00579708137215893,0.005639764241027835,0.0054688626263106185,0.005286704058752988,0.005089368917647917,0.004881119452835584,0.0046635362303441685,0.004439154238090467,0.004212158440786004,0.0039844345474120664,0.0037602670789550967,0.0035390984392635076,0.003323381224988235,0.0031107342828434106,0.0029071417389390252,0.0027133417765024233,0.0025278757635248442,0.0023520480777585936,0.0021867607705467113,0.0020308156671874455,0.001884844653068439,0.0017476529558648323,0.001619343428615144,0.001500206231839361,0.0013883489866067008,0.0012850499692122967,0.0011901598750268512,0.0011016126578818344,0.0010197377990934795,0.0009421051451983986,0.0008708735360578688],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"hovertemplate\":\"Color=multi loss\\u003cbr\\u003eEpoch=%{x}\\u003cbr\\u003eLoss=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"3\",\"line\":{\"color\":\"#ab63fa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"multi loss\",\"showlegend\":true,\"x\":[0,10,20,30,40,50,60,70,80,90,100,110,120,130,140,150,160,170,180,190,200,210,220,230,240,250,260,270,280,290,300,310,320,330,340,350,360,370,380,390,400,410,420,430,440,450,460,470,480,490,500,510,520,530,540,550,560,570,580,590,600,610,620,630,640,650,660,670,680,690,700,710,720,730,740,750,760,770,780,790,800,810,820,830,840,850,860,870,880,890,900,910,920,930,940,950,960,970,980,990,1000,1010,1020,1030,1040,1050,1060,1070,1080,1090,1100,1110,1120,1130,1140,1150,1160,1170,1180,1190,1200,1210,1220,1230,1240,1250,1260,1270,1280,1290,1300,1310,1320,1330,1340,1350,1360,1370,1380,1390,1400,1410,1420,1430,1440,1450,1460,1470,1480,1490,1500,1510,1520,1530,1540,1550,1560,1570,1580,1590,1600,1610,1620,1630,1640,1650,1660,1670,1680,1690,1700,1710,1720,1730,1740,1750,1760,1770,1780,1790,1800,1810,1820,1830,1840,1850,1860,1870,1880,1890,1900,1910,1920,1930,1940,1950,1960,1970,1980,1990,2000,2010,2020,2030,2040,2050,2060,2070,2080,2090,2100,2110,2120,2130,2140,2150,2160,2170,2180,2190,2200,2210,2220,2230,2240,2250,2260,2270,2280,2290,2300,2310,2320,2330,2340,2350,2360,2370,2380,2390,2400,2410,2420,2430,2440,2450,2460,2470,2480,2490,2500,2510,2520,2530,2540,2550,2560,2570,2580,2590,2600,2610,2620,2630,2640,2650,2660,2670,2680,2690,2700,2710,2720,2730,2740,2750,2760,2770,2780,2790,2800,2810,2820,2830,2840,2850,2860,2870,2880,2890,2900,2910,2920,2930,2940,2950,2960,2970,2980,2990,3000,3010,3020,3030,3040,3050,3060,3070,3080,3090,3100,3110,3120,3130,3140,3150,3160,3170,3180,3190,3200,3210,3220,3230,3240,3250,3260,3270,3280,3290,3300,3310,3320,3330,3340,3350,3360,3370,3380,3390,3400,3410,3420,3430,3440,3450,3460,3470,3480,3490,3500,3510,3520,3530,3540,3550,3560,3570,3580,3590,3600,3610,3620,3630,3640,3650,3660,3670,3680,3690,3700,3710,3720,3730,3740,3750,3760,3770,3780,3790,3800,3810,3820,3830,3840,3850,3860,3870,3880,3890,3900,3910,3920,3930,3940,3950,3960,3970,3980,3990,4000,4010,4020,4030,4040,4050,4060,4070,4080,4090,4100,4110,4120,4130,4140,4150,4160,4170,4180,4190,4200,4210,4220,4230,4240,4250,4260,4270,4280,4290,4300,4310,4320,4330,4340,4350,4360,4370,4380,4390,4400,4410,4420,4430,4440,4450,4460,4470,4480,4490,4500,4510,4520,4530,4540,4550,4560,4570,4580,4590,4600,4610,4620,4630,4640,4650,4660,4670,4680,4690,4700,4710,4720,4730,4740,4750,4760,4770,4780,4790,4800,4810,4820,4830,4840,4850,4860,4870,4880,4890,4900,4910,4920,4930,4940,4950,4960,4970,4980,4990],\"xaxis\":\"x\",\"y\":[4.7077671398049015,4.663226277668552,4.79438485265172,4.962955506019486,5.017157160422642,5.04912383271445,5.06247591122357,5.097829761994124,5.181514339682299,5.288784567071089,5.390320599018744,5.48253877988925,5.580484287247372,5.681083819024752,5.77271542401887,5.874964842751493,5.969367585136524,6.068326128461183,6.159336454362658,6.2548023504658214,6.3424127493965194,6.4299952213522165,6.503120075401321,6.573483222963056,6.641422214824728,6.69727198429498,6.745576797644848,6.794810676352156,6.837718361016855,6.875370128941447,6.915608028538998,6.956341714208385,6.985880522583203,7.02331261930018,7.051468418516068,7.087222210318794,7.111999994951198,7.148866361731283,7.1643322417010795,7.18527996237362,7.2144794756275,7.246786032914414,7.268842492719132,7.299403622771823,7.325311920007587,7.360473055326004,7.5267668742624885,7.450819302732093,7.448801998326318,7.444605718078441,7.44200619747322,7.4473721613795885,7.4366736761529,7.432601695573003,7.42953525066925,7.432414947036346,7.44271263857842,7.458869670261469,7.48167767945992,7.50923879327546,7.541032277849924,7.575187720932722,7.611896207864893,7.65014857241416,7.689001050791856,7.729570218213286,7.76930007525216,7.807464110111696,7.848994484552431,7.889559863335477,7.924680847650579,7.96790801195863,8.002634840570634,8.039168585115526,8.079816846826086,8.110542033795982,8.154113275695378,8.181867636422146,8.216716904305718,8.259864444309745,8.279509778090967,8.663376021667949,7.716305848387863,8.005146802297723,7.93692097257976,7.847380696121731,7.798675784324815,7.727499075521521,7.656230558710358,7.582587509241333,7.516380889877585,7.456090550335815,7.402411491441388,7.3533067432168915,7.311665907302549,7.277319319776781,7.24924595527573,7.2273224493153405,7.212423313212572,7.203158821681807,7.198578357230658,7.197738129647041,7.200311449719021,7.204039637538859,7.210419287794682,7.224217331732409,7.233129614061123,7.243694052853532,7.27045264763273,7.266619659955555,7.307842096102855,7.312408975969116,7.371060774512844,7.201261730660325,7.1603526660377,7.148014740720823,7.131992915843548,7.0701298697463235,7.0211294243145055,6.979818334040393,6.934433871094725,6.889828410592628,6.8505532600063095,6.8151530359959285,6.784561217453547,6.758905820810403,6.737905830239542,6.722133068855382,6.7103842299503444,6.701278055066468,6.697276990882452,6.696593329789328,6.697487568108,6.697286739219964,6.709692909269001,6.708999772321419,6.724462812967961,6.850046325368104,6.728595361419807,6.685167102688748,6.650655582383055,6.6210276853884285,6.572598352427408,6.5385465210090175,6.50046658488161,6.454155101597272,6.411199576135233,6.370931774284238,6.336039700018739,6.306538430568911,6.279592553019287,6.2566224251811295,6.237985633351379,6.22335511340825,6.2114129241445415,6.202192333516037,6.198386034598251,6.193976524465086,6.190603201261637,6.196599191097485,6.191927333392246,6.213145021639526,6.369268777557234,6.368098849430275,6.274072334401415,6.245582287841611,6.214366446154298,6.175137994167064,6.144181921329587,6.098987841058495,6.054536326212572,6.017471200302208,5.980647724604281,5.948252774046995,5.92103335869169,5.89751767151967,5.87731564815103,5.862529626546571,5.848529960393031,5.839434145866711,5.831567170988264,5.824960937386801,5.825576332569828,5.830393922319622,5.843491484732315,5.8568902446656255,5.851121781847913,6.0405109945401625,6.233606489454612,6.0652082969073735,5.967137680252379,5.963621467425093,5.917972951255073,5.88411915130912,5.838336961917572,5.797961334567341,5.756163375110188,5.717834745659698,5.684779125728714,5.6532870728480304,5.626259458552706,5.604796603867958,5.5872159251730675,5.573433917709285,5.563660041201084,5.557408517076965,5.552964142011753,5.556099143450476,5.5558304920132295,5.561852938197447,5.571659844976061,5.57196865984473,5.591415226529737,5.601020763711063,5.62114824087612,7.379256689915677,5.945185585920501,5.840690362763572,5.7900791328206465,5.741986970962231,5.704214213289874,5.647587854087352,5.60501751935833,5.564086485459816,5.5224638457635775,5.482355468853444,5.44680117217701,5.414328347838801,5.387177323945439,5.364929569399889,5.3456359162945635,5.328878585892344,5.3159789710458165,5.30524918834582,5.300484988893683,5.296510172308738,5.293547215965107,5.294672540893072,5.296505157113918,5.307098532481735,5.3156946286540006,5.326444006482776,5.3309396391380774,5.359039890467122,6.2827896542594175,5.722772056677042,5.500274937010603,5.388008005359642,5.312250229975009,5.260005587514389,5.210913559983175,5.167449536725423,5.1230484677653685,5.081896015726013,5.042890812232744,5.008025384492793,4.976324189892045,4.947243883119202,4.921658736061212,4.899667728024221,4.878878620490655,4.862693680346866,4.848873358764488,4.839028192930045,4.826480347641874,4.816936405252998,4.814576706620586,4.805432130533333,4.803041075776736,4.802623166903388,4.805012637547135,4.796533443826207,4.8000363035598905,4.799073180763066,4.804861368053742,4.801291976780005,4.807015955952415,4.808817289740787,4.814033723286226,4.808762291082668,4.830362642388255,4.831354528524051,4.826045400598305,4.828813457630949,4.83878643855494,6.084509445163956,5.07724062332427,4.737123417140693,4.60984323014316,4.499129869434433,4.445416683793666,4.398919705851815,4.357202079495467,4.3179909993416805,4.2828068582954675,4.246649574172863,4.213501686953772,4.182436386815029,4.152886982078561,4.123651716390506,4.098340929334252,4.073738585960593,4.04961220941883,4.027262174646485,4.00609481307356,3.986255307324632,3.9661460306671157,3.9477522666761202,3.9301957387306854,3.913501462422889,3.897449563971911,3.879580789456469,3.8642443812677634,3.8527594189264027,3.8348159015511234,3.8216023275885003,3.812606796418223,3.7972395996116712,3.788384782632927,3.773766253708828,3.76333873729807,3.758154201400477,3.7487638298644597,3.7365595944719834,3.729844025792004,3.7219270905467434,3.715346298169565,3.7045400211451542,3.7293245668889092,5.016306998824841,3.8449879424369766,3.4227778971029537,3.2472881145227017,3.166974572879325,3.105614861358301,3.0682609511987615,3.043850063681891,3.0257810057610826,3.006579110701824,2.9882735788972825,2.968876487826224,2.949488066843395,2.928678592145446,2.906898698881744,2.8838113865985204,2.86077192188785,2.8373150560190883,2.8134730250484314,2.788669653596048,2.764117213123163,2.738474202657766,2.713762619210737,2.689061700317992,2.6646527723818534,2.64079190136017,2.617611012926408,2.5949734745291884,2.574605009162459,2.550863314913551,2.527627208027061,2.508594386637028,2.4917323263999958,2.469047386158566,2.452177913179312,2.434419534403701,2.4210892044205536,2.405619649806064,2.390456342481069,2.3829152857908356,2.3647913471348088,2.35013676559596,2.3427307061930995,2.3258155559684894,2.3168810720295636,2.310564515391991,2.293719603609878,2.2911078826666595,2.2784719642662106,2.2769510725877757,2.2645760388683156,2.25572152812243,2.2485262577587943,2.240875061671327,2.2434456489049013,2.239162822649676,2.3790380594101403,3.710265432028312,2.4766460696092816,2.0467169290135754,1.8171083809262756,1.718082002423356,1.6600911539585983,1.636323634516632,1.6249492236992953,1.6198749757752349,1.6151181563923103,1.611878829088096,1.6086317817550697,1.6043903264578108,1.5999787341825589,1.5941724104987705,1.5880424525377195,1.5817467510253962,1.574259043293745,1.56612962659218,1.5580752255938826,1.54775363098397,1.5370023698127655,1.5246657381391224,1.5105077317087816,1.4959171753077698,1.481734006115746,1.467551526495057,1.4524795874116545,1.437151882105336,1.4213956090598678,1.4063272771694515,1.3916111667127578,1.375478006061416,1.361565754190681,1.3513365343661945,1.335645689308606,1.3258441958388256,1.312655629410034,1.3003348576757128,1.295660619989912,1.2839681191341665,1.273172916510088,1.2697413582947183,1.2589062385848968,1.250192129798134,1.2461482566777249,1.2396159851560122,1.2395487106345164,1.2323337911224048,1.2375657018425799,1.228325174276285,1.227105932637364,1.2350860876141716,1.2231417239482816,1.227937697663583,1.2315091564868383,1.2311905721911527,1.2438581865982514,1.2358435605137756,1.252121936382632,1.245321239023752,1.2648428280512403,1.247405833279989,1.2549578159844463,1.2653646139978607,1.2805349745658177,5.321555544573053,2.1335715564136204,1.4908890641414576,1.2183907239867202,1.0713309838419227,0.9910098546434669,0.9500252097019923,0.9339477378648023,0.9233274855219111,0.9188020398959897,0.9135735940946064,0.9078220903190124,0.9034798093605031,0.8986227651781874,0.8935335730446244,0.8884347295892786,0.8833738757461715,0.8782382704777362,0.8717365068325119,0.8648068540976998,0.8572068219581152,0.8490036475490844,0.8402250938610858,0.830024010030862,0.819832603557125,0.8084639869510556,0.796919096020571,0.7845438634867264,0.7725093367950295,0.760228739891957,0.7493357316557813,0.737669568575133,0.7267254896912972,0.7153328434591232,0.7041571774656705,0.6945397319069749,0.6868225954796596,0.6773726338678484,0.66717612367908,0.6600617219523343,0.6546833007079326,0.6438529991433002,0.6374108657235714,0.6319142658143547,0.6223416259986247,0.6207589421264205,0.6101909580267139,0.6059685660682579],\"yaxis\":\"y\",\"type\":\"scattergl\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15,\"font\":{\"size\":20}},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15,\"font\":{\"size\":20}},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05,\"font\":{\"size\":30}},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Epoch\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Loss\"}},\"legend\":{\"title\":{\"text\":\"Color\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Training Curve for Modular Arithmetic - 70% Addition\"},\"updatemenus\":[{\"active\":-1,\"buttons\":[{\"args\":[{\"xaxis.type\":\"log\"}],\"args2\":[{\"xaxis.type\":\"linear\"}],\"label\":\"Log x-axis\",\"method\":\"relayout\"}],\"type\":\"buttons\",\"x\":-0.1,\"y\":1.0},{\"active\":-1,\"buttons\":[{\"args\":[{\"yaxis.type\":\"log\"}],\"args2\":[{\"yaxis.type\":\"linear\"}],\"label\":\"Log y-axis\",\"method\":\"relayout\"}],\"type\":\"buttons\",\"x\":-0.1,\"y\":0.85}]},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('5a134d09-a649-4c06-9b5d-4eaa2217d273');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                });            </script>        </div>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>                            <div id=\"83f91201-f49f-4642-9cff-e99220c85f8c\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"83f91201-f49f-4642-9cff-e99220c85f8c\")) {                    Plotly.newPlot(                        \"83f91201-f49f-4642-9cff-e99220c85f8c\",                        [{\"hovertemplate\":\"Color=train\\u003cbr\\u003eEpoch=%{x}\\u003cbr\\u003eRolling Avg Loss=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"0\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"train\",\"showlegend\":true,\"x\":[0,10,20,30,40,50,60,70,80,90,100,110,120,130,140,150,160,170,180,190,200,210,220,230,240,250,260,270,280,290,300,310,320,330,340,350,360,370,380,390,400,410,420,430,440,450,460,470,480,490,500,510,520,530,540,550,560,570,580,590,600,610,620,630,640,650,660,670,680,690,700,710,720,730,740,750,760,770,780,790,800,810,820,830,840,850,860,870,880,890,900,910,920,930,940,950,960,970,980,990,1000,1010,1020,1030,1040,1050,1060,1070,1080,1090,1100,1110,1120,1130,1140,1150,1160,1170,1180,1190,1200,1210,1220,1230,1240,1250,1260,1270,1280,1290,1300,1310,1320,1330,1340,1350,1360,1370,1380,1390,1400,1410,1420,1430,1440,1450,1460,1470,1480,1490,1500,1510,1520,1530,1540,1550,1560,1570,1580,1590,1600,1610,1620,1630,1640,1650,1660,1670,1680,1690,1700,1710,1720,1730,1740,1750,1760,1770,1780,1790,1800,1810,1820,1830,1840,1850,1860,1870,1880,1890,1900,1910,1920,1930,1940,1950,1960,1970,1980,1990,2000,2010,2020,2030,2040,2050,2060,2070,2080,2090,2100,2110,2120,2130,2140,2150,2160,2170,2180,2190,2200,2210,2220,2230,2240,2250,2260,2270,2280,2290,2300,2310,2320,2330,2340,2350,2360,2370,2380,2390,2400,2410,2420,2430,2440,2450,2460,2470,2480,2490,2500,2510,2520,2530,2540,2550,2560,2570,2580,2590,2600,2610,2620,2630,2640,2650,2660,2670,2680,2690,2700,2710,2720,2730,2740,2750,2760,2770,2780,2790,2800,2810,2820,2830,2840,2850,2860,2870,2880,2890,2900,2910,2920,2930,2940,2950,2960,2970,2980,2990,3000,3010,3020,3030,3040,3050,3060,3070,3080,3090,3100,3110,3120,3130,3140,3150,3160,3170,3180,3190,3200,3210,3220,3230,3240,3250,3260,3270,3280,3290,3300,3310,3320,3330,3340,3350,3360,3370,3380,3390,3400,3410,3420,3430,3440,3450,3460,3470,3480,3490,3500,3510,3520,3530,3540,3550,3560,3570,3580,3590,3600,3610,3620,3630,3640,3650,3660,3670,3680,3690,3700,3710,3720,3730,3740,3750,3760,3770,3780,3790,3800,3810,3820,3830,3840,3850,3860,3870,3880,3890,3900,3910,3920,3930,3940,3950,3960,3970,3980,3990,4000,4010,4020,4030,4040,4050,4060,4070,4080,4090,4100,4110,4120,4130,4140,4150,4160,4170,4180,4190,4200,4210,4220,4230,4240,4250,4260,4270,4280,4290,4300,4310,4320,4330,4340,4350,4360,4370,4380,4390,4400,4410,4420,4430,4440,4450,4460,4470,4480,4490,4500,4510,4520,4530,4540,4550,4560,4570,4580,4590,4600,4610,4620,4630,4640,4650,4660,4670,4680,4690,4700,4710,4720,4730,4740,4750,4760,4770,4780,4790,4800,4810,4820,4830,4840,4850,4860,4870,4880,4890,4900,4910,4920,4930,4940,4950,4960,4970,4980,4990],\"xaxis\":\"x\",\"y\":[5.046054775218921,4.77444535364744,4.72766241470282,4.693705437109825,4.651298344466017,4.592345091426577,4.512318614096559,4.407229902660088,4.277722066171608,4.127677420384991,3.9639527098481904,3.7943188695510175,3.624563743146186,3.4583019601656737,3.297611792008623,3.143966888296962,2.9982099812335368,2.860559048027378,2.7312985625242696,2.610217876556044,2.497128012824605,2.391756863812026,2.293629144290372,2.202299284296956,2.1172917225427508,2.026073835602736,1.8406142066240956,1.657384932717642,1.4758071886149795,1.2979196781696651,1.1264561743791393,0.9645537517500677,0.8159318487405005,0.6834122416414479,0.5685400777214566,0.4710428960228941,0.3891192506659642,0.32069735149250916,0.2639214530583488,0.21720111253567795,0.17899139740524628,0.14791058805320198,0.12288119287144085,0.10271914145096256,0.08659876226740411,0.07368273998822172,0.06324192673766019,0.05487424203784581,0.052516721524982046,0.048065537253360595,0.04378682513473841,0.039994084688789996,0.03670998479337643,0.033886535748531926,0.031460475343593315,0.029371783191760557,0.0275742149309016,0.02600757989927529,0.024645735282151814,0.023457237512538583,0.02240594709275394,0.021482490145585075,0.020665115162956084,0.01992938107535886,0.01927428764889964,0.018686433455766736,0.018160063363613123,0.01767781223911661,0.017246249742907886,0.0168460983504923,0.016486138682530273,0.01616769969432595,0.015787667536810466,0.0109523110034117,0.009409401629186624,0.008638000167640167,0.00812686897563955,0.007709686510300896,0.007323393261326302,0.006941996704633542,0.006559244439914567,0.006176716401626786,0.01430070672141195,0.036637367393078296,0.04084131307431464,0.042069870615153306,0.042514503536600586,0.042718957738534936,0.042852809587722446,0.04298030998606111,0.04312782269903315,0.04330543340832173,0.04351534257726824,0.043755606853299905,0.044022744799961974,0.04431218539384931,0.04461850172076907,0.04493659659133046,0.0452616517481958,0.045588844894757154,0.04591396633283071,0.04623329950609595,0.04654433252227513,0.046844291217439965,0.04713304032137367,0.04740818729052178,0.0476675712401713,0.039407328195949526,0.016925708151444598,0.012573025413065422,0.011196541960174732,0.010605751841521403,0.010258074759035968,0.009991114953011604,0.03417258910741414,0.0398304735782024,0.0415316121999206,0.04216424655698851,0.04242832934261989,0.04254789098896112,0.042613227931975334,0.04266199287926164,0.042710619432775244,0.04276627185241405,0.04283149128422994,0.04290662409368849,0.042990798104068244,0.04308237684355837,0.04317948328788382,0.043279980301778875,0.04338209159344588,0.043484022994598075,0.04358482591099981,0.043682825322056085,0.04377697739388054,0.043866508979139365,0.04395436220368671,0.04403915253920141,0.044201321046728734,0.06160651948455904,0.06768914335320932,0.06971911363853221,0.07058139891790657,0.07106217568210023,0.07140416084950214,0.07168038545914225,0.07192364242947052,0.07214784455831992,0.07235881854626751,0.07255893625330596,0.07274917073221547,0.07293003250374365,0.07310178363754992,0.07326490936904911,0.07341975170658974,0.07356658658232383,0.07370587225649844,0.07383770254392627,0.07396295997897885,0.07408185506191428,0.0741959672657198,0.07430693175495583,0.074411950677681,0.11619367320951993,0.09425654073802377,0.08871903239114032,0.08728766017943142,0.08689422426363516,0.08680807779705774,0.08681748092635974,0.08686287906176923,0.08691891577348436,0.08697468155100661,0.08702562156323387,0.08706983720628579,0.08710672455873572,0.0871363730837452,0.08715927791187031,0.08717608639177374,0.08718763999022369,0.08719474874923054,0.0871984006575702,0.08719969265253458,0.08720107100105783,0.08719822041349291,0.08720204924067938,0.0871919650193969,0.08717698582883318,0.04552372167392346,0.07280702380555353,0.0810934101704562,0.08357052051951012,0.08434207909825751,0.08459581533969408,0.08468169448477911,0.0847022708817596,0.0846986568897444,0.08468823143816254,0.08467827470879871,0.08467166789321266,0.08466916683247108,0.0846706752188541,0.08467576623269972,0.08468366279564192,0.08469360369208803,0.08470474849732687,0.08471577707362601,0.08472608991116767,0.08473252660856043,0.08473890066670292,0.08473314840499932,0.0847328211594778,0.08473444765255668,0.08460468278178032,0.03756472512945629,0.022943948318092173,0.034202490502434235,0.07341673355923169,0.0845132454153341,0.08790838748141246,0.0890509534237536,0.08947097852343133,0.08962957788107226,0.08968592675999001,0.08970652640623727,0.08971994586981324,0.08973827191378307,0.08976606364868356,0.08980405974197316,0.08985141329766612,0.08990683763731797,0.08996898433937701,0.09003555636007302,0.09010536070819364,0.09017716548669225,0.09024907053303566,0.09032040558794945,0.09039069738302571,0.09045816617759772,0.09052479547357466,0.09059030236279873,0.07445075698818521,0.03322384605521978,0.021036435788111724,0.016875760213644807,0.05483909922642069,0.07740345651697696,0.08414639528200196,0.08629990187172004,0.08709697662712687,0.08743092166469063,0.08758815449377476,0.08767938167320351,0.08775156467093938,0.0878249283335764,0.08790696531241453,0.08799956144206532,0.08810248220029701,0.08821407706971854,0.0883320378440972,0.08845398495073034,0.08857806225743743,0.08870197059441344,0.08882375370244644,0.08894303658284217,0.08905659188579172,0.0891670671988335,0.08927008319911772,0.08937058710663207,0.0894632353752772,0.04980165514921268,0.02629822546069532,0.01888119530283362,0.016152300274584343,0.014806871429369818,0.013930115938915594,0.013227250392865878,0.012584045255294078,0.01196585161754071,0.011351612557175013,0.010731260532146007,0.010119145642661347,0.00951346198110614,0.008915843339651019,0.00833457005160533,0.007772788141176483,0.03680365686541068,0.0556065608263464,0.06041528969071383,0.06190466778909328,0.06246642807344872,0.0627311620279442,0.0629013004039417,0.06305416074110394,0.06321979110658793,0.06340686562129116,0.06361640243659569,0.06384792480768808,0.06409450728260557,0.06435608169160512,0.06462452383079825,0.0648968429665838,0.06517336412493478,0.06544228770058327,0.06570642360802616,0.0659706267785632,0.06622082474576707,0.06646124432152066,0.06669362300004238,0.0669132747913565,0.06712035192734013,0.0377444034276172,0.01860861867659302,0.013480441775053425,0.011686592199686091,0.010836473802451762,0.01029967958438962,0.009873624843063452,0.00948109467043764,0.009092747614257447,0.008697357713811893,0.00829389543758146,0.007884574113712838,0.007471171778405597,0.00705772153791539,0.006649308634447509,0.006246399833316612,0.00585303443470415,0.005471553433688542,0.00510668315227803,0.05350564704860597,0.07010408886998183,0.07477568247414831,0.07646485016105965,0.07723430479003439,0.07769238209481262,0.07804360106273732,0.07836607291612868,0.07869037508389326,0.07902692760197023,0.0793780853145014,0.07974270646737203,0.08011786041820133,0.08050031662228997,0.08088620334837589,0.08127308249889767,0.08165697371804284,0.08203440564086406,0.0824040350419192,0.08276315897444768,0.08310822704906316,0.08344019950373824,0.08375642440382122,0.08405612375729836,0.0843360865126668,0.0358504755551915,0.019165001285839815,0.014407053366489354,0.01263314464843847,0.01178127919937472,0.011243816467833973,0.010816646544958721,0.010421761508749204,0.010029323280475275,0.009628655798213138,0.009217507898836349,0.008797385519441989,0.008370413800285054,0.0079400165594239,0.007509629400357391,0.007082058636935751,0.0066601844026665255,0.006247598106989971,0.005846501357111665,0.005458654531754523,0.00508600802587687,0.004729680196031679,0.004391755824270228,0.004071339586293515,0.0037691221391283575,0.0034854097388392633,0.003220145917251358,0.0029724149508803385,0.0027423411173120586,0.0025284654375650143,0.0023298786795975654,0.0021496387158156075,0.05934876830152511,0.07030165541946735,0.07345082981214719,0.07476736764356437,0.07549056113446939,0.07601138051973721,0.07645959675192394,0.0768875907095588,0.07731514737729375,0.07774921876982484,0.07818970731206108,0.07863507777843186,0.07908312356316088,0.07953070800306021,0.07997519363027368,0.08041272351810826,0.08084217900789333,0.0812607009934746,0.08166587277847423,0.08205566997786898,0.08242924900660158,0.08278480563638502,0.08312238224129763,0.08344157755864139,0.08373852937774257,0.026651576997967844,0.015805941380468588,0.01275895216451889,0.011539284009744626,0.010907296656899136,0.010472523957640593,0.010104923264197757,0.00975185678986327,0.009394173144018438,0.009025280879353675,0.008644835052993797,0.008254873674947589,0.007857868047262722,0.007457773759815472,0.007057269523950454,0.006659264256976534,0.006267042590652487,0.005883194718071494,0.005510123933750727,0.0051495549958878355,0.004803190495531774,0.004472405062112479,0.004157886845172116,0.003860405836492896,0.003581415609339538,0.0033183385154135414,0.0030710539486488537,0.0028401343483405355,0.002625472731512897,0.0024246338061754014,0.002238029791928027,0.002064914187571854,0.0019050789718176044,0.001756912701379117,0.0016201033591172964,0.0014939777013115842,0.0013782167686667466,0.001271527801302426,0.0011721446411452464,0.0010806306246724697,0.000996740057285757,0.009354034545871161,0.03079628361643676,0.03431019796606932,0.03540331445800452,0.035901378048338366,0.03620776778347894,0.03644643670994815,0.03666304028467488,0.0368751350554486,0.03709136210213472,0.03731268076220179,0.0375371170609191,0.03776266446851623,0.03798992201985843,0.038216501951386685,0.0384414817014054,0.03866365459944814,0.03888300271329987,0.039098314056231584,0.039308660678865466,0.039512853163503066,0.03971103391176235,0.03990280727088379,0.04008692285966598,0.04026276479734626,0.03199550238405642,0.0106407262090201,0.0072110645093427265,0.006198816400119731,0.005777844924973381,0.005544389294500455,0.005374592756562868,0.005222615498470945,0.0050697030279542865,0.004909687703892654,0.004741413296232317,0.0045659774421942245,0.004384933640922506,0.004199847454317242,0.004012080822771258,0.003822883394120866,0.003633326875817121,0.0034443446234008845,0.0032569532065633068,0.0030721538593757227,0.00289090235987821,0.002714135709878857],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"hovertemplate\":\"Color=test\\u003cbr\\u003eEpoch=%{x}\\u003cbr\\u003eRolling Avg Loss=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"1\",\"line\":{\"color\":\"#EF553B\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"test\",\"showlegend\":true,\"x\":[0,10,20,30,40,50,60,70,80,90,100,110,120,130,140,150,160,170,180,190,200,210,220,230,240,250,260,270,280,290,300,310,320,330,340,350,360,370,380,390,400,410,420,430,440,450,460,470,480,490,500,510,520,530,540,550,560,570,580,590,600,610,620,630,640,650,660,670,680,690,700,710,720,730,740,750,760,770,780,790,800,810,820,830,840,850,860,870,880,890,900,910,920,930,940,950,960,970,980,990,1000,1010,1020,1030,1040,1050,1060,1070,1080,1090,1100,1110,1120,1130,1140,1150,1160,1170,1180,1190,1200,1210,1220,1230,1240,1250,1260,1270,1280,1290,1300,1310,1320,1330,1340,1350,1360,1370,1380,1390,1400,1410,1420,1430,1440,1450,1460,1470,1480,1490,1500,1510,1520,1530,1540,1550,1560,1570,1580,1590,1600,1610,1620,1630,1640,1650,1660,1670,1680,1690,1700,1710,1720,1730,1740,1750,1760,1770,1780,1790,1800,1810,1820,1830,1840,1850,1860,1870,1880,1890,1900,1910,1920,1930,1940,1950,1960,1970,1980,1990,2000,2010,2020,2030,2040,2050,2060,2070,2080,2090,2100,2110,2120,2130,2140,2150,2160,2170,2180,2190,2200,2210,2220,2230,2240,2250,2260,2270,2280,2290,2300,2310,2320,2330,2340,2350,2360,2370,2380,2390,2400,2410,2420,2430,2440,2450,2460,2470,2480,2490,2500,2510,2520,2530,2540,2550,2560,2570,2580,2590,2600,2610,2620,2630,2640,2650,2660,2670,2680,2690,2700,2710,2720,2730,2740,2750,2760,2770,2780,2790,2800,2810,2820,2830,2840,2850,2860,2870,2880,2890,2900,2910,2920,2930,2940,2950,2960,2970,2980,2990,3000,3010,3020,3030,3040,3050,3060,3070,3080,3090,3100,3110,3120,3130,3140,3150,3160,3170,3180,3190,3200,3210,3220,3230,3240,3250,3260,3270,3280,3290,3300,3310,3320,3330,3340,3350,3360,3370,3380,3390,3400,3410,3420,3430,3440,3450,3460,3470,3480,3490,3500,3510,3520,3530,3540,3550,3560,3570,3580,3590,3600,3610,3620,3630,3640,3650,3660,3670,3680,3690,3700,3710,3720,3730,3740,3750,3760,3770,3780,3790,3800,3810,3820,3830,3840,3850,3860,3870,3880,3890,3900,3910,3920,3930,3940,3950,3960,3970,3980,3990,4000,4010,4020,4030,4040,4050,4060,4070,4080,4090,4100,4110,4120,4130,4140,4150,4160,4170,4180,4190,4200,4210,4220,4230,4240,4250,4260,4270,4280,4290,4300,4310,4320,4330,4340,4350,4360,4370,4380,4390,4400,4410,4420,4430,4440,4450,4460,4470,4480,4490,4500,4510,4520,4530,4540,4550,4560,4570,4580,4590,4600,4610,4620,4630,4640,4650,4660,4670,4680,4690,4700,4710,4720,4730,4740,4750,4760,4770,4780,4790,4800,4810,4820,4830,4840,4850,4860,4870,4880,4890,4900,4910,4920,4930,4940,4950,4960,4970,4980,4990],\"xaxis\":\"x\",\"y\":[4.903952655034201,4.770245469446028,4.746137662217242,4.752257226452566,4.785297499671912,4.8220448525534065,4.853627896666595,4.87693320008714,4.88727910516081,4.882771573766987,4.866536636745884,4.844427425974025,4.82055412210184,4.7971216430864905,4.775197834097492,4.755614937246382,4.738634861778732,4.724152416204446,4.712160403875091,4.7022512270141785,4.694249530807764,4.68795070339305,4.683129228566654,4.679467296455355,4.676735461168936,4.673825290526043,4.66905454685147,4.666060089507397,4.661382874168316,4.6519000844427305,4.639069853344577,4.624592573787983,4.610001413250046,4.5976698477894296,4.589892127016532,4.58719502839271,4.588284670872394,4.591918540688726,4.5971235230703105,4.603169468810936,4.609402953444843,4.615442659990651,4.621048051029309,4.625881528188044,4.630116087700594,4.63345601439112,4.635932410489817,4.6395635472227825,4.651345373933235,4.655038303127088,4.65530669770247,4.65420278663019,4.652430448013698,4.650074203528895,4.647376743321144,4.644417147227484,4.641325340341705,4.638183480537925,4.635244238575499,4.632567286805154,4.630227714350157,4.628405542845693,4.627096245672884,4.62635679417508,4.626299401185489,4.626895931688977,4.628083824163453,4.6298347253669085,4.632173372593604,4.634922516863896,4.638243320238654,4.642021730041704,4.6441925105762145,4.637844903861555,4.639271968863615,4.643837516570786,4.649597103435014,4.6558892062447175,4.6628445903261335,4.670103168035778,4.67768159570876,4.685474710441455,4.708497099466262,4.714626363985702,4.717036884233872,4.7157865900938,4.71019339915761,4.702050420966542,4.691698613266935,4.67916052293165,4.664488301385926,4.647829707201644,4.629384330488187,4.6093036214396506,4.587681717999445,4.564660293852944,4.5403758960768315,4.514972948930516,4.4885541083580405,4.461231321600852,4.433165963013487,4.4044020009328015,4.375079770995694,4.345180694061963,4.314909280795879,4.284232567616487,4.253165198261316,4.206611603500764,4.176629193649027,4.149928605720583,4.126433482076704,4.106658578987588,4.0888517108211975,4.072817213737746,4.077329071876441,4.064955683705261,4.049962717114547,4.034264936186589,4.018020729191297,4.001228327121291,3.984333298672397,3.9672565639548973,3.94993926309592,3.9323909446270213,3.9146011599904327,3.8965214517824065,3.8781485074799176,3.85952372990886,3.8406759850124814,3.821629989858989,3.8024269617471123,3.7831068656210536,3.7636971567045125,3.744196852074771,3.7246408281152443,3.7050110974753405,3.685485363356187,3.6659558623569835,3.65173190695457,3.641628396661086,3.6265983736276524,3.611811060544936,3.5968567774494997,3.581864236813133,3.5672141303421614,3.552625174433228,3.5381054178803946,3.523597986616951,3.509115076182779,3.494662766775884,3.4802879658340093,3.4659900212836776,3.4517523547326796,3.4375725360133904,3.4234609682636976,3.4094037575948644,3.395416275917988,3.3815032948623793,3.3676632115240346,3.353908155735488,3.3402194739442623,3.326587759843303,3.3131115272653875,3.321327580152103,3.2867837732494927,3.2727973802392105,3.2605091391083696,3.2492353967840546,3.238530941836493,3.22834231711299,3.2182665005537965,3.2081895368724798,3.1982795244136253,3.1884781142876797,3.1787788362505323,3.1691699410000873,3.159663418658369,3.1502792593896003,3.1410164162987524,3.1318545096351,3.122802500325623,3.1138664486742305,3.1050576660413336,3.0964126577961553,3.0878834684637044,3.0795974717761743,3.0714951840908804,3.0635114096036213,3.0333232301659288,3.050461428773568,3.048700711091053,3.0437408244602633,3.0382274826910693,3.032648700035752,3.026902831503648,3.0211643802869825,3.0154727838739452,3.0097687572038727,3.004018141744738,2.998271544123295,2.9924875232161163,2.986649545062267,2.9808002036398156,2.9749387802371823,2.969091109906735,2.963272679679962,2.957475942640309,2.951696506421951,2.9459265147131504,2.940208466618293,2.934441839665645,2.928634139138172,2.9228510848293445,2.9124120714643578,2.8746699866012095,2.858965061667768,2.87036591352009,2.885102219823631,2.887110175851404,2.8865485054853446,2.884974612459491,2.8831197052290434,2.88095376122239,2.8786138649438304,2.876149454564412,2.873493206886453,2.8706129943051226,2.867458334993033,2.8640223896141146,2.8603104457968964,2.8563610575068146,2.852167816094261,2.8477136434100547,2.8429755862072357,2.8380083666767737,2.832818300680545,2.8274382396085835,2.8218390754728007,2.816059638411683,2.810059524821473,2.8038732354921323,2.7760478763359173,2.7467964340138864,2.7316899486551,2.7203920438145213,2.7490330554931415,2.7565273095998104,2.75668435802824,2.753805374290057,2.749304123454456,2.7442815009289245,2.739026376875987,2.733565926663388,2.7278945473080665,2.7219478780457185,2.7156766360919558,2.7090894378626618,2.7022002054666756,2.695015689526631,2.687498718462834,2.6796621987415836,2.67150053243176,2.6630351027517287,2.6542622249165633,2.6451860609179896,2.6358114346686983,2.6261275757211906,2.6160917184487857,2.605767430397475,2.595056430926104,2.5462436493671663,2.519753591600073,2.5016821592297696,2.487702792927632,2.4761481589273786,2.466006715979456,2.456969008336828,2.448900183240573,2.441924368304252,2.4358195725050042,2.4305174747538483,2.4261133148063534,2.422448163727494,2.4193965605556653,2.416987414975825,2.4151596521237106,2.4475340587157968,2.4621863403692767,2.4635317000790353,2.4603638005016935,2.4547786936607654,2.4478602522486343,2.4400305639741116,2.431427885669348,2.42210848332614,2.412148721467809,2.401493343303103,2.390216550222477,2.3782527200232018,2.365717059798881,2.3525391185222473,2.338777970759369,2.3245053890962617,2.309541740056427,2.29411207292865,2.2782546000088497,2.26181967580292,2.244907625464752,2.2276051168003606,2.2098675103569274,2.1916863264432322,2.139385914236258,2.1048473759225503,2.0836159414006628,2.0668549100323372,2.0524499439510766,2.0392922769835806,2.026938783179429,2.015248367532775,2.004121382715835,1.9934969388904045,1.983402302718157,1.9738210398227338,1.964686560865969,1.9559735774129046,1.9477213965540066,1.9398068615192434,1.9322677779212583,1.9250877716988866,1.9186146714328682,1.9684743208984858,1.972858049543663,1.965469974891081,1.9530307621368965,1.9384256708493772,1.9227681395267426,1.9065097849329729,1.8899773124387336,1.8733684072777437,1.856714241560689,1.839975460647381,1.8231352054590824,1.8061683864239721,1.7890297681596286,1.7717075345027022,1.7541404938134453,1.736314451890691,1.7181931417059397,1.6997888207813587,1.681074778836728,1.6620063507485552,1.642620829206927,1.6228667792062903,1.6027590719505942,1.5819015088283044,1.504663919924502,1.472873422240352,1.4528029721777334,1.4377130920889032,1.424690448163992,1.4126231904420767,1.4010975240686598,1.389773240374516,1.378467978552872,1.367155818250372,1.3558884112454512,1.3446667796490097,1.3335448707193418,1.3225582707527652,1.3117283795755414,1.3010651711435375,1.2906025666608725,1.2803808184559138,1.2703927157678816,1.2606922530698463,1.2512425409448769,1.2421124308035478,1.2333641709567011,1.2248328478341783,1.2166910938870066,1.2089078738811854,1.2014869292044459,1.1943563248282965,1.1876177371510472,1.1812382366778602,1.1751962321781548,1.1725232535590924,1.2440152975635759,1.2530814999936486,1.2484449088149951,1.2379835235039167,1.2248413182814595,1.2104760392986067,1.195696831065659,1.1808702492139032,1.1662002194490937,1.1516963371807862,1.1373523652982387,1.1231940310602795,1.1091664472053044,1.0952950753594968,1.0815161764349834,1.0677263865494329,1.054087762632557,1.040422431740127,1.0267223563774102,1.0129357558514447,0.999125315133039,0.9851610188937913,0.9710423335726408,0.9567534126331521,0.9392024548796502,0.8475968299398379,0.818499084925619,0.8031753149478137,0.7936949954860644,0.7869121160293386,0.7813380047248336,0.776134923554552,0.7709522539491211,0.7656195452109006,0.7601136296338169,0.7544241910702529,0.7485457018436082,0.74248658556522,0.7363132908622261,0.7300550000185116,0.7237128345557199,0.7173509909387461,0.7109580592517177,0.7045971419545604,0.6982500579077477,0.6919739318266251,0.6858355859073727,0.6798390459918694,0.6740657467277006,0.668648981013648,0.6632905661238294,0.6582450779902299,0.6535787645273939,0.6491073449903738,0.6449754981639862,0.6412413088928826,0.6378168696339077,0.6348873588191865,0.6321742082209487,0.6299248668739994,0.6279239281292038,0.6264264914411944,0.6250302095554756,0.6239692416811169,0.6232740185600638,0.6229916125175887,0.6514441103580813,0.6846776931053341,0.693536076289191,0.6949303719351749,0.6925436067709129,0.6881501317372485,0.6827197904322414,0.6769117954421708,0.6707800807271942,0.6647772600866273,0.6586546652378883,0.6523517069031238,0.6460664594658383,0.639674954517518,0.6330924255236784,0.626412287290676,0.6194417684459841,0.6124398444517984,0.6051250338507003,0.5976810551220374,0.5898370647167084,0.5819895299063372,0.5738423704323462,0.5653265971946138,0.5564062889437695,0.5186779450076321,0.47612169415052974,0.45783164097538037,0.44691899184739636,0.43967559031084064,0.43429312344227156,0.42982095721674934,0.42555384767993754,0.4213343383657877,0.4170092243370703,0.41259309855656023,0.40808704504288007,0.4034981590718886,0.39882811349494246,0.39409046788276275,0.38929473353817484,0.3844575115066411,0.37956933335969373,0.3746554271381967,0.3697543391401149,0.36486799850266854,0.36003092460184716],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"hovertemplate\":\"Color=add loss\\u003cbr\\u003eEpoch=%{x}\\u003cbr\\u003eRolling Avg Loss=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"2\",\"line\":{\"color\":\"#00cc96\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"add loss\",\"showlegend\":true,\"x\":[0,10,20,30,40,50,60,70,80,90,100,110,120,130,140,150,160,170,180,190,200,210,220,230,240,250,260,270,280,290,300,310,320,330,340,350,360,370,380,390,400,410,420,430,440,450,460,470,480,490,500,510,520,530,540,550,560,570,580,590,600,610,620,630,640,650,660,670,680,690,700,710,720,730,740,750,760,770,780,790,800,810,820,830,840,850,860,870,880,890,900,910,920,930,940,950,960,970,980,990,1000,1010,1020,1030,1040,1050,1060,1070,1080,1090,1100,1110,1120,1130,1140,1150,1160,1170,1180,1190,1200,1210,1220,1230,1240,1250,1260,1270,1280,1290,1300,1310,1320,1330,1340,1350,1360,1370,1380,1390,1400,1410,1420,1430,1440,1450,1460,1470,1480,1490,1500,1510,1520,1530,1540,1550,1560,1570,1580,1590,1600,1610,1620,1630,1640,1650,1660,1670,1680,1690,1700,1710,1720,1730,1740,1750,1760,1770,1780,1790,1800,1810,1820,1830,1840,1850,1860,1870,1880,1890,1900,1910,1920,1930,1940,1950,1960,1970,1980,1990,2000,2010,2020,2030,2040,2050,2060,2070,2080,2090,2100,2110,2120,2130,2140,2150,2160,2170,2180,2190,2200,2210,2220,2230,2240,2250,2260,2270,2280,2290,2300,2310,2320,2330,2340,2350,2360,2370,2380,2390,2400,2410,2420,2430,2440,2450,2460,2470,2480,2490,2500,2510,2520,2530,2540,2550,2560,2570,2580,2590,2600,2610,2620,2630,2640,2650,2660,2670,2680,2690,2700,2710,2720,2730,2740,2750,2760,2770,2780,2790,2800,2810,2820,2830,2840,2850,2860,2870,2880,2890,2900,2910,2920,2930,2940,2950,2960,2970,2980,2990,3000,3010,3020,3030,3040,3050,3060,3070,3080,3090,3100,3110,3120,3130,3140,3150,3160,3170,3180,3190,3200,3210,3220,3230,3240,3250,3260,3270,3280,3290,3300,3310,3320,3330,3340,3350,3360,3370,3380,3390,3400,3410,3420,3430,3440,3450,3460,3470,3480,3490,3500,3510,3520,3530,3540,3550,3560,3570,3580,3590,3600,3610,3620,3630,3640,3650,3660,3670,3680,3690,3700,3710,3720,3730,3740,3750,3760,3770,3780,3790,3800,3810,3820,3830,3840,3850,3860,3870,3880,3890,3900,3910,3920,3930,3940,3950,3960,3970,3980,3990,4000,4010,4020,4030,4040,4050,4060,4070,4080,4090,4100,4110,4120,4130,4140,4150,4160,4170,4180,4190,4200,4210,4220,4230,4240,4250,4260,4270,4280,4290,4300,4310,4320,4330,4340,4350,4360,4370,4380,4390,4400,4410,4420,4430,4440,4450,4460,4470,4480,4490,4500,4510,4520,4530,4540,4550,4560,4570,4580,4590,4600,4610,4620,4630,4640,4650,4660,4670,4680,4690,4700,4710,4720,4730,4740,4750,4760,4770,4780,4790,4800,4810,4820,4830,4840,4850,4860,4870,4880,4890,4900,4910,4920,4930,4940,4950,4960,4970,4980,4990],\"xaxis\":\"x\",\"y\":[4.753764206627752,4.761940656299279,4.780934680261062,4.8085000055938805,4.840614640950479,4.8671371664566525,4.880093330566273,4.86458668757421,4.8149157585792475,4.740347232050583,4.654557273144801,4.565793855989777,4.478056139530855,4.393402801644462,4.312493433457191,4.2364770870918385,4.165084730792385,4.098245481771521,4.034960485840728,3.975639280695538,3.9194860310932698,3.86634521059776,3.815817375620527,3.7677808875160133,3.7220461031392738,3.635213089300073,3.5461816471841034,3.4536797972826965,3.3566290046565963,3.255014532355747,3.1507750425167926,3.046634289582751,2.9491023620041243,2.8637008116982168,2.7908225862808895,2.7274713080163906,2.671035953191617,2.6198762540656753,2.5725488906477296,2.5284121049098203,2.48645306664511,2.446144416340393,2.406917045535238,2.369361621901939,2.332273496050778,2.2959195018621643,2.2632798637295735,2.241331917457817,2.209788873987959,2.1764491751430173,2.143804488912,2.1117488042372488,2.0809696688615293,2.051496919999982,2.023298917233132,1.9962419216768708,1.9704836926215394,1.9458644448258593,1.9222914764662562,1.8997196524826796,1.878089752523689,1.8573475952340064,1.8374014178911486,1.818375974764194,1.8001059411608467,1.7824289146539813,1.765397748693111,1.749012796779071,1.732886195060442,1.7174390564596238,1.7025132578889282,1.6848924038858257,1.657457299956656,1.640316706640464,1.6256104323842657,1.6107565886310178,1.5958840947502226,1.5800810966719478,1.5633917010413771,1.545995331521211,1.5274383584716735,1.5427283170980362,1.5359991411538574,1.5171838973263632,1.494098736845775,1.4684368507544594,1.4417773240945793,1.414809699485692,1.3880352396378453,1.3614934098526457,1.3353875462230942,1.309810343642593,1.2848107439036627,1.2603542607404785,1.2364306326172956,1.2130448657233963,1.1901145570887834,1.1676836130919026,1.1456569972738582,1.123945599629306,1.1026830684017495,1.0816512970220251,1.0610148358954803,1.0407876287876616,1.0205961507323613,1.00095978536999,0.9467925931546489,0.9139829338652256,0.8927533766291922,0.8751421261596429,0.8596747396007793,0.8445629398967307,0.8295640733839548,0.8325878486810286,0.8214080030528541,0.805274292488139,0.7869801661655851,0.7671652607181453,0.7467249577518316,0.7261173392572564,0.7055315811159357,0.6850916888359484,0.6649286379131886,0.6450361698466445,0.625412854389067,0.6060596043919078,0.5870217497776177,0.5682849771267199,0.5498662920184197,0.5317678185665714,0.5139707272767453,0.4965645627792606,0.47955139829313254,0.4628097802378416,0.44657765203598543,0.43063980522220896,0.4152596886249812,0.4007726687949731,0.38880178916452096,0.3782080671230537,0.36837121363684777,0.358472482045859,0.34858171932665316,0.3386768309778971,0.32882946438672567,0.3189790520198861,0.3091653443544065,0.2993757568495586,0.28968842031754094,0.2801288261575897,0.2707506781912814,0.26156608538395776,0.2526098771692883,0.24390892031558736,0.23546742727272568,0.22732117492639897,0.21948181983813658,0.21197176362893164,0.20479685126473485,0.19792816846876105,0.19139884663974815,0.18522525125095066,0.19992662521953458,0.18123831395169587,0.17165580761737145,0.1643213579706159,0.15825073037082055,0.15331555634604666,0.14892588056479522,0.14470898875461297,0.14064666363967956,0.13667242773103497,0.13277053769847813,0.12894409593206368,0.12520595248410818,0.12157033195943746,0.11805433816724512,0.11466714545194275,0.11141717717319657,0.10831635132920589,0.1053666247934936,0.10257449772710281,0.09994905490440077,0.09748649649687388,0.09518767121459358,0.09303913673800263,0.0910157534399751,0.06801198248721585,0.07306905841369843,0.07433308885110014,0.0741066636248881,0.07322303917708452,0.07220976195382692,0.07111422819143459,0.07001169819215192,0.06893816990486634,0.06789763040981474,0.06690053071064858,0.0659492584990332,0.06504522813326331,0.06419030202508798,0.06338676371908218,0.06263641354210345,0.06193849521845146,0.06129130536358826,0.06069385243203164,0.06013934945336162,0.059619139557421846,0.05913768462491611,0.05868016638194739,0.05825370815006942,0.05786659509665964,0.05733682935818284,0.041898585332690204,0.03428026885101185,0.11491006369476783,0.1253200981758418,0.12901705404524835,0.13025964958735772,0.13058227298845815,0.1305560089387841,0.130385800228009,0.1301643824121514,0.12992630441441785,0.1296999371843017,0.12949627967882718,0.1293165194988587,0.12916131414658888,0.129030363007774,0.12892073926722303,0.12883016901187858,0.12875575289742822,0.12869453537417663,0.12864640661681692,0.12860876340377997,0.1285795270203184,0.12855824652609976,0.12854360496782977,0.12853490354014732,0.12853209046791808,0.04382043598505976,0.031024787556148382,0.025546444800114348,0.022842123620620387,0.049906265957193954,0.05756685219804033,0.06094024801887363,0.062239596735870144,0.06285024249707222,0.06314830199545973,0.06331445512428646,0.06344086654764619,0.0635536989785812,0.06366266153422143,0.06377469141911049,0.06389117828423276,0.06401085686687225,0.06413293515463515,0.06425392450759429,0.06437068189336057,0.06448035274069502,0.06458372589335652,0.06468101020085007,0.06477192101363205,0.06485496007930014,0.06493024766499998,0.06499836858425821,0.06506035930985336,0.06511621512291693,0.03644816270651626,0.02759173770439034,0.023199555021725687,0.020960568800944056,0.019454160895884285,0.018281800565093917,0.017256513181477893,0.0162894207563452,0.015360445459983267,0.01445935482056982,0.013579928623715537,0.012732822507882153,0.011913925325552402,0.011127703100724752,0.010378750769387754,0.009668563713381324,0.03699372776934379,0.043019880375342046,0.0455535788174689,0.04663343411890195,0.047228582202772505,0.04762519083829984,0.04794741230950669,0.04825937838699344,0.04858024207350586,0.04891286792943563,0.049252155295223136,0.04959724765183316,0.049941066588500324,0.05028102772445634,0.05061341098064175,0.05093644262612192,0.05124929091665064,0.05154643304955012,0.05183016886464409,0.052103618371221384,0.05235756712147191,0.05260053926215697,0.05283054279308599,0.053046322451805156,0.053249189715043235,0.02544432974401548,0.018965745020514,0.016004488645645784,0.014522521304835017,0.01355037483181498,0.012801932713243655,0.012150695628964005,0.011531854661844903,0.010925704968418602,0.010326621809584111,0.009738505207752829,0.009163810036354098,0.0086055302699533,0.008066715228975134,0.007549834014286751,0.00705515257665128,0.006584419733068422,0.006138631191940798,0.005720643100517481,0.02070101099390255,0.024984943103448197,0.02709285083520552,0.02803135070357958,0.028559653719316045,0.028944534739115145,0.02927949643684442,0.029605410937363016,0.02993746013481343,0.030279593197865363,0.030632097402636643,0.030991545656992317,0.03135549547427938,0.031720817539035544,0.03208484958825953,0.03244553882413799,0.032799912462069536,0.03314499101197047,0.0334800605233008,0.033803734630665765,0.03411394499208956,0.03441109681805876,0.03469363599648684,0.03496154221993578,0.03521168092190062,0.02007305532439969,0.015640140284248007,0.013392818059352132,0.012323715980582793,0.011673479562630313,0.011174592232866374,0.010733050745618797,0.010307812966411273,0.009883420691384237,0.00945521925487266,0.009022486439328398,0.008588923113510472,0.00815620565536515,0.007727157980113863,0.007304273827767418,0.006889039647396946,0.006484171032613894,0.006092138383189407,0.005714082203711491,0.0053510955364243365,0.005004335941890345,0.004673672629731073,0.004360551176172414,0.004063855326443765,0.0037836641360240474,0.003519602099995891,0.0032713074058921643,0.0030382666259078056,0.002820257649099787,0.002616265168356173,0.0024257988133812754,0.002252483323281673,0.0147577207317364,0.018844169456854548,0.020642547798150494,0.021734992058719548,0.022494115326877548,0.023114324711214093,0.023690929046203825,0.024256013287262138,0.024821601034888476,0.025391058140138183,0.02596320902159722,0.02653461983810059,0.027101732143499223,0.027661133379500272,0.028209604920388587,0.028742891544811598,0.02925919465540042,0.02975529764177547,0.030229324920721785,0.0306788833739859,0.03110330775665506,0.03150203587840807,0.03187482904623663,0.032222262607850966,0.0325410651608933,0.020170236850794523,0.01620808862088542,0.014524573549053876,0.013538458147787126,0.012877312869546282,0.012347440231748408,0.011854234720810836,0.011365481099561668,0.010869829577323359,0.010364873995382766,0.009851531746694678,0.009334188477670518,0.00881652156147117,0.008302276676795587,0.007796054589240552,0.007300780472933951,0.0068199579976296635,0.006356919847916635,0.005913483203488561,0.005492265831777116,0.005094070084207099,0.004719416135962506,0.004369100463551444,0.004042651656205383,0.003739828350397929,0.0034588017325951482,0.0031977114162205196,0.002956204142127999,0.002732298974775532,0.002524766145535272,0.002332866744984226,0.0021553722762704584,0.0019919875760340015,0.001841055242521309,0.0017017931637017694,0.0015735633084035916,0.00145739099059676,0.0013484583584311171,0.0012477075939013613,0.0011542757852766143,0.0010684409484941941,0.006191381116351127,0.009648756200378318,0.01119784308686221,0.011831180966356453,0.012184822072550448,0.012441657912217767,0.012664857553152793,0.012876567265831387,0.013087099828381616,0.013300760043650401,0.013517929574078949,0.01373621587937322,0.013954828340901313,0.014172829777880895,0.014389180753163944,0.014603032636192162,0.01481340570834187,0.015020418150372104,0.015222938301044335,0.015420323427329054,0.015609821289813385,0.015794994632219245,0.01597355213071485,0.01614468035605468,0.016307664196390702,0.011260573095494086,0.007876728070816297,0.0063987290607099,0.005833487568793884,0.005544823523278338,0.005349588554699938,0.005184365471660137,0.005027278103168311,0.0048673429161819395,0.004701241005686897,0.0045289984505116196,0.0043520335323898535,0.004171910192802107,0.003989981981842558,0.0038070912874114938,0.0036242518956073584,0.003442161808074814,0.0032616805519569488,0.003083696377316909,0.0029090063785797583,0.0027383277281933776,0.002572437177295397,0.002412027340624288],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"hovertemplate\":\"Color=multi loss\\u003cbr\\u003eEpoch=%{x}\\u003cbr\\u003eRolling Avg Loss=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"3\",\"line\":{\"color\":\"#ab63fa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"multi loss\",\"showlegend\":true,\"x\":[0,10,20,30,40,50,60,70,80,90,100,110,120,130,140,150,160,170,180,190,200,210,220,230,240,250,260,270,280,290,300,310,320,330,340,350,360,370,380,390,400,410,420,430,440,450,460,470,480,490,500,510,520,530,540,550,560,570,580,590,600,610,620,630,640,650,660,670,680,690,700,710,720,730,740,750,760,770,780,790,800,810,820,830,840,850,860,870,880,890,900,910,920,930,940,950,960,970,980,990,1000,1010,1020,1030,1040,1050,1060,1070,1080,1090,1100,1110,1120,1130,1140,1150,1160,1170,1180,1190,1200,1210,1220,1230,1240,1250,1260,1270,1280,1290,1300,1310,1320,1330,1340,1350,1360,1370,1380,1390,1400,1410,1420,1430,1440,1450,1460,1470,1480,1490,1500,1510,1520,1530,1540,1550,1560,1570,1580,1590,1600,1610,1620,1630,1640,1650,1660,1670,1680,1690,1700,1710,1720,1730,1740,1750,1760,1770,1780,1790,1800,1810,1820,1830,1840,1850,1860,1870,1880,1890,1900,1910,1920,1930,1940,1950,1960,1970,1980,1990,2000,2010,2020,2030,2040,2050,2060,2070,2080,2090,2100,2110,2120,2130,2140,2150,2160,2170,2180,2190,2200,2210,2220,2230,2240,2250,2260,2270,2280,2290,2300,2310,2320,2330,2340,2350,2360,2370,2380,2390,2400,2410,2420,2430,2440,2450,2460,2470,2480,2490,2500,2510,2520,2530,2540,2550,2560,2570,2580,2590,2600,2610,2620,2630,2640,2650,2660,2670,2680,2690,2700,2710,2720,2730,2740,2750,2760,2770,2780,2790,2800,2810,2820,2830,2840,2850,2860,2870,2880,2890,2900,2910,2920,2930,2940,2950,2960,2970,2980,2990,3000,3010,3020,3030,3040,3050,3060,3070,3080,3090,3100,3110,3120,3130,3140,3150,3160,3170,3180,3190,3200,3210,3220,3230,3240,3250,3260,3270,3280,3290,3300,3310,3320,3330,3340,3350,3360,3370,3380,3390,3400,3410,3420,3430,3440,3450,3460,3470,3480,3490,3500,3510,3520,3530,3540,3550,3560,3570,3580,3590,3600,3610,3620,3630,3640,3650,3660,3670,3680,3690,3700,3710,3720,3730,3740,3750,3760,3770,3780,3790,3800,3810,3820,3830,3840,3850,3860,3870,3880,3890,3900,3910,3920,3930,3940,3950,3960,3970,3980,3990,4000,4010,4020,4030,4040,4050,4060,4070,4080,4090,4100,4110,4120,4130,4140,4150,4160,4170,4180,4190,4200,4210,4220,4230,4240,4250,4260,4270,4280,4290,4300,4310,4320,4330,4340,4350,4360,4370,4380,4390,4400,4410,4420,4430,4440,4450,4460,4470,4480,4490,4500,4510,4520,4530,4540,4550,4560,4570,4580,4590,4600,4610,4620,4630,4640,4650,4660,4670,4680,4690,4700,4710,4720,4730,4740,4750,4760,4770,4780,4790,4800,4810,4820,4830,4840,4850,4860,4870,4880,4890,4900,4910,4920,4930,4940,4950,4960,4970,4980,4990],\"xaxis\":\"x\",\"y\":[4.7077671398049015,4.685496708736727,4.721792756708392,4.782083444036164,4.829098187313461,4.865769128213626,4.8938700972150455,4.919365055312431,4.948492753575749,4.982521934925283,5.019594540751961,5.058173227346736,5.098351001185246,5.139974773888069,5.182157483896788,5.225457943825207,5.269217334490579,5.313612267488946,5.358124066798088,5.4029579809814745,5.447693922334572,5.492343981380829,5.536290768077372,5.579507120364275,5.6219837241426935,5.7015639179222966,5.784857938721348,5.864874971669366,5.939865485869261,6.014194004610013,6.088853372442995,6.164608004562387,6.24013003498595,6.313801966170667,6.384309320228465,6.452185384680467,6.517363833282945,6.580099116262302,6.639429053169355,6.695931634703545,6.749512220018585,6.8006089579297,6.848629612500019,6.894232299236385,6.937052682018056,6.977775094255235,7.021645960371647,7.059553929464877,7.094566680479407,7.1266940206095555,7.156483389136685,7.184555203686075,7.210229723678104,7.234025057060351,7.256191661929463,7.276863938669356,7.296318775644158,7.3152383415512885,7.333572943957679,7.351883758948054,7.370036161649299,7.38856367068856,7.407084864533905,7.426517517762428,7.446666361299158,7.467269991002589,7.488170552696099,7.509715417391801,7.531699051863026,7.554268969596142,7.576837281289125,7.59448292679697,7.616555548310512,7.64017021178208,7.665578656931985,7.6923200903848965,7.720589734957527,7.750397493368297,7.781762101717606,7.8149752694632255,7.848859062705412,7.897685598028992,7.907983045154047,7.9289218100675605,7.946029097239732,7.958283033970604,7.967222556506288,7.971846671212553,7.9720899506644,7.967833409002379,7.9593058358689515,7.946777454872298,7.930575350125485,7.910747840472064,7.887632082230747,7.861737621115796,7.832991138848479,7.801978643198267,7.76890883232215,7.733842511316379,7.697363964253765,7.6591089584118315,7.619846710943707,7.579339620273032,7.537361814012429,7.495150116158087,7.437940259853814,7.41903578803244,7.389648021845841,7.362835969340873,7.341254425340118,7.321803753005891,7.307546220965543,7.289347467843542,7.272458074115397,7.257723428149125,7.244759522769435,7.231468257901632,7.218181165145537,7.20490726221505,7.1911918442677685,7.176815142480445,7.161744374908084,7.145853563819418,7.129109659650287,7.111522758193477,7.093129466217177,7.074002330982632,7.054256114679091,7.0338904653699625,7.012812851735964,6.991351400365093,6.969503140975271,6.94657650463876,6.9242994346112985,6.900345741660041,6.876827895139994,6.855987317174205,6.837080662404584,6.8180732398706265,6.798178873537115,6.777740264318911,6.757839003626154,6.738535687493935,6.719361617527584,6.700150466747686,6.68100531336939,6.661820453940506,6.642655920501419,6.623535009026034,6.604362478314389,6.585111142112052,6.565745244691892,6.546264080030209,6.526669474793331,6.5068660884986755,6.4869377966910315,6.4667973549453155,6.446530013426982,6.4260062647001215,6.405323367142954,6.384870655489817,6.365639553577382,6.351219693097801,6.334775902366308,6.31857297058465,6.302306521015285,6.286408106684871,6.270633522697693,6.254574372944769,6.238589621929381,6.22284048689606,6.207229124908862,6.191717647869992,6.176297444994904,6.161014449734918,6.145842178653714,6.130823938381522,6.115830932260914,6.100951781129799,6.08612677462869,6.071189770740232,6.056453763064422,6.042045391906741,6.027921083652134,6.0145196001030685,6.000038670511405,5.986888359190722,5.981508664791695,5.973154103291933,5.962016318988364,5.951986519839196,5.941699918122716,5.931297407321897,5.9208713721562605,5.910608372490451,5.900156059482771,5.889643540324987,5.879104594392256,5.86839474295851,5.857544414439831,5.846643652668508,5.835631104613568,5.824627262906218,5.8135962987195935,5.802629952563141,5.791750080748139,5.780970993183365,5.769988455971109,5.758722914109715,5.747313698122132,5.736147573242005,5.718183742521587,5.692880313491846,5.675117911250595,5.731602671637128,5.730865236376944,5.727773932837284,5.724012332097746,5.720158332459531,5.7164084476084325,5.71206542676752,5.707552737715464,5.702725032104708,5.697492103021331,5.691735943433359,5.6854161261657215,5.678500623072352,5.671050359321797,5.66310114044975,5.654630236418453,5.645666814173677,5.6360620072774905,5.626038755130794,5.615584037158644,5.60457805025195,5.593441192496766,5.581571485071299,5.569390860807414,5.556828872471638,5.474286390021172,5.449536726843662,5.429146697898642,5.411905128204502,5.433537235536389,5.434279549271875,5.428387032588805,5.419706652028858,5.4096332018094655,5.399134871479498,5.3882771951246875,5.377103129706623,5.365451934503686,5.35324068217491,5.340359131888224,5.3268547106161535,5.312752534776141,5.298003131259077,5.282659513167692,5.266626822732913,5.249921560660191,5.23268741923546,5.214855451950317,5.196556373382963,5.177331645989368,5.157381317053328,5.13690662505884,5.11588632471465,5.0936463721270355,5.034439712632794,4.997729335867598,4.9695796761402224,4.946060808068232,4.925533726099754,4.907327957321328,4.890943093993202,4.876525750762281,4.8639565036412975,4.853242011943706,4.843876871097703,4.836770361413522,4.830971574958802,4.826123635657966,4.822409824520756,4.819974572941985,4.868199805928916,4.876781683648012,4.872311685983061,4.863144287471585,4.850050268343288,4.835189479484915,4.818563199454164,4.800633997412649,4.781231994355247,4.76043934201093,4.738104819475959,4.714783549201062,4.690079552531268,4.6642321045838875,4.6369837185173575,4.608865676619527,4.579534581819854,4.5491663786069765,4.517695516661387,4.485588817541022,4.451824524138477,4.4172161842242,4.382084458867313,4.346139750111302,4.30912835106602,4.221645955818338,4.173739562463626,4.1388244010287085,4.108541048580038,4.081968489864706,4.0570159156165,4.0335633992391555,4.011164900043804,3.9899806513754537,3.9696190271919884,3.950286593716997,3.932072694294865,3.914725792016842,3.898072696512579,3.8823203888886386,3.867263835337139,3.8529281438254976,3.8391252562945506,3.8272077519842473,3.867616239414299,3.861965544818793,3.840230819476226,3.812212253390089,3.7816834067560348,3.7493679427134516,3.7162003982025253,3.6827711691715423,3.649232634151275,3.615385421822292,3.5815237289161383,3.5474146953256476,3.512889946142654,3.478147505844005,3.4428880624939575,3.407289867809545,3.3711871951931367,3.334353629377881,3.2969419971852396,3.2590263995502027,3.220397327043449,3.1810592115278897,3.1409958643695366,3.1003767315364503,3.057789859756168,2.9627692558575816,2.9136741786771587,2.880562001774208,2.853654677559798,2.8290102272411675,2.805890721107917,2.7835040585254482,2.7614193490341723,2.739150004250072,2.7169739563491713,2.694819794569428,2.6729083032332013,2.6511535665517076,2.629624676565133,2.608665340041496,2.587904538462948,2.5674791322112727,2.5476957582182327,2.528189459455035,2.5093179161923755,2.491175808283129,2.4733856243212133,2.4564794348594505,2.440055845417379,2.424547777425616,2.4094991429259416,2.395023563533783,2.3811656748629666,2.3678164769633216,2.3555197703229758,2.3439811949078804,2.338798941818805,2.3875402660439375,2.387844213381966,2.3716257740153366,2.3469333278762394,2.3188130397963516,2.288991899962453,2.2588265916438757,2.228507949160214,2.198711294305831,2.169310549937685,2.140076474853485,2.111389123884948,2.082889494062078,2.0544660628137006,2.0264841750892564,1.9983615578840987,1.970492549354466,1.942384868182705,1.9144470116916594,1.8865411595905175,1.8585102545195247,1.830355346845182,1.801604150414551,1.7724579467769153,1.7371331114128206,1.6479918543763177,1.6076280726517487,1.583858578987672,1.5686603190348345,1.5567928633002948,1.546642308228729,1.536853809516574,1.5268749608110588,1.5165425919476767,1.505991327066632,1.4949420014754522,1.4836304980388026,1.4719611101568915,1.4599753550966177,1.4480348834762635,1.4358719101401212,1.4235289567595089,1.4113482493595477,1.3990593138392566,1.3867439900074265,1.374679775035177,1.3627843196489067,1.3513796385487225,1.3402526809252675,1.3299186219866599,1.3197822687130811,1.3101644449587735,1.3014687049668743,1.2929082986405922,1.2851699821847407,1.2781772573574361,1.271760433576572,1.2664956407980454,1.2614667530509691,1.2574981691316267,1.2538851911202327,1.2514451364087291,1.2488351445635273,1.2470200628958767,1.2458082226561946,1.2456708968734607,1.4076062019959792,1.4421594099207353,1.4514387229429977,1.450166666710541,1.4431739757971094,1.4332297305766073,1.4216487905393063,1.4097133484090023,1.3971438197561756,1.3847628943809636,1.3722216008392534,1.359131040947447,1.3463445643639358,1.33317196706452,1.3196529437268316,1.3059427100227565,1.2915233375886734,1.2772191259872319,1.262003708805227,1.246783133408185,1.2304776931644599,1.2145416057352236,1.1979522968502894,1.1805386726916094,1.1621105778512615,0.9815869155463817,0.9281208171306597,0.8998670091044706,0.8820317536168027,0.8695876638588043,0.8599206989392968,0.8514264732942225,0.8431375833672823,0.8348177976847707,0.826232003187558,0.8174706487000527,0.8086306689064786,0.7995863818867724,0.7903285162268081,0.7809896421831165,0.7716395850278627,0.7620587499637478,0.7524256537735812,0.7428327641328549,0.7331341550088919,0.7236762398156241,0.7141237322347292,0.7047534711230162],\"yaxis\":\"y\",\"type\":\"scattergl\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15,\"font\":{\"size\":20}},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15,\"font\":{\"size\":20}},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05,\"font\":{\"size\":30}},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Epoch\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Rolling Avg Loss\"}},\"legend\":{\"title\":{\"text\":\"Color\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Training Curve for Modular Arithmetic - 70% Addition\"},\"updatemenus\":[{\"active\":-1,\"buttons\":[{\"args\":[{\"xaxis.type\":\"log\"}],\"args2\":[{\"xaxis.type\":\"linear\"}],\"label\":\"Log x-axis\",\"method\":\"relayout\"}],\"type\":\"buttons\",\"x\":-0.1,\"y\":1.0},{\"active\":-1,\"buttons\":[{\"args\":[{\"yaxis.type\":\"log\"}],\"args2\":[{\"yaxis.type\":\"linear\"}],\"label\":\"Log y-axis\",\"method\":\"relayout\"}],\"type\":\"buttons\",\"x\":-0.1,\"y\":0.85}]},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('83f91201-f49f-4642-9cff-e99220c85f8c');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                });            </script>        </div>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from neel_plotly.plot import line\n",
        "step = 10\n",
        "average_window = 250\n",
        "train_losses_avg = rolling_average(train_losses, average_window)\n",
        "test_losses_avg = rolling_average(test_losses, average_window)\n",
        "add_test_losses_avg = rolling_average(add_test_losses, average_window//10)\n",
        "multi_test_losses_avg = rolling_average(multi_test_losses, average_window//10)\n",
        "\n",
        "line([train_losses[::step], test_losses[::step], add_test_losses, multi_test_losses], x=np.arange(0, len(train_losses_avg), step), xaxis=\"Epoch\", yaxis=\"Loss\", log_y=False, title=f\"Training Curve for Modular Arithmetic - {addition_frac*100:.0f}% Addition\", line_labels=['train', 'test', 'add loss', 'multi loss'], toggle_x=True, toggle_y=True)\n",
        "line([train_losses_avg[::step], test_losses_avg[::step], add_test_losses_avg, multi_test_losses_avg], x=np.arange(0, len(train_losses_avg), step), xaxis=\"Epoch\", yaxis=\"Rolling Avg Loss\", log_y=False, title=f\"Training Curve for Modular Arithmetic - {addition_frac*100:.0f}% Addition\", line_labels=['train', 'test', 'add loss', 'multi loss'], toggle_x=True, toggle_y=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "TEST_PATH = \"../saves/test.pth\"\n",
        "torch.save(\n",
        "        {\n",
        "            \"train_data\": train_data,\n",
        "            \"train_labels\": train_labels,\n",
        "            \"test_data\": test_data,\n",
        "            \"test_labels\": test_labels,\n",
        "        },\n",
        "        TEST_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test_data.shape = torch.Size([16900, 3])\n",
            "test_data[:10] = tensor([[ 94,   0,  47],\n",
            "        [115,   0,  89],\n",
            "        [ 89,   1,  85],\n",
            "        [ 20,   0,  85],\n",
            "        [122,   1,  39],\n",
            "        [103,   0,   8],\n",
            "        [118,   1, 100],\n",
            "        [ 23,   1,  14],\n",
            "        [ 78,   0,  82],\n",
            "        [ 28,   1,  57]])\n"
          ]
        }
      ],
      "source": [
        "cached_data = torch.load(TEST_PATH, weights_only=False)\n",
        "test_data = cached_data['test_data']\n",
        "print(f\"test_data.shape = {test_data.shape}\")\n",
        "print(f\"test_data[:10] = {test_data[:10]}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "8859a5491331dba93123a91c2831400aced845b502848170e05fcb48b2c144be"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
