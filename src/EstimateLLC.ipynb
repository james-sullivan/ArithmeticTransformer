{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_losses) = 6000 len(test_losses) = 6000 len(model_checkpoints) = 120\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformer_lens import HookedTransformer, HookedTransformerConfig\n",
    "from neel_plotly.plot import line\n",
    "from helpers import loss_fn\n",
    "from devinterp.slt.sampler import estimate_learning_coeff_with_summary, estimate_learning_coeff, SGLD\n",
    "from devinterp.utils import plot_trace\n",
    "import tqdm.auto as tqdm\n",
    "import os\n",
    "from pathlib import Path\n",
    "from helpers import rolling_average\n",
    "\n",
    "CREATE_ESTIMATES = True\n",
    "TUNE_HYPERPARAMS = True\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "RAND_SEED = 42\n",
    "\n",
    "if CREATE_ESTIMATES:\n",
    "    LOAD_LOCATION = \"../saves/check_point_50/grokking_addition.pth\"\n",
    "\n",
    "    cached_data = torch.load(LOAD_LOCATION, weights_only=False)\n",
    "\n",
    "    state_dict = cached_data['model']\n",
    "    model_checkpoints = cached_data[\"checkpoints\"]\n",
    "    checkpoint_epochs = cached_data[\"checkpoint_epochs\"]\n",
    "    test_losses = cached_data['test_losses']\n",
    "    train_losses = cached_data['train_losses']\n",
    "    #add_test_losses = cached_data['add_test_losses']\n",
    "    #multi_test_losses = cached_data['multi_test_losses']\n",
    "    max_nums = cached_data['max_nums']\n",
    "    mod_value = cached_data['mod_value']\n",
    "    train_frac = cached_data['train_frac']\n",
    "    #addition_frac = cached_data['addition_frac']\n",
    "    train_data = cached_data['train_data']\n",
    "    train_labels = cached_data['train_labels']\n",
    "\n",
    "    # print(f\"train_frac = {train_frac} addition_frac = {addition_frac}\")\n",
    "    print(f\"len(train_losses) = {len(train_losses)} len(test_losses) = {len(test_losses)} len(model_checkpoints) = {len(model_checkpoints)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "if CREATE_ESTIMATES:\n",
    "    train_loader = DataLoader(TensorDataset(train_data, train_labels), batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CREATE_ESTIMATES:\n",
    "    cfg = HookedTransformerConfig(\n",
    "        n_layers = 1,\n",
    "        n_heads = 4,\n",
    "        d_model = 128,\n",
    "        d_head = 32,\n",
    "        d_mlp = 512,\n",
    "        act_fn = \"relu\",\n",
    "        normalization_type=None, # \"LN\",\n",
    "        d_vocab=max_nums+1,\n",
    "        d_vocab_out=mod_value,\n",
    "        n_ctx= 3,\n",
    "        init_weights=True,\n",
    "        device=device,\n",
    "        seed = RAND_SEED,\n",
    "    )\n",
    "\n",
    "    model = HookedTransformer(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Learning Coefficient (RLCT) Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 3e-2\n",
    "num_chains = 3\n",
    "num_draws = 150\n",
    "num_burnin_steps = 50\n",
    "num_steps_bw_draws = 1\n",
    "gamma = 5\n",
    "nbeta = 1.6\n",
    "sampling_method = \"sgld\"\n",
    "\n",
    "def evaluate(model, data):\n",
    "    inputs, outputs = data\n",
    "\n",
    "    return loss_fn(model(inputs), outputs), {\n",
    "        \"logits\": model(inputs)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the right hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "from typing import Type\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def estimate_llc_given_model(\n",
    "    model: torch.nn.Module,\n",
    "    loader: torch.utils.data.DataLoader,\n",
    "    evaluate: typing.Callable,\n",
    "    epsilon: float,\n",
    "    beta: float,\n",
    "    sampling_method: Type[torch.optim.Optimizer] = SGLD,\n",
    "    localization: float = 5.0,\n",
    "    num_chains: int = 3,\n",
    "    num_draws: int = 500,\n",
    "    num_burnin_steps: int = 0,\n",
    "    num_steps_bw_draws: int = 1,\n",
    "    device: torch.device = torch.device(\"cpu\"),\n",
    "    online: bool = True,\n",
    "    verbose: bool = False,\n",
    "):\n",
    "\n",
    "    sweep_stats = estimate_learning_coeff_with_summary(\n",
    "        model,\n",
    "        loader=loader,\n",
    "        evaluate=evaluate,\n",
    "        sampling_method=sampling_method,\n",
    "        optimizer_kwargs=dict(lr=epsilon, localization=localization, nbeta=beta),\n",
    "        num_chains=num_chains,  # How many independent chains to run\n",
    "        num_draws=num_draws,  # How many samples to draw per chain\n",
    "        num_burnin_steps=num_burnin_steps,  # How many samples to discard at the beginning of each chain\n",
    "        num_steps_bw_draws=num_steps_bw_draws,  # How many steps to take between each sample\n",
    "        device=device,\n",
    "        online=online,\n",
    "        verbose=verbose,\n",
    "    )\n",
    "\n",
    "    sweep_stats[\"llc/trace\"] = np.array(sweep_stats[\"llc/trace\"])\n",
    "    return sweep_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/james/dev/ArithmeticTransformer/.venv/lib/python3.12/site-packages/devinterp/vis_utils.py:86: UserWarning: Epsilon values greater than 1e-2 typically lead to instability in the sampling process. Consider reducing epsilon to between 1e-6 and 1e-2.\n",
      "  warnings.warn(\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]/Users/james/dev/ArithmeticTransformer/.venv/lib/python3.12/site-packages/devinterp/slt/sampler.py:118: UserWarning: Using passed in nbeta. Make sure callbacks are also initialized with the same nbeta.\n",
      "  warnings.warn(\n",
      "/Users/james/dev/ArithmeticTransformer/.venv/lib/python3.12/site-packages/devinterp/backends/default/slt/sampler.py:232: UserWarning: You are taking more draws than burn-in steps, your LLC estimates will likely be underestimates. Please check LLC chain convergence.\n",
      "  warnings.warn(\n",
      "/Users/james/dev/ArithmeticTransformer/.venv/lib/python3.12/site-packages/devinterp/backends/default/slt/sampler.py:236: UserWarning: You are taking more sample batches than there are dataloader batches available, this removes some randomness from sampling but is probably fine. (All sample batches beyond the number dataloader batches are cycled from the start, f.e. 9 samples from [A, B, C] would be [B, A, C, B, A, C, B, A, C].)\n",
      "  warnings.warn(\n",
      "/Users/james/dev/ArithmeticTransformer/.venv/lib/python3.12/site-packages/devinterp/backends/default/slt/sampler.py:277: UserWarning: If you're setting a nbeta or temperature in optimizer_kwargs, please also make sure to set it in the callbacks.\n",
      "  warnings.warn(\n",
      "/Users/james/dev/ArithmeticTransformer/.venv/lib/python3.12/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/Users/james/dev/ArithmeticTransformer/.venv/lib/python3.12/site-packages/devinterp/backends/default/slt/sampler.py:54: UserWarning: You are taking more sample batches than there are dataloader batches available, this removes some randomness from sampling but is probably fine. (All sample batches beyond the number dataloader batches are cycled from the start, f.e. 9 samples from [A, B, C] would be [B, A, C, B, A, C, B, A, C].)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/25 [00:05<02:06,  5.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2/25 [00:10<02:01,  5.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3/25 [00:15<01:57,  5.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 4/25 [00:21<01:53,  5.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 5/25 [00:27<01:48,  5.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 6/25 [00:32<01:45,  5.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 7/25 [00:38<01:41,  5.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 8/25 [00:44<01:38,  5.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 9/25 [00:50<01:33,  5.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 10/25 [00:56<01:26,  5.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 11/25 [01:01<01:19,  5.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 12/25 [01:07<01:13,  5.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 13/25 [01:13<01:08,  5.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 14/25 [01:19<01:03,  5.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 15/25 [01:25<00:58,  5.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 16/25 [01:31<00:54,  6.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 17/25 [01:38<00:49,  6.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 18/25 [01:44<00:42,  6.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 19/25 [01:50<00:37,  6.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 20/25 [01:56<00:31,  6.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 21/25 [02:03<00:25,  6.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 22/25 [02:09<00:19,  6.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 23/25 [02:15<00:12,  6.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 24/25 [02:22<00:06,  6.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [02:28<00:00,  5.93s/it]\n"
     ]
    }
   ],
   "source": [
    "from devinterp.vis_utils import EpsilonBetaAnalyzer\n",
    "\n",
    "if TUNE_HYPERPARAMS:\n",
    "    model.load_state_dict(model_checkpoints[-1])\n",
    "    analyzer = EpsilonBetaAnalyzer()\n",
    "    analyzer.configure_sweep(\n",
    "        llc_estimator=estimate_llc_given_model,\n",
    "        llc_estimator_kwargs=dict(\n",
    "            model=model,\n",
    "            evaluate=evaluate,\n",
    "            device=device,\n",
    "            loader=train_loader,\n",
    "        ),\n",
    "        min_epsilon=3e-5,\n",
    "        max_epsilon=3e-1,\n",
    "        epsilon_samples=5,\n",
    "        min_beta=None,\n",
    "        max_beta=None,\n",
    "        beta_samples=5,\n",
    "        dataloader=train_loader,\n",
    "    )\n",
    "    analyzer.sweep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TUNE_HYPERPARAMS:\n",
    "    analyzer.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/james/dev/ArithmeticTransformer/.venv/lib/python3.12/site-packages/devinterp/slt/sampler.py:118: UserWarning:\n",
      "\n",
      "Using passed in nbeta. Make sure callbacks are also initialized with the same nbeta.\n",
      "\n",
      "/Users/james/dev/ArithmeticTransformer/.venv/lib/python3.12/site-packages/devinterp/backends/default/slt/sampler.py:232: UserWarning:\n",
      "\n",
      "You are taking more draws than burn-in steps, your LLC estimates will likely be underestimates. Please check LLC chain convergence.\n",
      "\n",
      "/Users/james/dev/ArithmeticTransformer/.venv/lib/python3.12/site-packages/devinterp/backends/default/slt/sampler.py:277: UserWarning:\n",
      "\n",
      "If you're setting a nbeta or temperature in optimizer_kwargs, please also make sure to set it in the callbacks.\n",
      "\n",
      "/Users/james/dev/ArithmeticTransformer/.venv/lib/python3.12/site-packages/torch/storage.py:414: FutureWarning:\n",
      "\n",
      "You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nbeta = 1.6 gamma = 5 lr = 0.03\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chain 0: 100%|██████████| 200/200 [00:00<00:00, 277.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chain 1: 100%|██████████| 200/200 [00:00<00:00, 268.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chain 2: 100%|██████████| 200/200 [00:00<00:00, 282.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results.keys() = dict_keys(['init_loss', 'llc/means', 'llc/stds', 'llc/trace', 'loss/trace'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x900 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if TUNE_HYPERPARAMS:\n",
    "    print(f\"nbeta = {nbeta} gamma = {gamma} lr = {lr}\")\n",
    "\n",
    "    model.load_state_dict(model_checkpoints[60])\n",
    "\n",
    "    results = estimate_learning_coeff_with_summary(\n",
    "                    model,\n",
    "                    loader=train_loader,\n",
    "                    evaluate=evaluate,\n",
    "                    sampling_method=SGLD if sampling_method == \"sgld\" else None,\n",
    "                    optimizer_kwargs=dict(lr=lr, nbeta=nbeta, localization=gamma),\n",
    "                    num_chains=num_chains,                  # How many independent chains to run\n",
    "                    num_draws=num_draws,                    # How many samples to draw per chain\n",
    "                    num_burnin_steps=num_burnin_steps,      # How many samples to discard at the beginning of each chain\n",
    "                    num_steps_bw_draws=num_steps_bw_draws,  # How many steps to take between each sample\n",
    "                    device=device,\n",
    "                    online=True,\n",
    "                )\n",
    "    print(f\"results.keys() = {results.keys()}\")\n",
    "    plot_trace(\n",
    "        results[\"llc/trace\"],\n",
    "        \"Loss\",\n",
    "        x_axis=\"Step\",\n",
    "        title=f\"Loss Trace, avg LLC = {sum(results['llc/means']) / len(results['llc/means']):.2f}\",\n",
    "        plot_mean=False,\n",
    "        plot_std=False,\n",
    "        fig_size=(12, 9),\n",
    "        true_lc=None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate for model checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Addition frac = 0.3 Train frac = 0.5\n",
      "nbeta = 1.6 gamma = 5 lr = 0.03\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1dab6a76b4d472ca976012dab884c77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/james/dev/ArithmeticTransformer/.venv/lib/python3.12/site-packages/devinterp/slt/sampler.py:118: UserWarning: Using passed in nbeta. Make sure callbacks are also initialized with the same nbeta.\n",
      "  warnings.warn(\n",
      "/Users/james/dev/ArithmeticTransformer/.venv/lib/python3.12/site-packages/devinterp/backends/default/slt/sampler.py:232: UserWarning: You are taking more draws than burn-in steps, your LLC estimates will likely be underestimates. Please check LLC chain convergence.\n",
      "  warnings.warn(\n",
      "/Users/james/dev/ArithmeticTransformer/.venv/lib/python3.12/site-packages/devinterp/backends/default/slt/sampler.py:277: UserWarning: If you're setting a nbeta or temperature in optimizer_kwargs, please also make sure to set it in the callbacks.\n",
      "  warnings.warn(\n",
      "/Users/james/dev/ArithmeticTransformer/.venv/lib/python3.12/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chain 0: 100%|██████████| 200/200 [00:01<00:00, 190.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chain 1: 100%|██████████| 200/200 [00:00<00:00, 216.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chain 2: 100%|██████████| 200/200 [00:00<00:00, 209.26it/s]\n",
      "/Users/james/dev/ArithmeticTransformer/.venv/lib/python3.12/site-packages/devinterp/slt/sampler.py:118: UserWarning: Using passed in nbeta. Make sure callbacks are also initialized with the same nbeta.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result['llc/mean'] = 16.479957580566406\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chain 0: 100%|██████████| 200/200 [00:00<00:00, 211.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chain 1: 100%|██████████| 200/200 [00:00<00:00, 227.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chain 2:   7%|▋         | 14/200 [00:00<00:00, 221.63it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m saved_model \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(model_checkpoints):\n\u001b[1;32m     17\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_state_dict(saved_model)\n\u001b[0;32m---> 18\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mestimate_learning_coeff_with_summary\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                \u001b[49m\u001b[43mloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m                \u001b[49m\u001b[43mevaluate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m                \u001b[49m\u001b[43msampling_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSGLD\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msampling_method\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msgld\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m                \u001b[49m\u001b[43moptimizer_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnbeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocalization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgamma\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m                \u001b[49m\u001b[43mnum_chains\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_chains\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                  \u001b[49m\u001b[38;5;66;43;03m# How many independent chains to run\u001b[39;49;00m\n\u001b[1;32m     25\u001b[0m \u001b[43m                \u001b[49m\u001b[43mnum_draws\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_draws\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                    \u001b[49m\u001b[38;5;66;43;03m# How many samples to draw per chain\u001b[39;49;00m\n\u001b[1;32m     26\u001b[0m \u001b[43m                \u001b[49m\u001b[43mnum_burnin_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_burnin_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# How many samples to discard at the beginning of each chain\u001b[39;49;00m\n\u001b[1;32m     27\u001b[0m \u001b[43m                \u001b[49m\u001b[43mnum_steps_bw_draws\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_steps_bw_draws\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# How many steps to take between each sample\u001b[39;49;00m\n\u001b[1;32m     28\u001b[0m \u001b[43m                \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m                \u001b[49m\u001b[43monline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mllc/mean\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m] = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllc/mean\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     32\u001b[0m     llc_estimates\u001b[38;5;241m.\u001b[39mappend(result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllc/mean\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/dev/ArithmeticTransformer/.venv/lib/python3.12/site-packages/devinterp/slt/sampler.py:165\u001b[0m, in \u001b[0;36mestimate_learning_coeff_with_summary\u001b[0;34m(model, loader, callbacks, evaluate, sampling_method, optimizer_kwargs, num_draws, num_chains, num_burnin_steps, num_steps_bw_draws, init_loss, grad_accum_steps, cores, seed, device, gpu_idxs, verbose, optimize_over_per_model_param, online, use_amp)\u001b[0m\n\u001b[1;32m    155\u001b[0m     llc_estimator \u001b[38;5;241m=\u001b[39m LLCEstimator(\n\u001b[1;32m    156\u001b[0m         num_chains,\n\u001b[1;32m    157\u001b[0m         num_draws,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    160\u001b[0m         init_loss\u001b[38;5;241m=\u001b[39minit_loss,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [llc_estimator, \u001b[38;5;241m*\u001b[39mcallbacks]\n\u001b[0;32m--> 165\u001b[0m \u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevaluate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m    \u001b[49m\u001b[43msampling_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msampling_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_draws\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_draws\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_chains\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_chains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_burnin_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_burnin_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_steps_bw_draws\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_steps_bw_draws\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_accum_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_accum_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimize_over_per_model_param\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimize_over_per_model_param\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgpu_idxs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgpu_idxs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_amp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_amp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m results \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m callbacks:\n",
      "File \u001b[0;32m~/dev/ArithmeticTransformer/.venv/lib/python3.12/site-packages/devinterp/backends/default/slt/sampler.py:361\u001b[0m, in \u001b[0;36msample\u001b[0;34m(model, loader, callbacks, evaluate, sampling_method, optimizer_kwargs, num_draws, num_chains, num_burnin_steps, num_steps_bw_draws, init_loss, grad_accum_steps, cores, seed, device, verbose, optimize_over_per_model_param, gpu_idxs, batch_size, use_amp, **kwargs)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_chains):\n\u001b[0;32m--> 361\u001b[0m         \u001b[43m_sample_single_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseeds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshared_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m callbacks:\n\u001b[1;32m    364\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(callback, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinalize\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/dev/ArithmeticTransformer/.venv/lib/python3.12/site-packages/devinterp/backends/default/slt/sampler.py:139\u001b[0m, in \u001b[0;36m_sample_single_chain\u001b[0;34m(kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m loader \u001b[38;5;241m=\u001b[39m cloudpickle\u001b[38;5;241m.\u001b[39mloads(kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloader\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    138\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickled_args}\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msample_single_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/ArithmeticTransformer/.venv/lib/python3.12/site-packages/devinterp/backends/default/slt/sampler.py:103\u001b[0m, in \u001b[0;36msample_single_chain\u001b[0;34m(ref_model, loader, evaluate, optimizer_kwargs, num_draws, num_burnin_steps, num_steps_bw_draws, grad_accum_steps, sampling_method, chain, seed, verbose, device, optimize_over_per_model_param, callbacks, use_amp, **kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m data \u001b[38;5;241m=\u001b[39m prepare_input(data, device)\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautocast(\n\u001b[1;32m    101\u001b[0m     device_type\u001b[38;5;241m=\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16, enabled\u001b[38;5;241m=\u001b[39muse_amp\n\u001b[1;32m    102\u001b[0m ):\n\u001b[0;32m--> 103\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m     loss, results \u001b[38;5;241m=\u001b[39m split_results(results)\n\u001b[1;32m    106\u001b[0m     loss \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m grad_accum_steps\n",
      "Cell \u001b[0;32mIn[10], line 8\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(model, data)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate\u001b[39m(model, data):\n\u001b[1;32m      5\u001b[0m     inputs, outputs \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_fn(model(inputs), outputs), {\n\u001b[0;32m----> 8\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogits\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     }\n",
      "File \u001b[0;32m~/dev/ArithmeticTransformer/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/ArithmeticTransformer/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/ArithmeticTransformer/.venv/lib/python3.12/site-packages/transformer_lens/HookedTransformer.py:561\u001b[0m, in \u001b[0;36mHookedTransformer.forward\u001b[0;34m(self, input, return_type, loss_per_token, prepend_bos, padding_side, start_at_layer, tokens, shortformer_pos_embed, attention_mask, stop_at_layer, past_kv_cache)\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shortformer_pos_embed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    557\u001b[0m         shortformer_pos_embed \u001b[38;5;241m=\u001b[39m shortformer_pos_embed\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m    558\u001b[0m             devices\u001b[38;5;241m.\u001b[39mget_device_for_block_index(i, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg)\n\u001b[1;32m    559\u001b[0m         )\n\u001b[0;32m--> 561\u001b[0m     residual \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Cache contains a list of HookedTransformerKeyValueCache objects, one for each\u001b[39;49;00m\n\u001b[1;32m    564\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# block\u001b[39;49;00m\n\u001b[1;32m    565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_kv_cache_entry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_kv_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpast_kv_cache\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n\u001b[1;32m    570\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stop_at_layer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;66;03m# When we stop at an early layer, we end here rather than doing further computation\u001b[39;00m\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m residual\n",
      "File \u001b[0;32m~/dev/ArithmeticTransformer/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/ArithmeticTransformer/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/ArithmeticTransformer/.venv/lib/python3.12/site-packages/transformer_lens/components/transformer_block.py:160\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[0;34m(self, resid_pre, shortformer_pos_embed, past_kv_cache_entry, attention_mask)\u001b[0m\n\u001b[1;32m    152\u001b[0m     key_input \u001b[38;5;241m=\u001b[39m attn_in\n\u001b[1;32m    153\u001b[0m     value_input \u001b[38;5;241m=\u001b[39m attn_in\n\u001b[1;32m    155\u001b[0m attn_out \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;66;03m# hook the residual stream states that are used to calculate the\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# queries, keys and values, independently.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;66;03m# Then take the layer norm of these inputs, and pass these to the attention module.\u001b[39;00m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn(\n\u001b[0;32m--> 160\u001b[0m         query_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m0.0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m shortformer_pos_embed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m shortformer_pos_embed),\n\u001b[1;32m    162\u001b[0m         key_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln1(key_input)\n\u001b[1;32m    163\u001b[0m         \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m0.0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m shortformer_pos_embed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m shortformer_pos_embed),\n\u001b[1;32m    164\u001b[0m         value_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln1(value_input),\n\u001b[1;32m    165\u001b[0m         past_kv_cache_entry\u001b[38;5;241m=\u001b[39mpast_kv_cache_entry,\n\u001b[1;32m    166\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m    167\u001b[0m     )\n\u001b[1;32m    168\u001b[0m )  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39muse_normalization_before_and_after:\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;66;03m# If we use LayerNorm both before and after, then apply the second LN after the layer\u001b[39;00m\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;66;03m# and before the hook. We do it before the hook so hook_attn_out captures \"that which\u001b[39;00m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;66;03m# is added to the residual stream\"\u001b[39;00m\n\u001b[1;32m    173\u001b[0m     attn_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln1_post(attn_out)\n",
      "File \u001b[0;32m~/dev/ArithmeticTransformer/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/ArithmeticTransformer/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/ArithmeticTransformer/.venv/lib/python3.12/site-packages/transformer_lens/components/layer_norm.py:53\u001b[0m, in \u001b[0;36mLayerNorm.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     49\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     51\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m-\u001b[39m x\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# [batch, pos, length]\u001b[39;00m\n\u001b[1;32m     52\u001b[0m scale: Float[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch pos 1\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_scale(\n\u001b[0;32m---> 53\u001b[0m     (\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meps)\u001b[38;5;241m.\u001b[39msqrt()\n\u001b[1;32m     54\u001b[0m )\n\u001b[1;32m     55\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m/\u001b[39m scale  \u001b[38;5;66;03m# [batch, pos, length]\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_normalized(x \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mdtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from devinterp.slt.sampler import estimate_learning_coeff_with_summary, estimate_learning_coeff, SGLD\n",
    "from devinterp.utils import plot_trace\n",
    "\n",
    "def evaluate(model, data):\n",
    "    inputs, outputs = data\n",
    "\n",
    "    return loss_fn(model(inputs), outputs), {\n",
    "        \"logits\": model(inputs)\n",
    "    }\n",
    "\n",
    "if CREATE_ESTIMATES:\n",
    "    print(f\"Addition frac = {addition_frac} Train frac = {train_frac}\")\n",
    "    print(f\"nbeta = {nbeta} gamma = {gamma} lr = {lr}\")\n",
    "    llc_estimates = []\n",
    "\n",
    "    for saved_model in tqdm.tqdm(model_checkpoints):\n",
    "        model.load_state_dict(saved_model)\n",
    "        result = estimate_learning_coeff_with_summary(\n",
    "                    model,\n",
    "                    loader=train_loader,\n",
    "                    evaluate=evaluate,\n",
    "                    sampling_method=SGLD if sampling_method == \"sgld\" else None,\n",
    "                    optimizer_kwargs=dict(lr=lr, nbeta=nbeta, localization=gamma),\n",
    "                    num_chains=num_chains,                  # How many independent chains to run\n",
    "                    num_draws=num_draws,                    # How many samples to draw per chain\n",
    "                    num_burnin_steps=num_burnin_steps,      # How many samples to discard at the beginning of each chain\n",
    "                    num_steps_bw_draws=num_steps_bw_draws,  # How many steps to take between each sample\n",
    "                    device=device,\n",
    "                    online=False,\n",
    "                )\n",
    "        print(f\"result['llc/mean'] = {result[\"llc/mean\"]}\")\n",
    "        llc_estimates.append(result[\"llc/mean\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "addition_frac = 0.3 train_frac = 0.5\n",
      "Saved to ../saves/check_point_50/llc_estimates_0.3.pth\n"
     ]
    }
   ],
   "source": [
    "SAVE_LOCATION = \"../saves/check_point_50/llc_estimates_0.3.pth\"\n",
    "\n",
    "if CREATE_ESTIMATES:\n",
    "    os.makedirs(Path(SAVE_LOCATION).parent, exist_ok=True)\n",
    "    torch.save({\n",
    "        \"llc_estimates\": llc_estimates,\n",
    "        \"lr\": lr,\n",
    "        \"nbeta\": nbeta,\n",
    "        \"gamma\": gamma,\n",
    "        \"num_chains\": num_chains,\n",
    "        \"num_draws\": num_draws,\n",
    "        \"num_burnin_steps\": num_burnin_steps,\n",
    "        \"num_steps_bw_draws\": num_steps_bw_draws,\n",
    "        \"sampling_method\": sampling_method,\n",
    "        \"train_frac\": train_frac,\n",
    "        \"addition_frac\": addition_frac,\n",
    "        \"LOAD_LOCATION\": LOAD_LOCATION,\n",
    "    }, SAVE_LOCATION)\n",
    "    print(f\"addition_frac = {addition_frac} train_frac = {train_frac}\")\n",
    "    print(f\"Saved to {SAVE_LOCATION}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "addition_frac = 0.5 train_frac = 0.5 len(llc_estimates) = 120\n",
      "Estimate created from ../saves/check_point_50/grokking_add_multi_0.5.pth\n",
      "len(train_losses) = 6000 len(test_losses) = 6000\n"
     ]
    }
   ],
   "source": [
    "LOAD_DATA_PATH = \"../saves/check_point_50/llc_estimates_0.5.pth\"\n",
    "if not CREATE_ESTIMATES:\n",
    "    cached_data = torch.load(LOAD_DATA_PATH, weights_only=False)\n",
    "    llc_estimates = cached_data['llc_estimates']\n",
    "    lr = cached_data['lr']\n",
    "    nbeta = cached_data['nbeta']\n",
    "    gamma = cached_data['gamma']\n",
    "    num_chains = cached_data['num_chains']\n",
    "    num_draws = cached_data['num_draws']\n",
    "    num_burnin_steps = cached_data['num_burnin_steps']\n",
    "    num_steps_bw_draws = cached_data['num_steps_bw_draws']\n",
    "    sampling_method = cached_data['sampling_method']\n",
    "    train_frac = cached_data['train_frac']\n",
    "    addition_frac = cached_data['addition_frac']\n",
    "    training_data_path = cached_data['LOAD_LOCATION']\n",
    "    print(f\"addition_frac = {addition_frac} train_frac = {train_frac} len(llc_estimates) = {len(llc_estimates)}\")\n",
    "    print(f\"Estimate created from {training_data_path}\")\n",
    "\n",
    "    training_data = torch.load(training_data_path, weights_only=False)\n",
    "    train_losses = training_data['train_losses']\n",
    "    test_losses = training_data['test_losses']\n",
    "    add_test_losses = training_data['add_test_losses']\n",
    "    multi_test_losses = training_data['multi_test_losses']\n",
    "    print(f\"len(train_losses) = {len(train_losses)} len(test_losses) = {len(test_losses)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make some cool graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "Epoch=%{x}<br>LLC=%{y}<extra></extra>",
         "legendgroup": "",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119
         ],
         "xaxis": "x",
         "y": [
          16.479957580566406,
          20.048080444335938,
          23.074201583862305,
          24.009546279907227,
          24.334497451782227,
          24.003591537475586,
          23.629514694213867,
          23.973440170288086,
          23.556272506713867,
          23.399778366088867,
          23.467668533325195,
          23.334177017211914,
          23.399206161499023,
          23.016393661499023,
          22.95465087890625,
          22.84465217590332,
          22.70098304748535,
          22.795373916625977,
          22.44291114807129,
          21.996152877807617,
          21.812368392944336,
          21.918210983276367,
          22.005388259887695,
          22.094329833984375,
          21.24054527282715,
          21.232282638549805,
          20.82445526123047,
          20.829740524291992,
          21.035390853881836,
          20.71051597595215,
          20.707468032836914,
          20.35664176940918,
          20.386228561401367,
          20.59971046447754,
          20.542348861694336,
          20.320039749145508,
          20.627408981323242,
          19.99530029296875,
          20.009565353393555,
          18.847105026245117,
          20.071855545043945,
          20.169775009155273,
          20.080974578857422,
          19.91028594970703,
          20.07011604309082,
          20.332183837890625,
          20.333694458007812,
          20.146087646484375,
          19.817420959472656,
          20.010583877563477,
          19.915557861328125,
          20.198240280151367,
          19.84882926940918,
          20.415082931518555,
          19.936140060424805,
          19.937158584594727,
          19.833770751953125,
          19.52684211730957,
          19.713939666748047,
          19.41980743408203,
          19.711328506469727,
          19.79450798034668,
          19.885665893554688,
          20.137802124023438,
          20.19316864013672,
          19.358346939086914,
          19.606672286987305,
          19.45249366760254,
          18.923805236816406,
          19.667158126831055,
          19.611854553222656,
          19.564725875854492,
          19.830184936523438,
          19.505340576171875,
          19.598709106445312,
          19.97844123840332,
          20.062952041625977,
          19.74314308166504,
          20.122770309448242,
          19.656824111938477,
          19.17273712158203,
          19.133543014526367,
          19.087005615234375,
          19.300025939941406,
          19.28624153137207,
          19.44236946105957,
          19.904592514038086,
          19.50224494934082,
          19.71489715576172,
          19.876296997070312,
          19.830446243286133,
          20.126800537109375,
          19.00998306274414,
          19.53801918029785,
          19.431222915649414,
          19.04078483581543,
          19.07149314880371,
          19.2233829498291,
          19.17755126953125,
          19.086959838867188,
          19.347389221191406,
          19.405370712280273,
          19.642641067504883,
          19.686269760131836,
          19.593603134155273,
          19.863191604614258,
          19.907800674438477,
          20.134950637817383,
          19.416568756103516,
          19.643423080444336,
          19.152687072753906,
          19.028579711914062,
          19.11075782775879,
          18.64345359802246,
          18.978639602661133,
          19.078140258789062,
          19.35706329345703,
          19.522994995117188,
          19.377668380737305,
          19.689104080200195
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "LLC - addition_frac = 0.3 nbeta = 1.6 epsilon = 0.03 gamma = 5"
        },
        "updatemenus": [
         {
          "active": -1,
          "buttons": [
           {
            "args": [
             {
              "xaxis.type": "log"
             }
            ],
            "args2": [
             {
              "xaxis.type": "linear"
             }
            ],
            "label": "Log x-axis",
            "method": "relayout"
           }
          ],
          "type": "buttons",
          "x": -0.1,
          "y": 1
         },
         {
          "active": -1,
          "buttons": [
           {
            "args": [
             {
              "yaxis.type": "log"
             }
            ],
            "args2": [
             {
              "yaxis.type": "linear"
             }
            ],
            "label": "Log y-axis",
            "method": "relayout"
           }
          ],
          "type": "buttons",
          "x": -0.1,
          "y": 0.85
         }
        ],
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Epoch"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "LLC"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "Epoch=%{x}<br>Rolling Average LLC=%{y}<extra></extra>",
         "legendgroup": "",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119
         ],
         "xaxis": "x",
         "y": [
          16.479957580566406,
          18.264019012451172,
          19.86741320292155,
          20.90294647216797,
          21.58925666809082,
          23.093983459472657,
          23.810270309448242,
          23.9901180267334,
          23.899463272094728,
          23.712519454956055,
          23.605334854125978,
          23.546267318725587,
          23.431420516967773,
          23.323444747924803,
          23.23441925048828,
          23.109815979003905,
          22.983177185058594,
          22.862410736083984,
          22.747714233398437,
          22.556014633178712,
          22.349557876586914,
          22.193003463745118,
          22.03500633239746,
          21.965290069580078,
          21.814168548583986,
          21.69815139770508,
          21.4794002532959,
          21.244270706176756,
          21.03248291015625,
          20.92647705078125,
          20.821514129638672,
          20.727951431274413,
          20.63924903869629,
          20.55211296081543,
          20.518479537963866,
          20.440993881225587,
          20.4951473236084,
          20.416961669921875,
          20.29893264770508,
          19.959883880615234,
          19.91024703979492,
          19.818720245361327,
          19.835855102539064,
          19.815999221801757,
          20.060601425170898,
          20.112667083740234,
          20.14545097351074,
          20.158473587036134,
          20.139900588989256,
          20.12799415588379,
          20.04466896057129,
          20.017578125,
          19.95812644958496,
          20.07765884399414,
          20.062770080566406,
          20.067090225219726,
          19.994196319580077,
          19.929798889160157,
          19.789570236206053,
          19.6863037109375,
          19.6411376953125,
          19.633285140991212,
          19.705049896240233,
          19.789822387695313,
          19.94449462890625,
          19.873898315429688,
          19.836331176757813,
          19.749696731567383,
          19.506897354125975,
          19.401695251464844,
          19.45239677429199,
          19.44400749206543,
          19.51954574584961,
          19.635852813720703,
          19.622163009643554,
          19.695480346679688,
          19.795125579833986,
          19.777717208862306,
          19.901203155517578,
          19.912826156616212,
          19.751685333251952,
          19.56580352783203,
          19.4345760345459,
          19.27002716064453,
          19.19591064453125,
          19.249837112426757,
          19.4040470123291,
          19.48709487915039,
          19.570069122314454,
          19.6880802154541,
          19.765695571899414,
          19.81013717651367,
          19.711684799194337,
          19.676309204101564,
          19.587294387817384,
          19.429362106323243,
          19.21830062866211,
          19.2609806060791,
          19.18888702392578,
          19.120034408569335,
          19.181355285644532,
          19.248130798339844,
          19.331982421875,
          19.433726119995118,
          19.535054779052736,
          19.638215255737304,
          19.738701248168944,
          19.837163162231445,
          19.783222961425782,
          19.793186950683594,
          19.651086044311523,
          19.47524185180664,
          19.27040328979492,
          19.11578025817871,
          18.98282356262207,
          18.967914199829103,
          19.033610916137697,
          19.116058349609375,
          19.262901306152344,
          19.404994201660156
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Learning Coefficient Estimates"
        },
        "updatemenus": [
         {
          "active": -1,
          "buttons": [
           {
            "args": [
             {
              "xaxis.type": "log"
             }
            ],
            "args2": [
             {
              "xaxis.type": "linear"
             }
            ],
            "label": "Log x-axis",
            "method": "relayout"
           }
          ],
          "type": "buttons",
          "x": -0.1,
          "y": 1
         },
         {
          "active": -1,
          "buttons": [
           {
            "args": [
             {
              "yaxis.type": "log"
             }
            ],
            "args2": [
             {
              "yaxis.type": "linear"
             }
            ],
            "label": "Log y-axis",
            "method": "relayout"
           }
          ],
          "type": "buttons",
          "x": -0.1,
          "y": 0.85
         }
        ],
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Epoch"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Rolling Average LLC"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "average_window = 5\n",
    "llc_estimates_avg = rolling_average(llc_estimates, average_window)\n",
    "line(llc_estimates, xaxis=\"Epoch\", yaxis=\"LLC\", title=f\"LLC - addition_frac = {addition_frac} nbeta = {nbeta} epsilon = {lr} gamma = {gamma}\", log_y=False, toggle_x=True, toggle_y=True)\n",
    "line(llc_estimates_avg, xaxis=\"Epoch\", yaxis=\"Rolling Average LLC\", title=\"Learning Coefficient Estimates\", log_y=False, toggle_x=True, toggle_y=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
