{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cil-TiwB2UV1"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/TransformerLensOrg/TransformerLens/blob/main/demos/Grokking_Demo.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2A9Wv1do2UV2"
      },
      "source": [
        "# Grokking Demo Notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A13-7Mc62UV3"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 475,
      "metadata": {
        "id": "Q998xCML2UV3"
      },
      "outputs": [],
      "source": [
        "TRAIN_MODEL = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 476,
      "metadata": {
        "id": "zUBTNnz62UV3",
        "outputId": "3658e07b-1cba-42b8-f23b-a319f209561a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running as a Jupyter notebook - intended for development only!\n",
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/85/m4tlmmlj4w58khykxvwgvt980000gn/T/ipykernel_81976/2858945602.py:22: DeprecationWarning:\n",
            "\n",
            "`magic(...)` is deprecated since IPython 0.13 (warning added in 8.1), use run_line_magic(magic_name, parameter_s).\n",
            "\n",
            "/var/folders/85/m4tlmmlj4w58khykxvwgvt980000gn/T/ipykernel_81976/2858945602.py:23: DeprecationWarning:\n",
            "\n",
            "`magic(...)` is deprecated since IPython 0.13 (warning added in 8.1), use run_line_magic(magic_name, parameter_s).\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Janky code to do different setup when run in a Colab notebook vs VSCode\n",
        "import os\n",
        "\n",
        "DEVELOPMENT_MODE = True\n",
        "IN_GITHUB = os.getenv(\"GITHUB_ACTIONS\") == \"true\"\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"Running as a Colab notebook\")\n",
        "\n",
        "    # PySvelte is an unmaintained visualization library, use it as a backup if circuitsvis isn't working\n",
        "    # # Install another version of node that makes PySvelte work way faster\n",
        "    # !curl -fsSL https://deb.nodesource.com/setup_16.x | sudo -E bash -; sudo apt-get install -y nodejs\n",
        "    # %pip install git+https://github.com/neelnanda-io/PySvelte.git\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    print(\"Running as a Jupyter notebook - intended for development only!\")\n",
        "    from IPython import get_ipython\n",
        "\n",
        "    ipython = get_ipython()\n",
        "    # Code to automatically update the HookedTransformer code as its edited without restarting the kernel\n",
        "    ipython.magic(\"load_ext autoreload\")\n",
        "    ipython.magic(\"autoreload 2\")\n",
        "\n",
        "if IN_COLAB or IN_GITHUB:\n",
        "    %pip install transformer_lens\n",
        "    %pip install circuitsvis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 477,
      "metadata": {
        "id": "I8nEQDlP2UV4",
        "outputId": "a46ab340-d447-407c-9e3d-36be3ef04ad3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using renderer: notebook_connected\n"
          ]
        }
      ],
      "source": [
        "# Plotly needs a different renderer for VSCode/Notebooks vs Colab argh\n",
        "import plotly.io as pio\n",
        "if IN_COLAB or not DEVELOPMENT_MODE:\n",
        "    pio.renderers.default = \"colab\"\n",
        "else:\n",
        "    pio.renderers.default = \"notebook_connected\"\n",
        "print(f\"Using renderer: {pio.renderers.default}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 478,
      "metadata": {
        "id": "rp4RGtCp2UV4"
      },
      "outputs": [],
      "source": [
        "pio.templates['plotly'].layout.xaxis.title.font.size = 20\n",
        "pio.templates['plotly'].layout.yaxis.title.font.size = 20\n",
        "pio.templates['plotly'].layout.title.font.size = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 479,
      "metadata": {
        "id": "RpPUz36r2UV4"
      },
      "outputs": [],
      "source": [
        "# Import stuff\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import einops\n",
        "from fancy_einsum import einsum\n",
        "import os\n",
        "import tqdm.auto as tqdm\n",
        "import random\n",
        "from pathlib import Path\n",
        "import plotly.express as px\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from typing import List, Union, Optional\n",
        "from functools import partial\n",
        "import copy\n",
        "\n",
        "import itertools\n",
        "from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n",
        "import dataclasses\n",
        "import datasets\n",
        "from IPython.display import HTML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 480,
      "metadata": {
        "id": "NmIM5yWr2UV4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "device: cpu\n"
          ]
        }
      ],
      "source": [
        "import transformer_lens\n",
        "import transformer_lens.utils as utils\n",
        "from transformer_lens.hook_points import (\n",
        "    HookedRootModule,\n",
        "    HookPoint,\n",
        ")  # Hooking utilities\n",
        "from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "print(f\"device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5bjmWrq2UV5"
      },
      "source": [
        "Plotting helper functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 481,
      "metadata": {
        "id": "aZe03f--2UV5"
      },
      "outputs": [],
      "source": [
        "def imshow(tensor, renderer=None, xaxis=\"\", yaxis=\"\", **kwargs):\n",
        "    px.imshow(utils.to_numpy(tensor), color_continuous_midpoint=0.0, color_continuous_scale=\"RdBu\", labels={\"x\":xaxis, \"y\":yaxis}, **kwargs).show(renderer)\n",
        "\n",
        "def line(tensor, renderer=None, xaxis=\"\", yaxis=\"\", **kwargs):\n",
        "    px.line(utils.to_numpy(tensor), labels={\"x\":xaxis, \"y\":yaxis}, **kwargs).show(renderer)\n",
        "\n",
        "def scatter(x, y, xaxis=\"\", yaxis=\"\", caxis=\"\", renderer=None, **kwargs):\n",
        "    x = utils.to_numpy(x)\n",
        "    y = utils.to_numpy(y)\n",
        "    px.scatter(y=y, x=x, labels={\"x\":xaxis, \"y\":yaxis, \"color\":caxis}, **kwargs).show(renderer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 482,
      "metadata": {
        "id": "xHscervl2UV5"
      },
      "outputs": [],
      "source": [
        "# Define the location to save the model, using a relative path\n",
        "PTH_LOCATION = \"workspace/_scratch/grokking_demo.pth\"\n",
        "\n",
        "# Create the directory if it does not exist\n",
        "os.makedirs(Path(PTH_LOCATION).parent, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EE1YCCg2UV5"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWEDLfns2UV5"
      },
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 483,
      "metadata": {
        "id": "2-6AgR5N2UV5"
      },
      "outputs": [],
      "source": [
        "frac_train = 0.3\n",
        "\n",
        "# Optimizer config\n",
        "lr = 1e-3\n",
        "wd = 1.\n",
        "betas = (0.9, 0.98)\n",
        "\n",
        "num_epochs = 30000\n",
        "checkpoint_every = 200\n",
        "\n",
        "DATA_SEED = 598"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqhvJcjT2UV5"
      },
      "source": [
        "## Define Task\n",
        "* Define modular addition\n",
        "* Define the dataset & labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 484,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dataset.shape = torch.Size([12769, 2])\n",
            "dataset[:5] = tensor([[0, 0],\n",
            "        [0, 1],\n",
            "        [0, 2],\n",
            "        [0, 3],\n",
            "        [0, 4]])\n"
          ]
        }
      ],
      "source": [
        "num_of_ops = 1\n",
        "max_nums = 113\n",
        "mod_value = 113\n",
        "\n",
        "# Generate all combinations\n",
        "a_vector = einops.repeat(torch.arange(max_nums), \"a -> (a b o)\", b=max_nums, o=num_of_ops)\n",
        "b_vector = einops.repeat(torch.arange(max_nums), \"b -> (a b o)\", a=max_nums, o=num_of_ops)\n",
        "operations = einops.repeat(torch.arange(num_of_ops), \"o -> (a b o)\", a=max_nums, b=max_nums)\n",
        "mod_vector = torch.full((max_nums * max_nums * num_of_ops,), mod_value)\n",
        "\n",
        "# Stack the vectors to create the\n",
        "if num_of_ops == 1:\n",
        "    dataset = torch.stack([a_vector, b_vector], dim=1)\n",
        "else:\n",
        "    dataset = torch.stack([a_vector, operations, b_vector], dim=1)\n",
        "\n",
        "print(f\"dataset.shape = {dataset.shape}\")\n",
        "print(f\"dataset[:5] = {dataset[:5]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 485,
      "metadata": {
        "id": "yZIYobGO2UV6",
        "outputId": "311f5c73-3859-4b6f-eb2c-5908ebcf4926"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([12769])\n",
            "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
            "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
            "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
            "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
            "        72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
            "        90, 91, 92, 93, 94, 95, 96, 97, 98, 99])\n"
          ]
        }
      ],
      "source": [
        "if num_of_ops == 1:\n",
        "    labels = (dataset[:, 0] + dataset[:, 1]) % p\n",
        "else:\n",
        "    labels = ((dataset[:, 0] + dataset[:, 2]) * (1 - dataset[:, 1]) + \n",
        "                (dataset[:, 0] * dataset[:, 2]) * dataset[:, 1]) % p\n",
        "print(labels.shape)\n",
        "print(labels[:100])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lv0e7P-W2UV6"
      },
      "source": [
        "Convert this to a train + test set - 30% in the training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 486,
      "metadata": {
        "id": "BbIhQkxK2UV6",
        "outputId": "84c412b2-e88b-4fa6-d6c7-f8a89a634f51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_data.shape = torch.Size([3830, 2])\n",
            "train_labels.shape = torch.Size([3830])\n",
            "test_data.shape = torch.Size([8939, 2])\n",
            "test_labels.shape = torch.Size([8939])\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(DATA_SEED)\n",
        "indices = torch.randperm(len(dataset))\n",
        "cutoff = int(len(indices)*frac_train)\n",
        "train_indices = indices[:cutoff]\n",
        "test_indices = indices[cutoff:]\n",
        "\n",
        "train_data = dataset[train_indices]\n",
        "train_labels = labels[train_indices]\n",
        "test_data = dataset[test_indices]\n",
        "test_labels = labels[test_indices]\n",
        "print(f\"train_data.shape = {train_data.shape}\")\n",
        "print(f\"train_labels.shape = {train_labels.shape}\")\n",
        "print(f\"test_data.shape = {test_data.shape}\")\n",
        "print(f\"test_labels.shape = {test_labels.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mcd2dy9x2UV6"
      },
      "source": [
        "## Define Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 487,
      "metadata": {
        "id": "GO7-UYjQ2UV6"
      },
      "outputs": [],
      "source": [
        "\n",
        "cfg = HookedTransformerConfig(\n",
        "    n_layers = 1,\n",
        "    n_heads = 4,\n",
        "    d_model = 128,\n",
        "    d_head = 32,\n",
        "    d_mlp = 512,\n",
        "    act_fn = \"relu\",\n",
        "    normalization_type=None,\n",
        "    d_vocab=p+1,\n",
        "    d_vocab_out=p,\n",
        "    n_ctx=dataset.size(1),\n",
        "    init_weights=True,\n",
        "    device=device,\n",
        "    seed = 999,\n",
        ")\n",
        "\n",
        "model = HookedTransformer(cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qNAf_pY2UV6"
      },
      "source": [
        "Disable the biases, as we don't need them for this task and it makes things easier to interpret."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 488,
      "metadata": {
        "id": "9Y6S95XF2UV6"
      },
      "outputs": [],
      "source": [
        "for name, param in model.named_parameters():\n",
        "    if \"b_\" in name:\n",
        "        param.requires_grad = False\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQtU2xX02UV6"
      },
      "source": [
        "## Define Optimizer + Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 489,
      "metadata": {
        "id": "kt9M_v7a2UV6"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd, betas=betas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 490,
      "metadata": {
        "id": "Aa0E-GvJ2UV6",
        "outputId": "9a149f5d-53d0-42ce-c387-f07f6360c5cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(4.7353, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
            "tensor(4.7343, dtype=torch.float64, grad_fn=<NegBackward0>)\n"
          ]
        }
      ],
      "source": [
        "def loss_fn(logits, labels):\n",
        "    if len(logits.shape)==3:\n",
        "        logits = logits[:, -1]\n",
        "    logits = logits.to(torch.float64)\n",
        "    log_probs = logits.log_softmax(dim=-1)\n",
        "    correct_log_probs = log_probs.gather(dim=-1, index=labels[:, None])[:, 0]\n",
        "    return -correct_log_probs.mean()\n",
        "train_logits = model(train_data)\n",
        "train_loss = loss_fn(train_logits, train_labels)\n",
        "print(train_loss)\n",
        "test_logits = model(test_data)\n",
        "test_loss = loss_fn(test_logits, test_labels)\n",
        "print(test_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 491,
      "metadata": {
        "id": "lepXc7Qp2UV7",
        "outputId": "5109e5e7-134d-4573-c37b-1f30c2f4a9dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Uniform loss:\n",
            "4.727387818712341\n"
          ]
        }
      ],
      "source": [
        "print(\"Uniform loss:\")\n",
        "print(np.log(p))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOuSwO1U2UV7"
      },
      "source": [
        "## Actually Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 492,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "c477d3a6463646deb7cf1de99bb0199a"
          ]
        },
        "id": "B78ji8Si2UV7",
        "outputId": "db8171c9-35a3-497a-aa61-a9b8efeee374"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6c96f03ac2e5479abbc49c9f60793144",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/30000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 199 Train Loss 0.041348269458804036 Test Loss 19.48617219535517\n",
            "Epoch 399 Train Loss 0.003746195121166419 Test Loss 21.942059109641917\n",
            "Epoch 599 Train Loss 0.00041157979416573087 Test Loss 24.593025608894166\n",
            "Epoch 799 Train Loss 4.847233861005623e-05 Test Loss 27.268220196194832\n",
            "Epoch 999 Train Loss 6.285739721184644e-06 Test Loss 29.848121644834933\n",
            "Epoch 1199 Train Loss 1.1315993189979596e-06 Test Loss 31.89666591754232\n",
            "Epoch 1399 Train Loss 4.5173761858496967e-07 Test Loss 32.69471161997263\n",
            "Epoch 1599 Train Loss 3.741912482645931e-07 Test Loss 32.34795810677088\n",
            "Epoch 1799 Train Loss 3.69275777937259e-07 Test Loss 31.719012941617155\n",
            "Epoch 1999 Train Loss 3.673932536999729e-07 Test Loss 31.08333876254604\n",
            "Epoch 2199 Train Loss 3.656048675109965e-07 Test Loss 30.466302073871848\n",
            "Epoch 2399 Train Loss 3.636057381058462e-07 Test Loss 29.845473377388238\n",
            "Epoch 2599 Train Loss 3.586869296625019e-07 Test Loss 29.226314394345476\n",
            "Epoch 2799 Train Loss 3.5624095771021065e-07 Test Loss 28.604851067780174\n",
            "Epoch 2999 Train Loss 3.519100404271315e-07 Test Loss 27.982398668865645\n",
            "Epoch 3199 Train Loss 3.4778625463904425e-07 Test Loss 27.352130725616394\n",
            "Epoch 3399 Train Loss 3.4497666789428626e-07 Test Loss 26.69701332828544\n",
            "Epoch 3599 Train Loss 3.4125632041028705e-07 Test Loss 26.043960325165465\n",
            "Epoch 3799 Train Loss 3.384795621256396e-07 Test Loss 25.365459167917432\n"
          ]
        }
      ],
      "source": [
        "train_losses = []\n",
        "test_losses = []\n",
        "model_checkpoints = []\n",
        "checkpoint_epochs = []\n",
        "if TRAIN_MODEL:\n",
        "    for epoch in tqdm.tqdm(range(num_epochs)):\n",
        "        train_logits = model(train_data)\n",
        "        train_loss = loss_fn(train_logits, train_labels)\n",
        "        train_loss.backward()\n",
        "        train_losses.append(train_loss.item())\n",
        "        # print(f\"train_loss.item() = {train_loss.item()}\")\n",
        "\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            test_logits = model(test_data)\n",
        "            test_loss = loss_fn(test_logits, test_labels)\n",
        "            test_losses.append(test_loss.item())\n",
        "\n",
        "        if ((epoch+1)%checkpoint_every)==0:\n",
        "            checkpoint_epochs.append(epoch)\n",
        "            model_checkpoints.append(copy.deepcopy(model.state_dict()))\n",
        "            print(f\"Epoch {epoch} Train Loss {train_loss.item()} Test Loss {test_loss.item()}\")\n",
        "            # print(f\"len(train_losses) = {len(train_losses)} len(test_losses) = {len(test_losses)} len(model_checkpoints) = {len(model_checkpoints)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "UrvOo2Qs2UV7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "len(train_losses) = 15000 len(test_losses) = 15000 len(model_checkpoints) = 150\n"
          ]
        }
      ],
      "source": [
        "if TRAIN_MODEL:\n",
        "    print(f\"len(train_losses) = {len(train_losses)} len(test_losses) = {len(test_losses)} len(model_checkpoints) = {len(model_checkpoints)}\")\n",
        "    torch.save(\n",
        "        {\n",
        "            \"model\":model.state_dict(),\n",
        "            \"config\": model.cfg,\n",
        "            \"checkpoints\": model_checkpoints,\n",
        "            \"checkpoint_epochs\": checkpoint_epochs,\n",
        "            \"test_losses\": test_losses,\n",
        "            \"train_losses\": train_losses,\n",
        "            \"train_indices\": train_indices,\n",
        "            \"test_indices\": test_indices,\n",
        "        },\n",
        "        PTH_LOCATION)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "tx5DVueg2UV7"
      },
      "outputs": [],
      "source": [
        "if not TRAIN_MODEL:\n",
        "    cached_data = torch.load(PTH_LOCATION, weights_only=False)\n",
        "    model.load_state_dict(cached_data['model'])\n",
        "    model_checkpoints = cached_data[\"checkpoints\"]\n",
        "    checkpoint_epochs = cached_data[\"checkpoint_epochs\"]\n",
        "    test_losses = cached_data['test_losses']\n",
        "    train_losses = cached_data['train_losses']\n",
        "    train_indices = cached_data[\"train_indices\"]\n",
        "    test_indices = cached_data[\"test_indices\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHA9-QD52UV7"
      },
      "source": [
        "## Show Model Training Statistics, Check that it groks!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "mHu_Yz8i2UV7",
        "outputId": "ff53e647-20f1-4a7d-8dae-f680164305f0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>                            <div id=\"70640b1a-f8fc-4ec2-b0b3-182a9ed75324\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"70640b1a-f8fc-4ec2-b0b3-182a9ed75324\")) {                    Plotly.newPlot(                        \"70640b1a-f8fc-4ec2-b0b3-182a9ed75324\",                        [{\"hovertemplate\":\"Color=train\\u003cbr\\u003eEpoch=%{x}\\u003cbr\\u003eLoss=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"0\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"train\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,100,200,300,400,500,600,700,800,900,1000,1100,1200,1300,1400,1500,1600,1700,1800,1900,2000,2100,2200,2300,2400,2500,2600,2700,2800,2900,3000,3100,3200,3300,3400,3500,3600,3700,3800,3900,4000,4100,4200,4300,4400,4500,4600,4700,4800,4900,5000,5100,5200,5300,5400,5500,5600,5700,5800,5900,6000,6100,6200,6300,6400,6500,6600,6700,6800,6900,7000,7100,7200,7300,7400,7500,7600,7700,7800,7900,8000,8100,8200,8300,8400,8500,8600,8700,8800,8900,9000,9100,9200,9300,9400,9500,9600,9700,9800,9900,10000,10100,10200,10300,10400,10500,10600,10700,10800,10900,11000,11100,11200,11300,11400,11500,11600,11700,11800,11900,12000,12100,12200,12300,12400,12500,12600,12700,12800,12900,13000,13100,13200,13300,13400,13500,13600,13700,13800,13900,14000,14100,14200,14300,14400,14500,14600,14700,14800,14900],\"xaxis\":\"x\",\"y\":[4.735885756566097,2.876261335814732,0.03259514003602968,0.010041422679369427,0.0032307918273634553,0.0010697937664407256,0.00036046852006808464,0.00012329985403822211,4.278380812389336e-05,1.5156547574155957e-05,5.5789841790856145e-06,2.2170303940438607e-06,1.0158975027098716e-06,5.750649146972516e-07,4.128561965889748e-07,3.594166637045512e-07,3.4539679937545883e-07,3.421643031450676e-07,3.4109709848478407e-07,3.400168055314706e-07,3.3882615070088687e-07,3.3774081915657516e-07,3.3618138205938307e-07,3.3485396845273324e-07,3.3351503142073213e-07,3.320354321268668e-07,3.3073217023785986e-07,3.293720406822476e-07,3.2814159832212017e-07,3.2685109901525195e-07,3.255688017129177e-07,3.2432978423065735e-07,3.23399742048283e-07,3.216906843321098e-07,3.209267631645373e-07,3.194598336088141e-07,3.183495825465899e-07,3.170328824517885e-07,3.1598510707682065e-07,3.147826126330532e-07,3.1368976805199025e-07,3.1251883291906415e-07,3.1192831595927836e-07,3.104891199806131e-07,3.094748456304122e-07,3.0800979880165646e-07,3.068817800777546e-07,3.057991329474354e-07,3.0449214558094183e-07,3.032687481454042e-07,3.020056452468742e-07,3.0055672918497615e-07,2.9969192355465914e-07,2.9828648351954725e-07,2.9693905598240567e-07,2.9549840926302455e-07,2.945797457030007e-07,2.930008279156451e-07,2.918595262438843e-07,2.904088952676657e-07,2.8866837530509194e-07,2.871053219354556e-07,2.854971947770269e-07,2.836622967913033e-07,2.8233746330534424e-07,2.804848879969061e-07,2.787921142804276e-07,2.7738488964204723e-07,2.756297271341257e-07,2.7374530271526176e-07,2.7197621023538304e-07,2.7003319510024686e-07,2.683307345865353e-07,2.6670206277204654e-07,2.647045569122506e-07,2.631992975252151e-07,2.613181719149004e-07,2.596685459499849e-07,2.575560158634629e-07,2.561169633785722e-07,2.5418717686046144e-07,2.5243435585919117e-07,2.5110599318314583e-07,2.494503859579225e-07,2.47180083963644e-07,2.4541526408238434e-07,2.4339950262445245e-07,2.4164443116400783e-07,2.394925033545863e-07,2.3741970274457287e-07,2.350373193147741e-07,2.3265822500140656e-07,2.2936909876509e-07,2.258196045573911e-07,2.2220971175653292e-07,2.1708477357426379e-07,2.1156183782812436e-07,2.0491040561606862e-07,1.972530015517509e-07,1.8945985696105095e-07,1.801982693688877e-07,1.7044832610395247e-07,1.6261908510479028e-07,1.5570228830845437e-07,1.493656942495678e-07,1.4374826021754028e-07,1.3879608137521156e-07,1.344257645058671e-07,1.306270533715169e-07,1.2692454604841746e-07,1.235561838208398e-07,1.2027803094015084e-07,1.1696129674782788e-07,1.1397600693051405e-07,1.1153574706569749e-07,1.0980426954245708e-07,1.0847901931046486e-07,1.0753836179227684e-07,1.0675272181059942e-07,1.060738349009534e-07,1.0543564179250107e-07,1.0483901656018649e-07,1.0425732890033152e-07,1.0367647801851779e-07,1.03085898363337e-07,1.0245294026008638e-07,1.0172286348257756e-07,1.0091816917674582e-07,1.0011381284061213e-07,9.934038630040268e-08,9.872590563185257e-08,9.820599501573562e-08,9.780978140767456e-08,9.745514507059307e-08,9.718591465407207e-08,9.69464813409083e-08,9.672650327570645e-08,9.653948746518124e-08,9.637968185490878e-08,9.623511189775645e-08,9.61034026449215e-08,9.598738775734673e-08,9.587907123893027e-08,9.577110728223455e-08,9.566125490009205e-08,9.555798666432748e-08,9.545785736162303e-08,9.538141942676303e-08,9.530670067435934e-08,9.523740126323773e-08],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"Color=test\\u003cbr\\u003eEpoch=%{x}\\u003cbr\\u003eLoss=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"1\",\"line\":{\"color\":\"#EF553B\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"test\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,100,200,300,400,500,600,700,800,900,1000,1100,1200,1300,1400,1500,1600,1700,1800,1900,2000,2100,2200,2300,2400,2500,2600,2700,2800,2900,3000,3100,3200,3300,3400,3500,3600,3700,3800,3900,4000,4100,4200,4300,4400,4500,4600,4700,4800,4900,5000,5100,5200,5300,5400,5500,5600,5700,5800,5900,6000,6100,6200,6300,6400,6500,6600,6700,6800,6900,7000,7100,7200,7300,7400,7500,7600,7700,7800,7900,8000,8100,8200,8300,8400,8500,8600,8700,8800,8900,9000,9100,9200,9300,9400,9500,9600,9700,9800,9900,10000,10100,10200,10300,10400,10500,10600,10700,10800,10900,11000,11100,11200,11300,11400,11500,11600,11700,11800,11900,12000,12100,12200,12300,12400,12500,12600,12700,12800,12900,13000,13100,13200,13300,13400,13500,13600,13700,13800,13900,14000,14100,14200,14300,14400,14500,14600,14700,14800,14900],\"xaxis\":\"x\",\"y\":[4.732172893373855,7.7394998406007085,20.057887656298572,20.91307332783636,22.15589220836194,23.47823572595192,24.848523270259435,26.221761489426374,27.59040396882145,28.93603069397398,30.21171468621399,31.3573710931173,32.2477292430029,32.7948973375603,32.96799271444859,32.83345633831749,32.54567883674333,32.21910620857275,31.890096031003022,31.568542101617947,31.246090094172317,30.930951059380995,30.618367762565263,30.314191004073837,30.02318812869787,29.73513547676136,29.449962008899806,29.176768777770743,28.904141064412652,28.631311787800737,28.361157854987123,28.093652283419324,27.829298131645654,27.566467532350536,27.320020101916704,27.06436580358973,26.807837094312347,26.553388934671794,26.292563321764238,26.037755920132614,25.785528316012048,25.524279857350805,25.260497596163354,24.99551264956792,24.7304663965787,24.45495417400165,24.174487872324825,23.887172611735885,23.600891679304365,23.30810648114867,23.00687612490701,22.68573490840295,22.351614358191377,22.01247145300937,21.65235784025338,21.291698991797496,20.920797250754504,20.5369920172971,20.146665690547557,19.741329402269326,19.32535232581492,18.89537368170042,18.45228933023354,17.991089024672714,17.50862862080892,17.032867283318915,16.558405810703086,16.083891222665628,15.605055699065923,15.126654177025436,14.651642184427612,14.163162470457355,13.671834324602475,13.182371843779908,12.700759956446955,12.217147965131247,11.730275629300174,11.269877589082709,10.823650244723607,10.39313679474872,9.9753437828739,9.576428710408825,9.188227599462426,8.798979888076216,8.417157095622553,8.043472703936606,7.674629320391939,7.30310232953302,6.922039085577769,6.537097062724024,6.140540331560386,5.728233616204505,5.295992957829484,4.8354275644292,4.340360341734236,3.8144358029531507,3.2596514634549862,2.677194583870035,2.0765581177348165,1.5058570054399543,1.001431274987147,0.6109221720621621,0.3510297376085294,0.19529582322174016,0.107047507159718,0.06000492682865387,0.033221580517056384,0.01862166574926482,0.010719739666997585,0.005991821160895907,0.0032064985796940787,0.0014315406082351235,0.0005360504972952265,0.0001792408761090561,5.653255033041271e-05,1.6079910823914646e-05,5.219577609412429e-06,2.6590448912790683e-06,1.9139025056256855e-06,1.6366930178295196e-06,1.56256804970598e-06,1.5236397045777696e-06,1.5798228420986422e-06,1.5911739982169031e-06,1.5848472887792488e-06,1.5595594203291985e-06,1.53896295654269e-06,1.5116750231697674e-06,1.4575954474196552e-06,1.34424379146857e-06,1.223248698015497e-06,1.117957206623851e-06,1.02364246389071e-06,9.235938507191503e-07,8.176114720460816e-07,7.191404270633092e-07,6.415409971774244e-07,5.746869922567705e-07,5.165426426513865e-07,4.762318768160878e-07,4.4088786435311163e-07,4.0943579158473286e-07,3.87402359274098e-07,3.6855502205770714e-07,3.5044665372952147e-07,3.370362832035316e-07,3.276812825072742e-07,3.2259450741615885e-07,3.199467528153208e-07,3.182660010748106e-07],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15,\"font\":{\"size\":20}},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15,\"font\":{\"size\":20}},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05,\"font\":{\"size\":30}},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Epoch\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Loss\"},\"type\":\"log\"},\"legend\":{\"title\":{\"text\":\"Color\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Training Curve for Modular Addition\"},\"updatemenus\":[{\"active\":-1,\"buttons\":[{\"args\":[{\"xaxis.type\":\"log\"}],\"args2\":[{\"xaxis.type\":\"linear\"}],\"label\":\"Log x-axis\",\"method\":\"relayout\"}],\"type\":\"buttons\",\"x\":-0.1,\"y\":1.0},{\"active\":0,\"buttons\":[{\"args\":[{\"yaxis.type\":\"log\"}],\"args2\":[{\"yaxis.type\":\"linear\"}],\"label\":\"Log y-axis\",\"method\":\"relayout\"}],\"type\":\"buttons\",\"x\":-0.1,\"y\":0.85}]},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('70640b1a-f8fc-4ec2-b0b3-182a9ed75324');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                });            </script>        </div>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from neel_plotly.plot import line\n",
        "line([train_losses[::100], test_losses[::100]], x=np.arange(0, len(train_losses), 100), xaxis=\"Epoch\", yaxis=\"Loss\", log_y=True, title=\"Training Curve for Modular Addition\", line_labels=['train', 'test'], toggle_x=True, toggle_y=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tN897frZ2UV7"
      },
      "source": [
        "# Analysing the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lky2UlrN2UV7"
      },
      "source": [
        "## Standard Things to Try"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Ad1cjmw2UV7",
        "outputId": "40290216-d392-452e-ef1b-0575d60908c4"
      },
      "outputs": [],
      "source": [
        "original_logits, cache = model.run_with_cache(dataset)\n",
        "print(original_logits.numel())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_32StlUr2UV8"
      },
      "source": [
        "Get key weight matrices:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0lbOxvs2UV8",
        "outputId": "c500b9a8-1697-4abe-a247-883532a1e436"
      },
      "outputs": [],
      "source": [
        "W_E = model.embed.W_E[:-1]\n",
        "print(\"W_E\", W_E.shape)\n",
        "W_neur = W_E @ model.blocks[0].attn.W_V @ model.blocks[0].attn.W_O @ model.blocks[0].mlp.W_in\n",
        "print(\"W_neur\", W_neur.shape)\n",
        "W_logit = model.blocks[0].mlp.W_out @ model.unembed.W_U\n",
        "print(\"W_logit\", W_logit.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yWSkeC1e2UV8",
        "outputId": "f18b80b4-a037-4c45-fb87-0aaa8b6ed942"
      },
      "outputs": [],
      "source": [
        "original_loss = loss_fn(original_logits, labels).item()\n",
        "print(\"Original Loss:\", original_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQs-TLVD2UV8"
      },
      "source": [
        "### Looking at Activations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_u-8AXN2UV8"
      },
      "source": [
        "Helper variable:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cMRzkNxW2UV8"
      },
      "outputs": [],
      "source": [
        "pattern_a = cache[\"pattern\", 0, \"attn\"][:, :, -1, 0]\n",
        "pattern_b = cache[\"pattern\", 0, \"attn\"][:, :, -1, 1]\n",
        "neuron_acts = cache[\"post\", 0, \"mlp\"][:, -1, :]\n",
        "neuron_pre_acts = cache[\"pre\", 0, \"mlp\"][:, -1, :]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xi43QmAV2UV8"
      },
      "source": [
        "Get all shapes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44O81Wt12UV8",
        "outputId": "7b92074e-d417-410d-e832-044cfb2c0a9e"
      },
      "outputs": [],
      "source": [
        "for param_name, param in cache.items():\n",
        "    print(param_name, param.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2tGOA822UV8",
        "outputId": "4930b366-5eef-43a6-e596-b3f3ede92329"
      },
      "outputs": [],
      "source": [
        "imshow(cache[\"pattern\", 0].mean(dim=0)[:, -1, :], title=\"Average Attention Pattern per Head\", xaxis=\"Source\", yaxis=\"Head\", x=['a', 'b', '='])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXFSWBrl2UV8",
        "outputId": "51f7df84-72c4-48f1-dd60-a5b0436b182a"
      },
      "outputs": [],
      "source": [
        "imshow(cache[\"pattern\", 0][5][:, -1, :], title=\"Average Attention Pattern per Head\", xaxis=\"Source\", yaxis=\"Head\", x=['a', 'b', '='])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WvHDHQcP2UV9",
        "outputId": "26485c31-fd76-4cfd-c2b6-fef71360d054"
      },
      "outputs": [],
      "source": [
        "dataset[:4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bhjwoXGe2UV9",
        "outputId": "ddb29030-fe5c-46db-9c4f-b817a951572b"
      },
      "outputs": [],
      "source": [
        "imshow(cache[\"pattern\", 0][:, 0, -1, 0].reshape(p, p), title=\"Attention for Head 0 from a -> =\", xaxis=\"b\", yaxis=\"a\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6LwbcjFj2UV9",
        "outputId": "a46be588-14b4-4d28-945c-0acbdf8ac13d"
      },
      "outputs": [],
      "source": [
        "imshow(\n",
        "    einops.rearrange(cache[\"pattern\", 0][:, :, -1, 0], \"(a b) head -> head a b\", a=p, b=p),\n",
        "    title=\"Attention for Head 0 from a -> =\", xaxis=\"b\", yaxis=\"a\", facet_col=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C18Gctun2UV9"
      },
      "source": [
        "Plotting neuron activations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFQzVdMM2UV9",
        "outputId": "4ac4c82c-5914-4efb-8845-edf48b016c78"
      },
      "outputs": [],
      "source": [
        "cache[\"post\", 0, \"mlp\"].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tz_2XGR2UV9",
        "outputId": "a77b881a-262d-4245-d92c-9a746d1e7577"
      },
      "outputs": [],
      "source": [
        "imshow(\n",
        "    einops.rearrange(neuron_acts[:, :5], \"(a b) neuron -> neuron a b\", a=p, b=p),\n",
        "    title=\"First 5 neuron acts\", xaxis=\"b\", yaxis=\"a\", facet_col=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoOcLnhm2UV9"
      },
      "source": [
        "### Singular Value Decomposition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kE-XXggQ2UV9",
        "outputId": "12cfad9b-b58f-410f-c13a-d91fd5dcb189"
      },
      "outputs": [],
      "source": [
        "W_E.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07Bm-WMn2UV9",
        "outputId": "739d044a-c6dd-4903-f147-0200378d47a1"
      },
      "outputs": [],
      "source": [
        "U, S, Vh = torch.svd(W_E)\n",
        "line(S, title=\"Singular Values\")\n",
        "imshow(U, title=\"Principal Components on the Input\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1OGIPYYb2UV9",
        "outputId": "2fc80913-97eb-4d6e-dbef-5f24cb80a968"
      },
      "outputs": [],
      "source": [
        "# Control - random Gaussian matrix\n",
        "U, S, Vh = torch.svd(torch.randn_like(W_E))\n",
        "line(S, title=\"Singular Values Random\")\n",
        "imshow(U, title=\"Principal Components Random\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4F8XwEN2UV-"
      },
      "source": [
        "## Explaining Algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2p89_lv2UV-"
      },
      "source": [
        "### Analyse the Embedding - It's a Lookup Table!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qpwI-2C82UV-",
        "outputId": "243d9d45-b006-4065-8eda-34ab8e36c3d8"
      },
      "outputs": [],
      "source": [
        "U, S, Vh = torch.svd(W_E)\n",
        "line(U[:, :8].T, title=\"Principal Components of the embedding\", xaxis=\"Input Vocabulary\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNHR2cO02UV-",
        "outputId": "d90d0575-e499-4601-f930-d1e29e523e90"
      },
      "outputs": [],
      "source": [
        "fourier_basis = []\n",
        "fourier_basis_names = []\n",
        "fourier_basis.append(torch.ones(p))\n",
        "fourier_basis_names.append(\"Constant\")\n",
        "for freq in range(1, p//2+1):\n",
        "    fourier_basis.append(torch.sin(torch.arange(p)*2 * torch.pi * freq / p))\n",
        "    fourier_basis_names.append(f\"Sin {freq}\")\n",
        "    fourier_basis.append(torch.cos(torch.arange(p)*2 * torch.pi * freq / p))\n",
        "    fourier_basis_names.append(f\"Cos {freq}\")\n",
        "fourier_basis = torch.stack(fourier_basis, dim=0).to(device)\n",
        "fourier_basis = fourier_basis/fourier_basis.norm(dim=-1, keepdim=True)\n",
        "imshow(fourier_basis, xaxis=\"Input\", yaxis=\"Component\", y=fourier_basis_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HpTQ6pZ62UV-",
        "outputId": "8bd7647d-b083-4796-e2d8-8d91bb110a26"
      },
      "outputs": [],
      "source": [
        "line(fourier_basis[:8], xaxis=\"Input\", line_labels=fourier_basis_names[:8], title=\"First 8 Fourier Components\")\n",
        "line(fourier_basis[25:29], xaxis=\"Input\", line_labels=fourier_basis_names[25:29], title=\"Middle Fourier Components\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QyYTvK0T2UV-",
        "outputId": "a50cdb18-cad8-461e-f39c-6d5a00af61e6"
      },
      "outputs": [],
      "source": [
        "imshow(fourier_basis @ fourier_basis.T, title=\"All Fourier Vectors are Orthogonal\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5axBeip2UV-"
      },
      "source": [
        "### Analyse the Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PIYWBRxL2UV-",
        "outputId": "f1797c1f-f193-46d8-9db6-478e3fcac0ff"
      },
      "outputs": [],
      "source": [
        "imshow(fourier_basis @ W_E, yaxis=\"Fourier Component\", xaxis=\"Residual Stream\", y=fourier_basis_names, title=\"Embedding in Fourier Basis\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DGzeqL52UV-",
        "outputId": "23e09b71-65fd-4bea-a601-e8fecc20c580"
      },
      "outputs": [],
      "source": [
        "line((fourier_basis @ W_E).norm(dim=-1), xaxis=\"Fourier Component\", x=fourier_basis_names, title=\"Norms of Embedding in Fourier Basis\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0TChjDes2UV-",
        "outputId": "d37ec48f-8ee0-4dcc-c1ab-c5cf45822ce0"
      },
      "outputs": [],
      "source": [
        "key_freqs = [17, 25, 32, 47]\n",
        "key_freq_indices = [33, 34, 49, 50, 63, 64, 93, 94]\n",
        "fourier_embed = fourier_basis @ W_E\n",
        "key_fourier_embed = fourier_embed[key_freq_indices]\n",
        "print(\"key_fourier_embed\", key_fourier_embed.shape)\n",
        "imshow(key_fourier_embed @ key_fourier_embed.T, title=\"Dot Product of embedding of key Fourier Terms\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5w3IyUz82UV-"
      },
      "source": [
        "### Key Frequencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oIgPAisZ2UV-",
        "outputId": "66e71cfc-b345-4edc-9106-1f47c4ac51e6"
      },
      "outputs": [],
      "source": [
        "line(fourier_basis[[34, 50, 64, 94]], title=\"Cos of key freqs\", line_labels=[34, 50, 64, 94])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KqxItZbN2UV_",
        "outputId": "e7a95003-7c80-4e79-958a-13eead2e008c"
      },
      "outputs": [],
      "source": [
        "line(fourier_basis[[34, 50, 64, 94]].mean(0), title=\"Constructive Interference\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJOGfHBJ2UV_"
      },
      "source": [
        "## Analyse Neurons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CN2BdryQ2UV_",
        "outputId": "82a0cff2-1ae7-4887-cf3c-232a7c46458a"
      },
      "outputs": [],
      "source": [
        "imshow(\n",
        "    einops.rearrange(neuron_acts[:, :5], \"(a b) neuron -> neuron a b\", a=p, b=p),\n",
        "    title=\"First 5 neuron acts\", xaxis=\"b\", yaxis=\"a\", facet_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwSwA7BB2UV_",
        "outputId": "280626ae-4052-4d28-89a9-814ce431eec7"
      },
      "outputs": [],
      "source": [
        "imshow(\n",
        "    einops.rearrange(neuron_acts[:, 0], \"(a b) -> a b\", a=p, b=p),\n",
        "    title=\"First neuron act\", xaxis=\"b\", yaxis=\"a\",)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKgpNncB2UV_",
        "outputId": "06cb8e00-12c4-47bd-d30f-c42b926400fc"
      },
      "outputs": [],
      "source": [
        "imshow(fourier_basis[94][None, :] * fourier_basis[94][:, None], title=\"Cos 47a * cos 47b\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_CfsHhN2UV_",
        "outputId": "217e41fd-7b71-408d-a25b-76b96f71a23c"
      },
      "outputs": [],
      "source": [
        "imshow(fourier_basis[94][None, :] * fourier_basis[0][:, None], title=\"Cos 47a * const\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LPO8kd6z2UV_",
        "outputId": "6b379743-c9fa-4753-e16b-fd380ff2cc25"
      },
      "outputs": [],
      "source": [
        "imshow(fourier_basis @ neuron_acts[:, 0].reshape(p, p) @ fourier_basis.T, title=\"2D Fourier Transformer of neuron 0\", xaxis=\"b\", yaxis=\"a\", x=fourier_basis_names, y=fourier_basis_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2h2_i8WS2UV_",
        "outputId": "caad8394-6533-4e40-9c57-f19d06d187f7"
      },
      "outputs": [],
      "source": [
        "imshow(fourier_basis @ neuron_acts[:, 5].reshape(p, p) @ fourier_basis.T, title=\"2D Fourier Transformer of neuron 5\", xaxis=\"b\", yaxis=\"a\", x=fourier_basis_names, y=fourier_basis_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LU6fmQau2UV_",
        "outputId": "fec9253d-be02-48b2-b1e1-f9742d130bbf"
      },
      "outputs": [],
      "source": [
        "imshow(fourier_basis @ torch.randn_like(neuron_acts[:, 0]).reshape(p, p) @ fourier_basis.T, title=\"2D Fourier Transformer of RANDOM\", xaxis=\"b\", yaxis=\"a\", x=fourier_basis_names, y=fourier_basis_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VALEk5FF2UV_"
      },
      "source": [
        "### Neuron Clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INkgFDrp2UV_",
        "outputId": "2f5d5b18-8e71-4604-90a3-b6286f455a45"
      },
      "outputs": [],
      "source": [
        "fourier_neuron_acts = fourier_basis @ einops.rearrange(neuron_acts, \"(a b) neuron -> neuron a b\", a=p, b=p) @ fourier_basis.T\n",
        "# Center these by removing the mean - doesn't matter!\n",
        "fourier_neuron_acts[:, 0, 0] = 0.\n",
        "print(\"fourier_neuron_acts\", fourier_neuron_acts.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uv5mnIue2UV_",
        "outputId": "25f8e51c-c61b-4ce3-842c-0d2eb3312c26"
      },
      "outputs": [],
      "source": [
        "neuron_freq_norm = torch.zeros(p//2, model.cfg.d_mlp).to(device)\n",
        "for freq in range(0, p//2):\n",
        "    for x in [0, 2*(freq+1) - 1, 2*(freq+1)]:\n",
        "        for y in [0, 2*(freq+1) - 1, 2*(freq+1)]:\n",
        "            neuron_freq_norm[freq] += fourier_neuron_acts[:, x, y]**2\n",
        "neuron_freq_norm = neuron_freq_norm / fourier_neuron_acts.pow(2).sum(dim=[-1, -2])[None, :]\n",
        "imshow(neuron_freq_norm, xaxis=\"Neuron\", yaxis=\"Freq\", y=torch.arange(1, p//2+1), title=\"Neuron Frac Explained by Freq\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRUBnAkR2UV_",
        "outputId": "0bba5e09-677e-4422-8470-3c5e7b8b26b5"
      },
      "outputs": [],
      "source": [
        "line(neuron_freq_norm.max(dim=0).values.sort().values, xaxis=\"Neuron\", title=\"Max Neuron Frac Explained over Freqs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROyJpjBu2UWA"
      },
      "source": [
        "## Read Off the Neuron-Logit Weights to Interpret"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwrTuOuU2UWA"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4_iAERQ2UWA",
        "outputId": "ea30ddf6-0e2f-4a77-e8c4-a039f05149a6"
      },
      "outputs": [],
      "source": [
        "W_logit = model.blocks[0].mlp.W_out @ model.unembed.W_U\n",
        "print(\"W_logit\", W_logit.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-pIY_GA2UWA",
        "outputId": "8cfd60a2-327a-4fd3-8a2e-fa8da103b855"
      },
      "outputs": [],
      "source": [
        "line((W_logit @ fourier_basis.T).norm(dim=0), x=fourier_basis_names, title=\"W_logit in the Fourier Basis\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5S6BRPXn2UWA",
        "outputId": "c792848c-f21d-4ad2-f166-dd0616516c51"
      },
      "outputs": [],
      "source": [
        "neurons_17 = neuron_freq_norm[17-1]>0.85\n",
        "neurons_17.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iAoHR8om2UWA",
        "outputId": "75976bb5-9bd5-4683-a424-2307486655e6"
      },
      "outputs": [],
      "source": [
        "neurons_17.sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ItQl2uZH2UWA",
        "outputId": "d753b3c1-d98f-4998-be39-4c9b15302516"
      },
      "outputs": [],
      "source": [
        "line((W_logit[neurons_17] @ fourier_basis.T).norm(dim=0), x=fourier_basis_names, title=\"W_logit for freq 17 neurons in the Fourier Basis\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUzoRXjv2UWA"
      },
      "source": [
        "Study sin 17"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3QULuLWO2UWA",
        "outputId": "cc133251-ba40-4a60-a832-a6cd996475a7"
      },
      "outputs": [],
      "source": [
        "freq = 17\n",
        "W_logit_fourier = W_logit @ fourier_basis\n",
        "neurons_sin_17 = W_logit_fourier[:, 2*freq-1]\n",
        "line(neurons_sin_17)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4PiyHIZ2UWA",
        "outputId": "0822fc3c-0665-4d7a-c597-45232ceb0b6c"
      },
      "outputs": [],
      "source": [
        "neuron_acts.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3rL4HX02UWA",
        "outputId": "e0ca3817-ddff-4278-e812-9b1f7fcfb24c"
      },
      "outputs": [],
      "source": [
        "inputs_sin_17c = neuron_acts @ neurons_sin_17\n",
        "imshow(fourier_basis @ inputs_sin_17c.reshape(p, p) @ fourier_basis.T, title=\"Fourier Heatmap over inputs for sin17c\", x=fourier_basis_names, y=fourier_basis_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiIpOKim2UWA"
      },
      "source": [
        "# Black Box Methods + Progress Measures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hcb1hzmn2UWB"
      },
      "source": [
        "## Setup Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7RR0FPS2UWB"
      },
      "source": [
        "Code to plot embedding freqs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sg7iSMKC2UWB"
      },
      "outputs": [],
      "source": [
        "def embed_to_cos_sin(fourier_embed):\n",
        "    if len(fourier_embed.shape) == 1:\n",
        "        return torch.stack([fourier_embed[1::2], fourier_embed[2::2]])\n",
        "    else:\n",
        "        return torch.stack([fourier_embed[:, 1::2], fourier_embed[:, 2::2]], dim=1)\n",
        "\n",
        "from neel_plotly.plot import melt\n",
        "\n",
        "def plot_embed_bars(\n",
        "    fourier_embed,\n",
        "    title=\"Norm of embedding of each Fourier Component\",\n",
        "    return_fig=False,\n",
        "    **kwargs\n",
        "):\n",
        "    cos_sin_embed = embed_to_cos_sin(fourier_embed)\n",
        "    df = melt(cos_sin_embed)\n",
        "    # display(df)\n",
        "    group_labels = {0: \"sin\", 1: \"cos\"}\n",
        "    df[\"Trig\"] = df[\"0\"].map(lambda x: group_labels[x])\n",
        "    fig = px.bar(\n",
        "        df,\n",
        "        barmode=\"group\",\n",
        "        color=\"Trig\",\n",
        "        x=\"1\",\n",
        "        y=\"value\",\n",
        "        labels={\"1\": \"$w_k$\", \"value\": \"Norm\"},\n",
        "        title=title,\n",
        "        **kwargs\n",
        "    )\n",
        "    fig.update_layout(dict(legend_title=\"\"))\n",
        "\n",
        "    if return_fig:\n",
        "        return fig\n",
        "    else:\n",
        "        fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otzQkRuy2UWB"
      },
      "source": [
        "Code to test a tensor of edited logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hg3m_8CQ2UWB"
      },
      "outputs": [],
      "source": [
        "def test_logits(logits, bias_correction=False, original_logits=None, mode=\"all\"):\n",
        "    # Calculates cross entropy loss of logits representing a batch of all p^2\n",
        "    # possible inputs\n",
        "    # Batch dimension is assumed to be first\n",
        "    if logits.shape[1] == p * p:\n",
        "        logits = logits.T\n",
        "    if logits.shape == torch.Size([p * p, p + 1]):\n",
        "        logits = logits[:, :-1]\n",
        "    logits = logits.reshape(p * p, p)\n",
        "    if bias_correction:\n",
        "        # Applies bias correction - we correct for any missing bias terms,\n",
        "        # independent of the input, by centering the new logits along the batch\n",
        "        # dimension, and then adding the average original logits across all inputs\n",
        "        logits = (\n",
        "            einops.reduce(original_logits - logits, \"batch ... -> ...\", \"mean\") + logits\n",
        "        )\n",
        "    if mode == \"train\":\n",
        "        return loss_fn(logits[train_indices], labels[train_indices])\n",
        "    elif mode == \"test\":\n",
        "        return loss_fn(logits[test_indices], labels[test_indices])\n",
        "    elif mode == \"all\":\n",
        "        return loss_fn(logits, labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkzZ7bok2UWB"
      },
      "source": [
        "Code to run a metric over every checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4WavCgES2UWB"
      },
      "outputs": [],
      "source": [
        "metric_cache = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eUsBnDvB2UWB"
      },
      "outputs": [],
      "source": [
        "def get_metrics(model, metric_cache, metric_fn, name, reset=False):\n",
        "    if reset or (name not in metric_cache) or (len(metric_cache[name]) == 0):\n",
        "        metric_cache[name] = []\n",
        "        for c, sd in enumerate(tqdm.tqdm((model_checkpoints))):\n",
        "            model.reset_hooks()\n",
        "            model.load_state_dict(sd)\n",
        "            out = metric_fn(model)\n",
        "            if type(out) == torch.Tensor:\n",
        "                out = utils.to_numpy(out)\n",
        "            metric_cache[name].append(out)\n",
        "        model.load_state_dict(model_checkpoints[-1])\n",
        "        try:\n",
        "            metric_cache[name] = torch.tensor(metric_cache[name])\n",
        "        except:\n",
        "            metric_cache[name] = torch.tensor(np.array(metric_cache[name]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kK2FTxEI2UWC"
      },
      "source": [
        "## Defining Progress Measures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2KsOuyM2UWC"
      },
      "source": [
        "### Loss Curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UXhKHkXD2UWC"
      },
      "outputs": [],
      "source": [
        "memorization_end_epoch = 1500\n",
        "circuit_formation_end_epoch = 13300\n",
        "cleanup_end_epoch = 16600"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nK6RI5it2UWC"
      },
      "outputs": [],
      "source": [
        "def add_lines(figure):\n",
        "    figure.add_vline(memorization_end_epoch, line_dash=\"dash\", opacity=0.7)\n",
        "    figure.add_vline(circuit_formation_end_epoch, line_dash=\"dash\", opacity=0.7)\n",
        "    figure.add_vline(cleanup_end_epoch, line_dash=\"dash\", opacity=0.7)\n",
        "    return figure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dcYtNoui2UWC",
        "outputId": "84186b0e-bf8d-4dd9-92cc-8522cb53b0ed"
      },
      "outputs": [],
      "source": [
        "fig = line([train_losses[::100], test_losses[::100]], x=np.arange(0, len(train_losses), 100), xaxis=\"Epoch\", yaxis=\"Loss\", log_y=True, title=\"Training Curve for Modular Addition\", line_labels=['train', 'test'], toggle_x=True, toggle_y=True, return_fig=True)\n",
        "add_lines(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvR9qcZ62UWC"
      },
      "source": [
        "### Logit Periodicity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_0fV89s2UWC",
        "outputId": "3ee892ae-7363-4ff0-ba81-48478fc80f9f"
      },
      "outputs": [],
      "source": [
        "all_logits = original_logits[:, -1, :]\n",
        "print(all_logits.shape)\n",
        "all_logits = einops.rearrange(all_logits, \"(a b) c -> a b c\", a=p, b=p)\n",
        "print(all_logits.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJ_Ex_ph2UWC",
        "outputId": "e6ead41d-2f9b-46be-eb03-cbc61e02bf19"
      },
      "outputs": [],
      "source": [
        "coses = {}\n",
        "for freq in key_freqs:\n",
        "    print(\"Freq:\", freq)\n",
        "    a = torch.arange(p)[:, None, None]\n",
        "    b = torch.arange(p)[None, :, None]\n",
        "    c = torch.arange(p)[None, None, :]\n",
        "    cube_predicted_logits = torch.cos(freq * 2 * torch.pi / p * (a + b - c)).to(device)\n",
        "    cube_predicted_logits /= cube_predicted_logits.norm()\n",
        "    coses[freq] = cube_predicted_logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRgWuabh2UWC",
        "outputId": "a449306e-cfa8-4b66-d68a-9db843cb778d"
      },
      "outputs": [],
      "source": [
        "approximated_logits = torch.zeros_like(all_logits)\n",
        "for freq in key_freqs:\n",
        "    print(\"Freq:\", freq)\n",
        "    coeff = (all_logits * coses[freq]).sum()\n",
        "    print(\"Coeff:\", coeff)\n",
        "    cosine_sim = coeff / all_logits.norm()\n",
        "    print(\"Cosine Sim:\", cosine_sim)\n",
        "    approximated_logits += coeff * coses[freq]\n",
        "residual = all_logits - approximated_logits\n",
        "print(\"Residual size:\", residual.norm())\n",
        "print(\"Residual fraction of norm:\", residual.norm()/all_logits.norm())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZnEO6Kj32UWC",
        "outputId": "c342b319-3128-44ac-9fcc-274f6c4f190f"
      },
      "outputs": [],
      "source": [
        "random_logit_cube = torch.randn_like(all_logits)\n",
        "print((all_logits * random_logit_cube).sum()/random_logit_cube.norm()/all_logits.norm())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3biEyWhq2UWC",
        "outputId": "afeeddec-b719-4dfa-a82f-3290e1a8d4f3"
      },
      "outputs": [],
      "source": [
        "test_logits(all_logits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2rOuQB4-2UWC",
        "outputId": "e2b7a101-d930-4206-8df9-5918126c9b3b"
      },
      "outputs": [],
      "source": [
        "test_logits(approximated_logits)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhrjC1y32UWC"
      },
      "source": [
        "#### Look During Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqIMTFib2UWC",
        "outputId": "2b4645eb-6214-451f-f27f-62fb594c1382"
      },
      "outputs": [],
      "source": [
        "cos_cube = []\n",
        "for freq in range(1, p//2 + 1):\n",
        "    a = torch.arange(p)[:, None, None]\n",
        "    b = torch.arange(p)[None, :, None]\n",
        "    c = torch.arange(p)[None, None, :]\n",
        "    cube_predicted_logits = torch.cos(freq * 2 * torch.pi / p * (a + b - c)).to(device)\n",
        "    cube_predicted_logits /= cube_predicted_logits.norm()\n",
        "    cos_cube.append(cube_predicted_logits)\n",
        "cos_cube = torch.stack(cos_cube, dim=0)\n",
        "print(cos_cube.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "4d3444ac0c09485bb2297c35246614f4"
          ]
        },
        "id": "-_1HaqhZ2UWC",
        "outputId": "d0073a8c-a93e-425a-c27c-672b925e586c"
      },
      "outputs": [],
      "source": [
        "def get_cos_coeffs(model):\n",
        "    logits = model(dataset)[:, -1]\n",
        "    logits = einops.rearrange(logits, \"(a b) c -> a b c\", a=p, b=p)\n",
        "    vals = (cos_cube * logits[None, :, :, :]).sum([-3, -2, -1])\n",
        "    return vals\n",
        "\n",
        "\n",
        "get_metrics(model, metric_cache, get_cos_coeffs, \"cos_coeffs\")\n",
        "print(metric_cache[\"cos_coeffs\"].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qx80vCX-2UWC",
        "outputId": "909273d0-9d4f-4026-f70b-24f7846b9b3d"
      },
      "outputs": [],
      "source": [
        "fig = line(metric_cache[\"cos_coeffs\"].T, line_labels=[f\"Freq {i}\" for i in range(1, p//2+1)], title=\"Coefficients with Predicted Logits\", xaxis=\"Epoch\", x=checkpoint_epochs, yaxis=\"Coefficient\", return_fig=True)\n",
        "add_lines(fig)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "64c4305b8e8f466f8dd9240817fbc5e2"
          ]
        },
        "id": "M_vIfqHw2UWC",
        "outputId": "2c1b11ba-51f3-40d1-d4ea-acc7e4ab2906"
      },
      "outputs": [],
      "source": [
        "def get_cos_sim(model):\n",
        "    logits = model(dataset)[:, -1]\n",
        "    logits = einops.rearrange(logits, \"(a b) c -> a b c\", a=p, b=p)\n",
        "    vals = (cos_cube * logits[None, :, :, :]).sum([-3, -2, -1])\n",
        "    return vals / logits.norm()\n",
        "\n",
        "get_metrics(model, metric_cache, get_cos_sim, \"cos_sim\") # You may need a big GPU. If you don't have one and can't work around this, raise an issue for help!\n",
        "print(metric_cache[\"cos_sim\"].shape)\n",
        "\n",
        "fig = line(metric_cache[\"cos_sim\"].T, line_labels=[f\"Freq {i}\" for i in range(1, p//2+1)], title=\"Cosine Sim with Predicted Logits\", xaxis=\"Epoch\", x=checkpoint_epochs, yaxis=\"Cosine Sim\", return_fig=True)\n",
        "add_lines(fig)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "93e129d45acf43d29dc422409440ad70"
          ]
        },
        "id": "gdNT2ys-2UWD",
        "outputId": "a86c212b-582f-484a-e834-741108bb3782"
      },
      "outputs": [],
      "source": [
        "def get_residual_cos_sim(model):\n",
        "    logits = model(dataset)[:, -1]\n",
        "    logits = einops.rearrange(logits, \"(a b) c -> a b c\", a=p, b=p)\n",
        "    vals = (cos_cube * logits[None, :, :, :]).sum([-3, -2, -1])\n",
        "    residual = logits - (vals[:, None, None, None] * cos_cube).sum(dim=0)\n",
        "    return residual.norm() / logits.norm()\n",
        "\n",
        "get_metrics(model, metric_cache, get_residual_cos_sim, \"residual_cos_sim\")\n",
        "print(metric_cache[\"residual_cos_sim\"].shape)\n",
        "\n",
        "fig = line([metric_cache[\"cos_sim\"][:, i] for i in range(p//2)]+[metric_cache[\"residual_cos_sim\"]], line_labels=[f\"Freq {i}\" for i in range(1, p//2+1)]+[\"residual\"], title=\"Cosine Sim with Predicted Logits + Residual\", xaxis=\"Epoch\", x=checkpoint_epochs, yaxis=\"Cosine Sim\", return_fig=True)\n",
        "add_lines(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSwcrGN42UWD"
      },
      "source": [
        "## Restricted Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ll4ANw62UWD",
        "outputId": "eb247de4-274b-4de4-b2a7-6e5b26ca184a"
      },
      "outputs": [],
      "source": [
        "neuron_acts.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bb7SzJxC2UWD",
        "outputId": "bc81f91c-53f2-4108-eb18-66be1d716e7a"
      },
      "outputs": [],
      "source": [
        "neuron_acts_square = einops.rearrange(neuron_acts, \"(a b) neur -> a b neur\", a=p, b=p).clone()\n",
        "# Center it\n",
        "neuron_acts_square -= einops.reduce(neuron_acts_square, \"a b neur -> 1 1 neur\", \"mean\")\n",
        "neuron_acts_square_fourier = einsum(\"a b neur, fa a, fb b -> fa fb neur\", neuron_acts_square, fourier_basis, fourier_basis)\n",
        "imshow(neuron_acts_square_fourier.norm(dim=-1), xaxis=\"Fourier Component b\", yaxis=\"Fourier Component a\", title=\"Norms of neuron activations by Fourier Component\", x=fourier_basis_names, y=fourier_basis_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "baKaHHHe2UWD",
        "outputId": "e94a0f6a-e395-4fec-e0e2-7cc676dc7a01"
      },
      "outputs": [],
      "source": [
        "original_logits, cache = model.run_with_cache(dataset)\n",
        "print(original_logits.numel())\n",
        "neuron_acts = cache[\"post\", 0, \"mlp\"][:, -1, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T47cdrQJ2UWD",
        "outputId": "9ea8ae5a-1e90-4340-cc5f-4e460a62dea5"
      },
      "outputs": [],
      "source": [
        "approx_neuron_acts = torch.zeros_like(neuron_acts)\n",
        "approx_neuron_acts += neuron_acts.mean(dim=0)\n",
        "a = torch.arange(p)[:, None]\n",
        "b = torch.arange(p)[None, :]\n",
        "for freq in key_freqs:\n",
        "    cos_apb_vec = torch.cos(freq * 2 * torch.pi / p * (a + b)).to(device)\n",
        "    cos_apb_vec /= cos_apb_vec.norm()\n",
        "    cos_apb_vec = einops.rearrange(cos_apb_vec, \"a b -> (a b) 1\")\n",
        "    approx_neuron_acts += (neuron_acts * cos_apb_vec).sum(dim=0) * cos_apb_vec\n",
        "    sin_apb_vec = torch.sin(freq * 2 * torch.pi / p * (a + b)).to(device)\n",
        "    sin_apb_vec /= sin_apb_vec.norm()\n",
        "    sin_apb_vec = einops.rearrange(sin_apb_vec, \"a b -> (a b) 1\")\n",
        "    approx_neuron_acts += (neuron_acts * sin_apb_vec).sum(dim=0) * sin_apb_vec\n",
        "restricted_logits = approx_neuron_acts @ W_logit\n",
        "print(loss_fn(restricted_logits[test_indices], test_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9utdvBE2UWD",
        "outputId": "ddfdb172-eac4-4df7-f6e5-e8ef02119ab4"
      },
      "outputs": [],
      "source": [
        "print(loss_fn(all_logits, labels)) # This bugged on models not fully trained"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qy72wtlN2UWD"
      },
      "source": [
        "### Look During Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JvX1sp7d2UWD",
        "outputId": "56039b47-6493-42ce-b6fd-9d55808933d7"
      },
      "outputs": [],
      "source": [
        "def get_restricted_loss(model):\n",
        "    logits, cache = model.run_with_cache(dataset)\n",
        "    logits = logits[:, -1, :]\n",
        "    neuron_acts = cache[\"post\", 0, \"mlp\"][:, -1, :]\n",
        "    approx_neuron_acts = torch.zeros_like(neuron_acts)\n",
        "    approx_neuron_acts += neuron_acts.mean(dim=0)\n",
        "    a = torch.arange(p)[:, None]\n",
        "    b = torch.arange(p)[None, :]\n",
        "    for freq in key_freqs:\n",
        "        cos_apb_vec = torch.cos(freq * 2 * torch.pi / p * (a + b)).to(device)\n",
        "        cos_apb_vec /= cos_apb_vec.norm()\n",
        "        cos_apb_vec = einops.rearrange(cos_apb_vec, \"a b -> (a b) 1\")\n",
        "        approx_neuron_acts += (neuron_acts * cos_apb_vec).sum(dim=0) * cos_apb_vec\n",
        "        sin_apb_vec = torch.sin(freq * 2 * torch.pi / p * (a + b)).to(device)\n",
        "        sin_apb_vec /= sin_apb_vec.norm()\n",
        "        sin_apb_vec = einops.rearrange(sin_apb_vec, \"a b -> (a b) 1\")\n",
        "        approx_neuron_acts += (neuron_acts * sin_apb_vec).sum(dim=0) * sin_apb_vec\n",
        "    restricted_logits = approx_neuron_acts @ model.blocks[0].mlp.W_out @ model.unembed.W_U\n",
        "    # Add bias term\n",
        "    restricted_logits += logits.mean(dim=0, keepdim=True) - restricted_logits.mean(dim=0, keepdim=True)\n",
        "    return loss_fn(restricted_logits[test_indices], test_labels)\n",
        "get_restricted_loss(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "3079070c7f5445aabbc6a198a53b04b2"
          ]
        },
        "id": "ve3FweXG2UWD",
        "outputId": "790a3cf2-c88d-4e3e-cbbf-c0316ed1ac48"
      },
      "outputs": [],
      "source": [
        "get_metrics(model, metric_cache, get_restricted_loss, \"restricted_loss\", reset=True)\n",
        "print(metric_cache[\"restricted_loss\"].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aHIwg6zO2UWD",
        "outputId": "da0b4330-e1f4-42fc-8698-d8e6a45902f2"
      },
      "outputs": [],
      "source": [
        "fig = line([train_losses[::100], test_losses[::100], metric_cache[\"restricted_loss\"]], x=np.arange(0, len(train_losses), 100), xaxis=\"Epoch\", yaxis=\"Loss\", log_y=True, title=\"Restricted Loss Curve\", line_labels=['train', 'test', \"restricted_loss\"], toggle_x=True, toggle_y=True, return_fig=True)\n",
        "add_lines(fig)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFh5Lkvy2UWD",
        "outputId": "15ea8635-3f4f-4aee-e5e4-257f63732f45"
      },
      "outputs": [],
      "source": [
        "fig = line([torch.tensor(test_losses[::100])/metric_cache[\"restricted_loss\"]], x=np.arange(0, len(train_losses), 100), xaxis=\"Epoch\", yaxis=\"Loss\", log_y=True, title=\"Restricted Loss to Test Loss Ratio\", toggle_x=True, toggle_y=True, return_fig=True)\n",
        "# WARNING: bugged when cancelling training half way thr ough\n",
        "add_lines(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1On6MAO02UWD"
      },
      "source": [
        "## Excluded Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WsDR1s5x2UWD",
        "outputId": "3a733bc0-1ca9-4f25-c22e-40f6e4e539d7"
      },
      "outputs": [],
      "source": [
        "approx_neuron_acts = torch.zeros_like(neuron_acts)\n",
        "# approx_neuron_acts += neuron_acts.mean(dim=0)\n",
        "a = torch.arange(p)[:, None]\n",
        "b = torch.arange(p)[None, :]\n",
        "for freq in key_freqs:\n",
        "    cos_apb_vec = torch.cos(freq * 2 * torch.pi / p * (a + b)).to(device)\n",
        "    cos_apb_vec /= cos_apb_vec.norm()\n",
        "    cos_apb_vec = einops.rearrange(cos_apb_vec, \"a b -> (a b) 1\")\n",
        "    approx_neuron_acts += (neuron_acts * cos_apb_vec).sum(dim=0) * cos_apb_vec\n",
        "    sin_apb_vec = torch.sin(freq * 2 * torch.pi / p * (a + b)).to(device)\n",
        "    sin_apb_vec /= sin_apb_vec.norm()\n",
        "    sin_apb_vec = einops.rearrange(sin_apb_vec, \"a b -> (a b) 1\")\n",
        "    approx_neuron_acts += (neuron_acts * sin_apb_vec).sum(dim=0) * sin_apb_vec\n",
        "excluded_neuron_acts = neuron_acts - approx_neuron_acts\n",
        "excluded_logits = excluded_neuron_acts @ W_logit\n",
        "print(loss_fn(excluded_logits[train_indices], train_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FLK6WdFs2UWD",
        "outputId": "bd6a5f20-6234-4bb1-cfbb-82a0081e2c93"
      },
      "outputs": [],
      "source": [
        "def get_excluded_loss(model):\n",
        "    logits, cache = model.run_with_cache(dataset)\n",
        "    logits = logits[:, -1, :]\n",
        "    neuron_acts = cache[\"post\", 0, \"mlp\"][:, -1, :]\n",
        "    approx_neuron_acts = torch.zeros_like(neuron_acts)\n",
        "    # approx_neuron_acts += neuron_acts.mean(dim=0)\n",
        "    a = torch.arange(p)[:, None]\n",
        "    b = torch.arange(p)[None, :]\n",
        "    for freq in key_freqs:\n",
        "        cos_apb_vec = torch.cos(freq * 2 * torch.pi / p * (a + b)).to(device)\n",
        "        cos_apb_vec /= cos_apb_vec.norm()\n",
        "        cos_apb_vec = einops.rearrange(cos_apb_vec, \"a b -> (a b) 1\")\n",
        "        approx_neuron_acts += (neuron_acts * cos_apb_vec).sum(dim=0) * cos_apb_vec\n",
        "        sin_apb_vec = torch.sin(freq * 2 * torch.pi / p * (a + b)).to(device)\n",
        "        sin_apb_vec /= sin_apb_vec.norm()\n",
        "        sin_apb_vec = einops.rearrange(sin_apb_vec, \"a b -> (a b) 1\")\n",
        "        approx_neuron_acts += (neuron_acts * sin_apb_vec).sum(dim=0) * sin_apb_vec\n",
        "    excluded_neuron_acts = neuron_acts - approx_neuron_acts\n",
        "    residual_stream_final = excluded_neuron_acts @ model.blocks[0].mlp.W_out + cache[\"resid_mid\", 0][:, -1, :]\n",
        "    excluded_logits = residual_stream_final @ model.unembed.W_U\n",
        "    return loss_fn(excluded_logits[train_indices], train_labels)\n",
        "get_excluded_loss(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "3661a3612a0744aa806d8f7c2e884666"
          ]
        },
        "id": "HFG8fslR2UWD",
        "outputId": "e04f9b0a-469b-4016-e078-dfdc62b66a14"
      },
      "outputs": [],
      "source": [
        "get_metrics(model, metric_cache, get_excluded_loss, \"excluded_loss\", reset=True)\n",
        "print(metric_cache[\"excluded_loss\"].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EqEDrPYn2UWD",
        "outputId": "7687fbfc-d9f3-4e72-9b67-95c199a7d121"
      },
      "outputs": [],
      "source": [
        "fig = line([train_losses[::100], test_losses[::100], metric_cache[\"excluded_loss\"], metric_cache[\"restricted_loss\"]], x=np.arange(0, len(train_losses), 100), xaxis=\"Epoch\", yaxis=\"Loss\", log_y=True, title=\"Excluded and Restricted Loss Curve\", line_labels=['train', 'test', \"excluded_loss\", \"restricted_loss\"], toggle_x=True, toggle_y=True, return_fig=True)\n",
        "\n",
        "add_lines(fig)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "8859a5491331dba93123a91c2831400aced845b502848170e05fcb48b2c144be"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
